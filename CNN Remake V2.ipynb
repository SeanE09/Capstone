{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conda activate TFgpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"DisplayIMG/Cartoon.png\" alt=\"Image Description\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = os.cpu_count()  # Get number of CPU cores\n",
    "num_cores_to_use = num_cores // 2  # Use half of the cores\n",
    "\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 4/85 [>.............................] - ETA: 53s - loss: 5.6746 - accuracy: 0.0312"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the folder name where the images are located\n",
    "folder_name = \"img\"\n",
    "\n",
    "# Construct the folder path\n",
    "folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# Specify the CSV file path containing image labels\n",
    "csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary where keys are filenames and values are labels\n",
    "labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder, labels_dict):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "        img = Image.open(file_path)\n",
    "        if img is not None:\n",
    "            img = img.convert('L')  # Convert image to grayscale\n",
    "            img = img.resize((64, 64))  # Resize the image to your desired size\n",
    "            np_img = np.array(img)\n",
    "            images.append(np_img)\n",
    "            filename = os.path.basename(file_path)\n",
    "            label = labels_dict[filename]  # Get the label from the filename\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "images = np.array(images)  # Convert list of arrays to a single array\n",
    "mean = np.mean(images)\n",
    "std = np.std(images)\n",
    "images = (images - mean) / std  # Normalize pixel values\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape array for CNN\n",
    "\n",
    "encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# Data augmentation for training data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=35,  # Rotate images randomly by 20 degrees\n",
    "    width_shift_range=0.1,  # Shift images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,  # Shift images vertically by 10% of the height\n",
    "    shear_range=0.0,  # Apply shear transformation with a shear intensity of 0.2\n",
    "    zoom_range=0.1,  # Apply zoom transformation with a zoom range of 0.2\n",
    "    horizontal_flip=False,  # Do not Flip images horizontally\n",
    "    vertical_flip=False  # Do not flip images vertically\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "lr_decay = ReduceLROnPlateau(factor=0.1, patience=10)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First block of convolutions\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Second block of convolutions\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train),\n",
    "                    steps_per_epoch=len(X_train) // 32,\n",
    "                    epochs=200,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[lr_decay])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "[7]\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=le.classes_, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the folder name where the images are located\n",
    "folder_name = \"img\"\n",
    "\n",
    "# Construct the folder path\n",
    "folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# Specify the CSV file path containing image labels\n",
    "csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary where keys are filenames and values are labels\n",
    "labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "def load_images_from_folder(folder, labels_dict):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "        img = Image.open(file_path)\n",
    "        if img is not None:\n",
    "            img = img.convert('L')  # Convert image to grayscale\n",
    "            img = img.resize((64, 64))  # Resize the image to your desired size\n",
    "            np_img = np.array(img)\n",
    "            images.append(np_img)\n",
    "            filename = os.path.basename(file_path)\n",
    "            label = labels_dict[filename]  # Get the label from the filename\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# PyTorch uses torch.Tensor, not np.array, so we need to convert arrays\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "mean = torch.mean(images)\n",
    "std = torch.std(images)\n",
    "images = (images - mean) / std  # Normalize pixel values\n",
    "\n",
    "# PyTorch expects channels dimension before height and width in image tensors\n",
    "images = images.permute(0, 3, 1, 2)\n",
    "\n",
    "# Convert labels to PyTorch tensor\n",
    "numerical_labels = torch.tensor(numerical_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, numerical_labels, test_size=0.2, random_state=42,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(512*2*2, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, len(le.classes_))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool3(F.relu(self.conv6(x)))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.pool4(F.relu(self.conv8(x)))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.pool5(F.relu(self.conv10(x)))\n",
    "        x = x.view(-1, 512*2*2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the model\n",
    "model = Net()\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(X_train, 0):\n",
    "        inputs, labels = data.to(device), y_train[i].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs.unsqueeze(0))\n",
    "        loss = criterion(outputs, labels.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(X_train)}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Testing the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test, 0):\n",
    "        images, labels = data.to(device), y_test[i].to(device)\n",
    "        outputs = model(images.unsqueeze(0))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct / total}')\n",
    "\n",
    "# Print a classification report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test, 0):\n",
    "        images, labels = data.to(device), y_test[i].to(device)\n",
    "        outputs = model(images.unsqueeze(0))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((64, 64))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# mean = np.mean(images)\n",
    "# std = np.std(images)\n",
    "# images = (images - mean) / std  # Normalize pixel values\n",
    "# images = images.reshape(-1, 64, 64, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42,\n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# # Data augmentation for training data\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=35,  # Rotate images randomly by 20 degrees\n",
    "#     width_shift_range=0.1,  # Shift images horizontally by 10% of the width\n",
    "#     height_shift_range=0.1,  # Shift images vertically by 10% of the height\n",
    "#     shear_range=0.0,  # Apply shear transformation with a shear intensity of 0.2\n",
    "#     zoom_range=0.1,  # Apply zoom transformation with a zoom range of 0.2\n",
    "#     horizontal_flip=False,  # Flip images horizontally\n",
    "#     vertical_flip=False  # Do not flip images vertically\n",
    "# )\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# #VGG16 style of model\n",
    "# model = Sequential()\n",
    "\n",
    "# # First block of convolutions\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 1)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Second block of convolutions\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Third block of convolutions\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Fourth block of convolutions\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Fifth block of convolutions\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Fully connected layers\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(4096, activation='relu'))\n",
    "# model.add(Dense(4096, activation='relu'))\n",
    "# model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(datagen.flow(X_train, y_train),\n",
    "#                     steps_per_epoch=len(X_train) // 32,\n",
    "#                     epochs=200,\n",
    "#                     validation_data=(X_test, y_test))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# # Print a classification report\n",
    "# print(classification_report(y_true_classes, y_pred_classes, target_names=le.classes_, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the folder path containing the images\n",
    "folder_path = \"Img\"\n",
    "\n",
    "# Get a list of image file names in the folder\n",
    "image_files = os.listdir(folder_path)\n",
    "\n",
    "# Iterate over the image files\n",
    "for file_name in image_files:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Open the image file\n",
    "    image = Image.open(file_path)\n",
    "\n",
    "    # Get the pixel size of the image\n",
    "    width, height = image.size\n",
    "\n",
    "    # Print the pixel size\n",
    "    print(f\"Image: {file_name}, Width: {width}px, Height: {height}px\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras_tuner import BayesianOptimization, HyperParameters\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras_tuner import HyperParameters\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras_tuner import BayesianOptimization, HyperParameters\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras_tuner import BayesianOptimization\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the folder name where the images are located\n",
    "folder_name = \"img\"\n",
    "\n",
    "# Construct the folder path\n",
    "folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# Specify the CSV file path containing image labels\n",
    "csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary where keys are filenames and values are labels\n",
    "labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder, labels_dict):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "        img = Image.open(file_path)\n",
    "        if img is not None:\n",
    "            img = img.convert('L')  # Convert image to grayscale\n",
    "            img = img.resize((64, 64))  # Resize the image                   3333\n",
    "            np_img = np.array(img)\n",
    "            images.append(np_img)\n",
    "            filename = os.path.basename(file_path)\n",
    "            label = labels_dict[filename]  # Get the label from the filename\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "images = np.array(images)  # Convert list of arrays to a single array\n",
    "mean = np.mean(images)\n",
    "std = np.std(images)\n",
    "images = (images - mean) / std  # Normalize pixel values\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape array for CNN\n",
    "\n",
    "encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# Data augmentation for training data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=35,  # Rotate images randomly by 20 degrees\n",
    "    width_shift_range=0.1,  # Shift images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,  # Shift images vertically by 10% of the height\n",
    "    shear_range=0.0,  # Apply shear transformation with a shear intensity of 0.2\n",
    "    zoom_range=0.1,  # Apply zoom transformation with a zoom range of 0.2\n",
    "    horizontal_flip=False,  # Flip images horizontally\n",
    "    vertical_flip=False  # Do not flip images vertically\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Specify the file path to save the best hyperparameters\n",
    "hyperparameters_file_path = 'best_hyperparameters.pkl'\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First block of convolutions\n",
    "    model.add(Conv2D(hp.Int('conv_1_units', min_value=32, max_value=128, step=32),\n",
    "                     (3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(64, 64, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Second block of convolutions\n",
    "    model.add(Conv2D(hp.Int('conv_2_units', min_value=64, max_value=256, step=64),\n",
    "                     (3, 3),\n",
    "                     activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Int('dense_1_units', min_value=128, max_value=512, step=128), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout_3', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,  # The function to construct the model\n",
    "    objective='val_accuracy',  # The metric to be optimized\n",
    "    max_trials=150,  # The maximum number of iterations for tuning\n",
    "    executions_per_trial=2,  # The number of models that should be built and fit for each trial for robustness purposes\n",
    "    directory=os.path.normpath('C:/keras_tuning'),  # The path to the directory where the search results are stored\n",
    "    project_name='keras_tuner_demo',  # The name of the project. This will be the name of the subdirectory under `directory` where the results are saved\n",
    "    overwrite=True  # Whether or not to overwrite the project if it already exists\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(\n",
    "    X_train,  # Training data\n",
    "    y_train,  # Training labels\n",
    "    epochs=200,  # The number of epochs for training\n",
    "    validation_data=(X_test, y_test),  # Validation data\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Callbacks to be used during training\n",
    ")\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "# Save the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "with open(hyperparameters_file_path, 'wb') as file:\n",
    "    pickle.dump(best_hyperparameters.values, file)\n",
    "\n",
    "# Load the saved hyperparameters\n",
    "with open(hyperparameters_file_path, 'rb') as file:\n",
    "    loaded_hyperparameters_dict = pickle.load(file)\n",
    "\n",
    "# Create a new HyperParameters object and set the loaded hyperparameters\n",
    "loaded_hyperparameters = HyperParameters()\n",
    "loaded_hyperparameters.values = loaded_hyperparameters_dict\n",
    "\n",
    "# Build and train the model with the loaded hyperparameters and augmented data\n",
    "best_model = build_model(loaded_hyperparameters)\n",
    "history = best_model.fit(datagen.flow(X_train, y_train),  # Use the augmented data generator for training data\n",
    "                         steps_per_epoch=len(X_train) // 32,  # Adjust the steps per epoch based on augmented data size\n",
    "                         epochs=500,\n",
    "                         validation_data=(X_test, y_test),\n",
    "                         callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Plotting the accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=le.classes_, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((64, 64))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 64, 64, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# # Data augmentation for training data\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=35,  # Rotate images randomly by 20 degrees\n",
    "#     width_shift_range=0.1,  # Shift images horizontally by 10% of the width\n",
    "#     height_shift_range=0.1,  # Shift images vertically by 10% of the height\n",
    "#     shear_range=0.0,  # Apply shear transformation with a shear intensity of 0.2\n",
    "#     zoom_range=0.1,  # Apply zoom transformation with a zoom range of 0.2\n",
    "#     horizontal_flip=False,  # Flip images horizontally\n",
    "#     vertical_flip=False  # Do not flip images vertically\n",
    "# )\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # Specify the file path to the saved hyperparameters\n",
    "# hyperparameters_file_path = 'best_hyperparameters.pkl'\n",
    "\n",
    "# # Load the saved hyperparameters\n",
    "# with open(hyperparameters_file_path, 'rb') as file:\n",
    "#     loaded_hyperparameters_dict = pickle.load(file)\n",
    "\n",
    "# # Create a new HyperParameters object and set the loaded hyperparameters\n",
    "# loaded_hyperparameters = HyperParameters()\n",
    "# loaded_hyperparameters.values = loaded_hyperparameters_dict\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # First block of convolutions\n",
    "#     model.add(Conv2D(loaded_hyperparameters.get('conv_1_units'),\n",
    "#                      (3, 3),\n",
    "#                      activation='relu',\n",
    "#                      input_shape=(64, 64, 1)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(loaded_hyperparameters.get('dropout_1')))\n",
    "\n",
    "#     # Second block of convolutions\n",
    "#     model.add(Conv2D(loaded_hyperparameters.get('conv_2_units'),\n",
    "#                      (3, 3),\n",
    "#                      activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(loaded_hyperparameters.get('dropout_2')))\n",
    "\n",
    "#     # Fully connected layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(loaded_hyperparameters.get('dense_1_units'), activation='relu'))\n",
    "#     model.add(Dropout(loaded_hyperparameters.get('dropout_3')))\n",
    "#     model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "#     # Compile model\n",
    "#     model.compile(optimizer=Adam(loaded_hyperparameters.get('learning_rate')),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=1000)\n",
    "# model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# # Build and train the model with the loaded hyperparameters and augmented data\n",
    "# best_model = build_model(loaded_hyperparameters)\n",
    "# history = best_model.fit(datagen.flow(X_train, y_train),  # Use the augmented data generator for training data\n",
    "#                          steps_per_epoch=len(X_train) // 32,  # Adjust the steps per epoch based on augmented data size\n",
    "#                          epochs=500,\n",
    "#                          validation_data=(X_test, y_test),\n",
    "#                          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# # Plotting the accuracy and loss\n",
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# # Print a classification report\n",
    "# print(classification_report(y_true_classes, y_pred_classes, target_names=le.classes_, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=[12,8])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=[12,8])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = best_model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Save Model For Furture Use\n",
    "# model.save('EpochTenThousand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Assume you have a history object from model.fit\n",
    "# # history = model.fit(....)\n",
    "\n",
    "# # Save it under some name\n",
    "# with open('trainHistoryDict', 'wb') as file_pi:\n",
    "#     pickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trainHistoryDict', 'rb') as file_pi:\n",
    "#     loaded_history = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = best_model.evaluate(X_train, y_train)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Also convert the one-hot encoded labels back to label encoding\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Convert numerical labels back to original labels\n",
    "y_pred_labels = le.inverse_transform(y_pred_labels)\n",
    "y_true_labels = le.inverse_transform(y_true_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Create a list of unique labels\n",
    "labels = list(le.classes_)\n",
    "\n",
    "# Set the font scale (this will affect heatmap annotation size)\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Adjust size of labels, title using rcParams\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "# Visualize confusion matrix using seaborn's heatmap\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label', fontsize=20)\n",
    "plt.ylabel('True Label', fontsize=20)\n",
    "plt.title('Confusion Matrix', fontsize=25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Maps (CAM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_4')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "\n",
    "# Choose an image from the test set\n",
    "test_image = X_test[4]\n",
    "\n",
    "# Reshape the image to match the input shape of the model\n",
    "test_image = np.reshape(test_image, (1, 64, 64, 1))\n",
    "\n",
    "# Generate the CAM for the chosen image\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_3')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_2')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Reshape the input image to match the expected input shape of the model\n",
    "    img = np.reshape(img, (1, 64, 64, 1))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Maps (CAM) of First Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_2')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Reshape the input image to match the expected input shape of the model\n",
    "    img = np.reshape(img, (-1, 64, 64, 1))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the image to match the expected input shape of the model\n",
    "test_image = np.reshape(test_image, (64, 64))\n",
    "test_image = np.expand_dims(test_image, axis=-1)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Maps (CAM) of 2nd Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_3')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "\n",
    "# Choose an image from the test set\n",
    "test_image = X_test[3]\n",
    "\n",
    "# Reshape the image to match the input shape of the model\n",
    "test_image = np.reshape(test_image, (1, 64, 64, 1))\n",
    "\n",
    "# Generate the CAM for the chosen image\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tf_explain.core.grad_cam import GradCAM\n",
    "\n",
    "# def image_to_uint_255(image):\n",
    "#     if isinstance(image, np.ndarray):\n",
    "#         if image.dtype == np.uint8:\n",
    "#             return image\n",
    "#         if image.min() < 0:\n",
    "#             image = (image + 1.0) / 2.0\n",
    "#         return (image * 255).astype(\"uint8\")\n",
    "#     elif isinstance(image, tf.Tensor):\n",
    "#         if tf.reduce_min(image) < 0:\n",
    "#             image = (image + 1.0) / 2.0\n",
    "#         return (image * 255).numpy().astype(\"uint8\")\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported image type. Expected NumPy array or TensorFlow tensor.\")\n",
    "\n",
    "\n",
    "\n",
    "# # Load the best model\n",
    "# best_model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# # Choose an image from the test set to generate Grad-CAM\n",
    "# image_index = 0\n",
    "# input_image = X_test[image_index]\n",
    "\n",
    "# # Preprocess the input image\n",
    "# preprocessed_image = tf.expand_dims(input_image, axis=0)\n",
    "\n",
    "# # Create a GradCAM instance\n",
    "# explainer = GradCAM()\n",
    "\n",
    "# # Generate Grad-CAM for the predicted class\n",
    "# class_index = np.argmax(best_model.predict(preprocessed_image), axis=1)[0]\n",
    "# grid = explainer.explain(validation_data=(preprocessed_image, None), model=best_model, layer_name=\"conv2d_3\", class_index=class_index)\n",
    "\n",
    "# # Rescale the grid for visualization\n",
    "# grid = cv2.resize(grid[0], (input_image.shape[1], input_image.shape[0]))\n",
    "\n",
    "# # Overlay the original image with the Grad-CAM grid\n",
    "# heatmap = cv2.applyColorMap(np.uint8(255 * grid), cv2.COLORMAP_JET)\n",
    "# output_image = cv2.addWeighted(cv2.cvtColor((input_image * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR), 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "# # Visualize the original image and Grad-CAM\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow((input_image * 255).astype(np.uint8), cmap='gray')\n",
    "# plt.title('Original Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(output_image[:, :, ::-1])\n",
    "# plt.title('Grad-CAM')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, img):\n",
    "    # Extract the intermediate feature maps\n",
    "    layer_outputs = [layer.output for layer in model.layers if 'conv2d' in layer.name]\n",
    "    activation_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    feature_maps = activation_model.predict(img)\n",
    "    \n",
    "    # Plot the feature maps\n",
    "    for layer, feature_map in zip(model.layers, feature_maps):\n",
    "        if 'conv2d' in layer.name:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.imshow(feature_map[0, :, :, 0], cmap='gray')\n",
    "            plt.title(layer.name + ' Feature Map')\n",
    "            plt.show()\n",
    "\n",
    "# Visualize the feature maps for the chosen image\n",
    "visualize_feature_maps(best_model, test_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_filters(model, layer_name):\n",
    "    layer = model.get_layer(layer_name)\n",
    "    filters, _ = layer.get_weights()\n",
    "\n",
    "    if filters.ndim == 4:\n",
    "        filters = np.moveaxis(filters, -1, 0)\n",
    "\n",
    "    num_filters = filters.shape[0]\n",
    "    num_rows = (num_filters + 7) // 8\n",
    "    plt.figure(figsize=(12, num_rows * 1.5))\n",
    "\n",
    "    for i, filter_ in enumerate(filters):\n",
    "        plt.subplot(num_rows, 8, i+1)\n",
    "        plt.imshow(filter_, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(layer_name + ' Filters')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Visualize the filters of the first convolutional layer\n",
    "visualize_filters(best_model, 'conv2d_2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_histograms(model, img):\n",
    "    activation_model = tf.keras.Model(inputs=model.input,\n",
    "                                      outputs=[layer.output for layer in model.layers if 'conv2d' in layer.name])\n",
    "    activations = activation_model.predict(img)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, activation in enumerate(activations):\n",
    "        if 'conv2d_2' in model.layers[i].name:\n",
    "            plt.subplot(2, 4, i+1)\n",
    "            plt.hist(activation.flatten(), bins=50)\n",
    "            plt.title(model.layers[i].name + ' Activation')\n",
    "            plt.xlabel('Activation Value')\n",
    "            plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the activation histograms for the chosen image\n",
    "plot_activation_histograms(best_model, test_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the results of hyperparameter optimization\n",
    "results = pd.read_csv('hyperparameter_results.csv')\n",
    "\n",
    "# Plot the accuracy and loss values for different hyperparameter settings\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results['learning_rate'], results['accuracy'], 'o-')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(results['learning_rate'], results['loss'], 'o-')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# ... (existing code)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the model architecture\n",
    "plot_model(best_model, to_file='model_architecture.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the embeddings from the model\n",
    "embedding_model = tf.keras.Model(inputs=best_model.input,\n",
    "                                 outputs=best_model.get_layer('conv2d_2').output)\n",
    "embeddings = embedding_model.predict(X_test)\n",
    "\n",
    "# Reshape the embeddings array to have two dimensions\n",
    "reshaped_embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "\n",
    "# Standardize the embeddings\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(reshaped_embeddings)\n",
    "\n",
    "# Reduce the dimensionality of the embeddings using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(scaled_embeddings)\n",
    "\n",
    "# Plot the embeddings\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], c=y_true_classes)\n",
    "plt.colorbar()\n",
    "plt.title('Embedding Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
