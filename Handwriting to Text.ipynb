{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate TFgpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 4.1225 - accuracy: 0.0238 - val_loss: 4.0857 - val_accuracy: 0.0220\n",
      "Epoch 2/5\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.7175 - accuracy: 0.0869 - val_loss: 3.2641 - val_accuracy: 0.1745\n",
      "Epoch 3/5\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.7254 - accuracy: 0.2819 - val_loss: 2.5832 - val_accuracy: 0.3402\n",
      "Epoch 4/5\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 2.1166 - accuracy: 0.4249 - val_loss: 2.2214 - val_accuracy: 0.4223\n",
      "Epoch 5/5\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.7076 - accuracy: 0.5246 - val_loss: 1.8346 - val_accuracy: 0.5337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe5fe1ff10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "# import glob\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((28, 28))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# num_classes = len(set(numerical_labels))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 4.0487 - accuracy: 0.0286 - val_loss: 3.7491 - val_accuracy: 0.0865\n",
      "Epoch 2/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 3.1456 - accuracy: 0.1954 - val_loss: 2.7184 - val_accuracy: 0.2742\n",
      "Epoch 3/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 2.0651 - accuracy: 0.4395 - val_loss: 1.8162 - val_accuracy: 0.4985\n",
      "Epoch 4/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.3487 - accuracy: 0.6045 - val_loss: 1.4531 - val_accuracy: 0.5704\n",
      "Epoch 5/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.0118 - accuracy: 0.7023 - val_loss: 1.2266 - val_accuracy: 0.6598\n",
      "Epoch 6/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.7421 - accuracy: 0.7639 - val_loss: 1.1699 - val_accuracy: 0.6657\n",
      "Epoch 7/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.5630 - accuracy: 0.8098 - val_loss: 1.1438 - val_accuracy: 0.6642\n",
      "Epoch 8/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.4557 - accuracy: 0.8471 - val_loss: 1.1156 - val_accuracy: 0.6891\n",
      "Epoch 9/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.3542 - accuracy: 0.8809 - val_loss: 1.2289 - val_accuracy: 0.6716\n",
      "Epoch 10/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2931 - accuracy: 0.9095 - val_loss: 1.2226 - val_accuracy: 0.7009\n",
      "Epoch 11/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2523 - accuracy: 0.9135 - val_loss: 1.2302 - val_accuracy: 0.7273\n",
      "Epoch 12/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2076 - accuracy: 0.9300 - val_loss: 1.2205 - val_accuracy: 0.7155\n",
      "Epoch 13/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.1708 - accuracy: 0.9457 - val_loss: 1.2775 - val_accuracy: 0.7185\n",
      "Epoch 14/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1498 - accuracy: 0.9520 - val_loss: 1.4261 - val_accuracy: 0.7009\n",
      "Epoch 15/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1316 - accuracy: 0.9593 - val_loss: 1.2979 - val_accuracy: 0.7243\n",
      "Epoch 16/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1042 - accuracy: 0.9619 - val_loss: 1.5053 - val_accuracy: 0.6950\n",
      "Epoch 17/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1266 - accuracy: 0.9560 - val_loss: 1.4724 - val_accuracy: 0.7141\n",
      "Epoch 18/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1358 - accuracy: 0.9542 - val_loss: 1.5958 - val_accuracy: 0.7053\n",
      "Epoch 19/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0950 - accuracy: 0.9718 - val_loss: 1.6397 - val_accuracy: 0.7170\n",
      "Epoch 20/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1186 - accuracy: 0.9622 - val_loss: 1.4938 - val_accuracy: 0.6994\n",
      "Epoch 21/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0910 - accuracy: 0.9699 - val_loss: 1.5793 - val_accuracy: 0.7141\n",
      "Epoch 22/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9850 - val_loss: 1.6357 - val_accuracy: 0.7214\n",
      "Epoch 23/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9886 - val_loss: 1.7411 - val_accuracy: 0.7317\n",
      "Epoch 24/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 1.8063 - val_accuracy: 0.7067\n",
      "Epoch 25/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0944 - accuracy: 0.9670 - val_loss: 1.9085 - val_accuracy: 0.6862\n",
      "Epoch 26/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1552 - accuracy: 0.9509 - val_loss: 1.6398 - val_accuracy: 0.7126\n",
      "Epoch 27/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0711 - accuracy: 0.9765 - val_loss: 1.5142 - val_accuracy: 0.7199\n",
      "Epoch 28/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1338 - accuracy: 0.9604 - val_loss: 1.5007 - val_accuracy: 0.7067\n",
      "Epoch 29/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0739 - accuracy: 0.9791 - val_loss: 1.6710 - val_accuracy: 0.7097\n",
      "Epoch 30/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0664 - accuracy: 0.9791 - val_loss: 1.7855 - val_accuracy: 0.7170\n",
      "Epoch 31/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 1.7426 - val_accuracy: 0.7155\n",
      "Epoch 32/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 2.0017 - val_accuracy: 0.6950\n",
      "Epoch 33/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9824 - val_loss: 2.0807 - val_accuracy: 0.6906\n",
      "Epoch 34/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1379 - accuracy: 0.9542 - val_loss: 1.6631 - val_accuracy: 0.6965\n",
      "Epoch 35/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9600 - val_loss: 1.7034 - val_accuracy: 0.7199\n",
      "Epoch 36/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 1.8108 - val_accuracy: 0.7141\n",
      "Epoch 37/40\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 1.7129 - val_accuracy: 0.7243\n",
      "Epoch 38/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 1.6972 - val_accuracy: 0.7361\n",
      "Epoch 39/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 1.7399 - val_accuracy: 0.7419\n",
      "Epoch 40/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 1.7976 - val_accuracy: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe60969750>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "# import glob\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((28, 28))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# num_classes = len(set(numerical_labels))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 4.1274 - accuracy: 0.0136 - val_loss: 4.0938 - val_accuracy: 0.0308\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 3.3595 - accuracy: 0.1540 - val_loss: 2.5466 - val_accuracy: 0.3138\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 2.0615 - accuracy: 0.4238 - val_loss: 1.9384 - val_accuracy: 0.4487\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 1.4710 - accuracy: 0.5579 - val_loss: 1.4671 - val_accuracy: 0.5777\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 1.0963 - accuracy: 0.6510 - val_loss: 1.3418 - val_accuracy: 0.6158\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.8966 - accuracy: 0.7060 - val_loss: 1.2017 - val_accuracy: 0.6554\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.7492 - accuracy: 0.7430 - val_loss: 1.1940 - val_accuracy: 0.6452\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6301 - accuracy: 0.7808 - val_loss: 1.1208 - val_accuracy: 0.6730\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.5240 - accuracy: 0.8145 - val_loss: 1.1526 - val_accuracy: 0.6789\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.8526 - val_loss: 1.1824 - val_accuracy: 0.6730\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.3629 - accuracy: 0.8702 - val_loss: 1.1361 - val_accuracy: 0.6848\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.3358 - accuracy: 0.8798 - val_loss: 1.4035 - val_accuracy: 0.6276\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.3464 - accuracy: 0.8765 - val_loss: 1.2415 - val_accuracy: 0.6804\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2902 - accuracy: 0.9032 - val_loss: 1.2217 - val_accuracy: 0.7009\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2178 - accuracy: 0.9216 - val_loss: 1.3744 - val_accuracy: 0.6848\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2123 - accuracy: 0.9274 - val_loss: 1.3224 - val_accuracy: 0.7170\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1812 - accuracy: 0.9348 - val_loss: 1.4251 - val_accuracy: 0.6979\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1906 - accuracy: 0.9337 - val_loss: 1.5050 - val_accuracy: 0.6818\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1829 - accuracy: 0.9428 - val_loss: 1.5636 - val_accuracy: 0.7038\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1459 - accuracy: 0.9472 - val_loss: 1.5835 - val_accuracy: 0.6950\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1553 - accuracy: 0.9457 - val_loss: 1.4926 - val_accuracy: 0.7141\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1423 - accuracy: 0.9531 - val_loss: 1.3987 - val_accuracy: 0.7111\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1086 - accuracy: 0.9630 - val_loss: 1.3130 - val_accuracy: 0.7258\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0972 - accuracy: 0.9641 - val_loss: 1.5521 - val_accuracy: 0.7038\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0844 - accuracy: 0.9670 - val_loss: 1.5612 - val_accuracy: 0.7141\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0677 - accuracy: 0.9747 - val_loss: 1.7567 - val_accuracy: 0.7185\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1116 - accuracy: 0.9619 - val_loss: 1.7560 - val_accuracy: 0.7023\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1548 - accuracy: 0.9443 - val_loss: 1.4889 - val_accuracy: 0.7258\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.0809 - accuracy: 0.9696 - val_loss: 1.6505 - val_accuracy: 0.6965\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1386 - accuracy: 0.9571 - val_loss: 1.5890 - val_accuracy: 0.7141\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0605 - accuracy: 0.9809 - val_loss: 1.6498 - val_accuracy: 0.7023\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 1.8049 - val_accuracy: 0.7038\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 1.8414 - val_accuracy: 0.7097\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0300 - accuracy: 0.9916 - val_loss: 1.7348 - val_accuracy: 0.7199\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0188 - accuracy: 0.9916 - val_loss: 1.8974 - val_accuracy: 0.6979\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.1792 - accuracy: 0.9428 - val_loss: 1.7727 - val_accuracy: 0.6672\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0990 - accuracy: 0.9655 - val_loss: 1.7456 - val_accuracy: 0.6979\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0883 - accuracy: 0.9740 - val_loss: 1.6653 - val_accuracy: 0.7038\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0774 - accuracy: 0.9758 - val_loss: 1.6805 - val_accuracy: 0.7141\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0829 - accuracy: 0.9751 - val_loss: 1.8103 - val_accuracy: 0.7067\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1181 - accuracy: 0.9630 - val_loss: 1.8671 - val_accuracy: 0.6979\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0914 - accuracy: 0.9648 - val_loss: 1.5858 - val_accuracy: 0.7302\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0869 - accuracy: 0.9699 - val_loss: 1.5365 - val_accuracy: 0.7097\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0593 - accuracy: 0.9817 - val_loss: 1.7920 - val_accuracy: 0.7067\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0920 - accuracy: 0.9677 - val_loss: 1.7514 - val_accuracy: 0.6979\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9853 - val_loss: 1.8501 - val_accuracy: 0.7214\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 1.8898 - val_accuracy: 0.7067\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0676 - accuracy: 0.9820 - val_loss: 1.8923 - val_accuracy: 0.6965\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0545 - accuracy: 0.9828 - val_loss: 1.8992 - val_accuracy: 0.7302\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 1.8693 - val_accuracy: 0.7170\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.9630 - val_accuracy: 0.7155\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.9853 - val_accuracy: 0.7155\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 2.0432 - val_accuracy: 0.7170\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 2.1501 - val_accuracy: 0.7243\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9952 - val_loss: 2.1320 - val_accuracy: 0.7258\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 2.1222 - val_accuracy: 0.7199\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 2.1450 - val_accuracy: 0.7273\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 2.1545 - val_accuracy: 0.7302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1855 - accuracy: 0.9443 - val_loss: 1.7042 - val_accuracy: 0.6730\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9527 - val_loss: 1.8738 - val_accuracy: 0.6921\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0854 - accuracy: 0.9721 - val_loss: 1.8556 - val_accuracy: 0.6877\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 1.7378 - val_accuracy: 0.6994\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0997 - accuracy: 0.9710 - val_loss: 1.7096 - val_accuracy: 0.6950\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0525 - accuracy: 0.9842 - val_loss: 1.9746 - val_accuracy: 0.7067\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 1.9891 - val_accuracy: 0.7185\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 1.8530 - val_accuracy: 0.6848\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0822 - accuracy: 0.9769 - val_loss: 1.7402 - val_accuracy: 0.7185\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 1.7632 - val_accuracy: 0.7419\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 2.0232 - val_accuracy: 0.7141\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 2.0112 - val_accuracy: 0.7141\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 2.1307 - val_accuracy: 0.7199\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 2.0702 - val_accuracy: 0.7141\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0518 - accuracy: 0.9872 - val_loss: 1.8720 - val_accuracy: 0.7141\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 1.9076 - val_accuracy: 0.7170\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1212 - accuracy: 0.9611 - val_loss: 1.7632 - val_accuracy: 0.7009\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9795 - val_loss: 1.8423 - val_accuracy: 0.7199\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9916 - val_loss: 1.8091 - val_accuracy: 0.7287\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 2.0870 - val_accuracy: 0.7009\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0539 - accuracy: 0.9824 - val_loss: 2.0923 - val_accuracy: 0.7111\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1302 - accuracy: 0.9586 - val_loss: 1.6751 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0554 - accuracy: 0.9842 - val_loss: 1.9310 - val_accuracy: 0.7155\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.0185 - accuracy: 0.9963 - val_loss: 1.9777 - val_accuracy: 0.7097\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9908 - val_loss: 2.1591 - val_accuracy: 0.7023\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 2.1083 - val_accuracy: 0.7258\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 2.2308 - val_accuracy: 0.7273\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 2.2879 - val_accuracy: 0.7258\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 2.2318 - val_accuracy: 0.7243\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 2.2674 - val_accuracy: 0.7214\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 2.2964 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0647 - accuracy: 0.9835 - val_loss: 1.9730 - val_accuracy: 0.6950\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1188 - accuracy: 0.9666 - val_loss: 1.8248 - val_accuracy: 0.7038\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0839 - accuracy: 0.9762 - val_loss: 1.8740 - val_accuracy: 0.6891\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0561 - accuracy: 0.9809 - val_loss: 1.9498 - val_accuracy: 0.7097\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 2.0502 - val_accuracy: 0.6965\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 2.0890 - val_accuracy: 0.7023\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9872 - val_loss: 2.3668 - val_accuracy: 0.7038\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0678 - accuracy: 0.9773 - val_loss: 2.2738 - val_accuracy: 0.6657\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0591 - accuracy: 0.9846 - val_loss: 1.8840 - val_accuracy: 0.7243\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 2.0310 - val_accuracy: 0.7097\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 2.0927 - val_accuracy: 0.7170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe61b5d9c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "# import glob\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((28, 28))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# model.add(Dense(228, activation='relu'))\n",
    "\n",
    "# num_classes = len(set(numerical_labels))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "86/86 [==============================] - 3s 25ms/step - loss: 4.5012 - accuracy: 0.0554 - val_loss: 11.9708 - val_accuracy: 0.0117\n",
      "Epoch 2/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 3.6231 - accuracy: 0.1221 - val_loss: 4.2682 - val_accuracy: 0.0440\n",
      "Epoch 3/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 3.1685 - accuracy: 0.1990 - val_loss: 3.4369 - val_accuracy: 0.1320\n",
      "Epoch 4/300\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7277 - accuracy: 0.2793 - val_loss: 2.5696 - val_accuracy: 0.2551\n",
      "Epoch 5/300\n",
      "86/86 [==============================] - 7s 78ms/step - loss: 2.3888 - accuracy: 0.3614 - val_loss: 1.9015 - val_accuracy: 0.4809\n",
      "Epoch 6/300\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.2130 - accuracy: 0.3915 - val_loss: 2.0125 - val_accuracy: 0.4472\n",
      "Epoch 7/300\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.0280 - accuracy: 0.4311 - val_loss: 3.3763 - val_accuracy: 0.2683\n",
      "Epoch 8/300\n",
      "86/86 [==============================] - 4s 48ms/step - loss: 1.8887 - accuracy: 0.4608 - val_loss: 1.3032 - val_accuracy: 0.6129\n",
      "Epoch 9/300\n",
      "86/86 [==============================] - 6s 63ms/step - loss: 1.7576 - accuracy: 0.4842 - val_loss: 3.1191 - val_accuracy: 0.3152\n",
      "Epoch 10/300\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 1.6453 - accuracy: 0.5136 - val_loss: 1.0945 - val_accuracy: 0.6774\n",
      "Epoch 11/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.5490 - accuracy: 0.5374 - val_loss: 1.2588 - val_accuracy: 0.6100\n",
      "Epoch 12/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.4818 - accuracy: 0.5557 - val_loss: 2.4061 - val_accuracy: 0.4150\n",
      "Epoch 13/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.4397 - accuracy: 0.5623 - val_loss: 5.0647 - val_accuracy: 0.2361\n",
      "Epoch 14/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 1.3703 - accuracy: 0.5872 - val_loss: 2.1998 - val_accuracy: 0.4633\n",
      "Epoch 15/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.3036 - accuracy: 0.5920 - val_loss: 1.4329 - val_accuracy: 0.5982\n",
      "Epoch 16/300\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 1.2568 - accuracy: 0.6056 - val_loss: 0.9714 - val_accuracy: 0.6950\n",
      "Epoch 17/300\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.1964 - accuracy: 0.6353 - val_loss: 0.7704 - val_accuracy: 0.7566\n",
      "Epoch 18/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.1536 - accuracy: 0.6345 - val_loss: 1.2274 - val_accuracy: 0.6408\n",
      "Epoch 19/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 1.1517 - accuracy: 0.6356 - val_loss: 2.0454 - val_accuracy: 0.5029\n",
      "Epoch 20/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 1.1109 - accuracy: 0.6558 - val_loss: 1.6173 - val_accuracy: 0.5645\n",
      "Epoch 21/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 1.0768 - accuracy: 0.6664 - val_loss: 0.8172 - val_accuracy: 0.7214\n",
      "Epoch 22/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.0619 - accuracy: 0.6719 - val_loss: 0.9218 - val_accuracy: 0.7258\n",
      "Epoch 23/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 1.0359 - accuracy: 0.6657 - val_loss: 1.7112 - val_accuracy: 0.5161\n",
      "Epoch 24/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.0017 - accuracy: 0.6848 - val_loss: 0.6166 - val_accuracy: 0.8079\n",
      "Epoch 25/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.0213 - accuracy: 0.6822 - val_loss: 0.6866 - val_accuracy: 0.7874\n",
      "Epoch 26/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9776 - accuracy: 0.6917 - val_loss: 1.1741 - val_accuracy: 0.6422\n",
      "Epoch 27/300\n",
      "86/86 [==============================] - 2s 22ms/step - loss: 0.9413 - accuracy: 0.7031 - val_loss: 0.6183 - val_accuracy: 0.8109\n",
      "Epoch 28/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9151 - accuracy: 0.6961 - val_loss: 1.1184 - val_accuracy: 0.6804\n",
      "Epoch 29/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.9208 - accuracy: 0.7005 - val_loss: 0.8101 - val_accuracy: 0.7463\n",
      "Epoch 30/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.9168 - accuracy: 0.7078 - val_loss: 0.9382 - val_accuracy: 0.7053\n",
      "Epoch 31/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.8546 - accuracy: 0.7298 - val_loss: 0.7619 - val_accuracy: 0.7463\n",
      "Epoch 32/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8526 - accuracy: 0.7207 - val_loss: 0.7686 - val_accuracy: 0.7478\n",
      "Epoch 33/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.8733 - accuracy: 0.7174 - val_loss: 0.9690 - val_accuracy: 0.7126\n",
      "Epoch 34/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8807 - accuracy: 0.7141 - val_loss: 0.6978 - val_accuracy: 0.7889\n",
      "Epoch 35/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8443 - accuracy: 0.7258 - val_loss: 0.8456 - val_accuracy: 0.7375\n",
      "Epoch 36/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.8321 - accuracy: 0.7221 - val_loss: 0.5135 - val_accuracy: 0.8358\n",
      "Epoch 37/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7718 - accuracy: 0.7533 - val_loss: 0.9837 - val_accuracy: 0.7155\n",
      "Epoch 38/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.8088 - accuracy: 0.7390 - val_loss: 0.9261 - val_accuracy: 0.7405\n",
      "Epoch 39/300\n",
      "86/86 [==============================] - 2s 17ms/step - loss: 0.8201 - accuracy: 0.7298 - val_loss: 0.8942 - val_accuracy: 0.7287\n",
      "Epoch 40/300\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.7763 - accuracy: 0.7471 - val_loss: 0.6053 - val_accuracy: 0.7991\n",
      "Epoch 41/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.7462 - accuracy: 0.7511 - val_loss: 1.6548 - val_accuracy: 0.5909\n",
      "Epoch 42/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.7507 - accuracy: 0.7551 - val_loss: 0.4702 - val_accuracy: 0.8328\n",
      "Epoch 43/300\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 0.7652 - accuracy: 0.7562 - val_loss: 0.8565 - val_accuracy: 0.7199\n",
      "Epoch 44/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.7747 - accuracy: 0.7504 - val_loss: 0.5880 - val_accuracy: 0.8109\n",
      "Epoch 45/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.7957 - accuracy: 0.7423 - val_loss: 0.6133 - val_accuracy: 0.7977\n",
      "Epoch 46/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.7166 - accuracy: 0.7562 - val_loss: 0.7788 - val_accuracy: 0.7639\n",
      "Epoch 47/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7001 - accuracy: 0.7683 - val_loss: 0.6621 - val_accuracy: 0.7815\n",
      "Epoch 48/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7246 - accuracy: 0.7588 - val_loss: 0.6548 - val_accuracy: 0.7786\n",
      "Epoch 49/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.7628 - val_loss: 0.6236 - val_accuracy: 0.7830\n",
      "Epoch 50/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7116 - accuracy: 0.7584 - val_loss: 0.5238 - val_accuracy: 0.8255\n",
      "Epoch 51/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7301 - accuracy: 0.7595 - val_loss: 0.7761 - val_accuracy: 0.7683\n",
      "Epoch 52/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.7386 - accuracy: 0.7603 - val_loss: 0.5818 - val_accuracy: 0.8050\n",
      "Epoch 53/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.6803 - accuracy: 0.7694 - val_loss: 0.6226 - val_accuracy: 0.7801\n",
      "Epoch 54/300\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.6866 - accuracy: 0.7661 - val_loss: 0.4376 - val_accuracy: 0.8504\n",
      "Epoch 55/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6465 - accuracy: 0.7896 - val_loss: 0.4582 - val_accuracy: 0.8460\n",
      "Epoch 56/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6718 - accuracy: 0.7764 - val_loss: 0.5803 - val_accuracy: 0.8065\n",
      "Epoch 57/300\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.6460 - accuracy: 0.7845 - val_loss: 0.4864 - val_accuracy: 0.8402\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 14ms/step - loss: 0.6475 - accuracy: 0.7852 - val_loss: 0.4851 - val_accuracy: 0.8314\n",
      "Epoch 59/300\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.6256 - accuracy: 0.7881 - val_loss: 0.5312 - val_accuracy: 0.8196\n",
      "Epoch 60/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6455 - accuracy: 0.7845 - val_loss: 0.4474 - val_accuracy: 0.8578\n",
      "Epoch 61/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5810 - accuracy: 0.8039 - val_loss: 1.1377 - val_accuracy: 0.6833\n",
      "Epoch 62/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6414 - accuracy: 0.7914 - val_loss: 0.6160 - val_accuracy: 0.8006\n",
      "Epoch 63/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.6413 - accuracy: 0.7852 - val_loss: 0.7077 - val_accuracy: 0.7962\n",
      "Epoch 64/300\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.6294 - accuracy: 0.7955 - val_loss: 0.4434 - val_accuracy: 0.8490\n",
      "Epoch 65/300\n",
      "86/86 [==============================] - 2s 17ms/step - loss: 0.6170 - accuracy: 0.7925 - val_loss: 0.9991 - val_accuracy: 0.7185\n",
      "Epoch 66/300\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.6320 - accuracy: 0.7903 - val_loss: 1.7067 - val_accuracy: 0.6305\n",
      "Epoch 67/300\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.6077 - accuracy: 0.7955 - val_loss: 0.5364 - val_accuracy: 0.8226\n",
      "Epoch 68/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.6003 - accuracy: 0.7947 - val_loss: 0.4396 - val_accuracy: 0.8284\n",
      "Epoch 69/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.6361 - accuracy: 0.7859 - val_loss: 0.4602 - val_accuracy: 0.8402\n",
      "Epoch 70/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5970 - accuracy: 0.8006 - val_loss: 0.4693 - val_accuracy: 0.8284\n",
      "Epoch 71/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5947 - accuracy: 0.7947 - val_loss: 0.4439 - val_accuracy: 0.8328\n",
      "Epoch 72/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5763 - accuracy: 0.7984 - val_loss: 0.5287 - val_accuracy: 0.8138\n",
      "Epoch 73/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5818 - accuracy: 0.8017 - val_loss: 0.4269 - val_accuracy: 0.8387\n",
      "Epoch 74/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5836 - accuracy: 0.8043 - val_loss: 0.5237 - val_accuracy: 0.8211\n",
      "Epoch 75/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5593 - accuracy: 0.8112 - val_loss: 0.5533 - val_accuracy: 0.8314\n",
      "Epoch 76/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5806 - accuracy: 0.8109 - val_loss: 0.5215 - val_accuracy: 0.8167\n",
      "Epoch 77/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5906 - accuracy: 0.7988 - val_loss: 0.4061 - val_accuracy: 0.8622\n",
      "Epoch 78/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5664 - accuracy: 0.8061 - val_loss: 0.5292 - val_accuracy: 0.8123\n",
      "Epoch 79/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5697 - accuracy: 0.8087 - val_loss: 0.6985 - val_accuracy: 0.7786\n",
      "Epoch 80/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5532 - accuracy: 0.8079 - val_loss: 1.2153 - val_accuracy: 0.6657\n",
      "Epoch 81/300\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.5820 - accuracy: 0.7984 - val_loss: 1.4880 - val_accuracy: 0.6041\n",
      "Epoch 82/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5627 - accuracy: 0.8024 - val_loss: 0.6980 - val_accuracy: 0.7918\n",
      "Epoch 83/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.5522 - accuracy: 0.8112 - val_loss: 0.5200 - val_accuracy: 0.8226\n",
      "Epoch 84/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5723 - accuracy: 0.8061 - val_loss: 0.5247 - val_accuracy: 0.8240\n",
      "Epoch 85/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5423 - accuracy: 0.8109 - val_loss: 0.5062 - val_accuracy: 0.8402\n",
      "Epoch 86/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5444 - accuracy: 0.8105 - val_loss: 1.1911 - val_accuracy: 0.6862\n",
      "Epoch 87/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5557 - accuracy: 0.8116 - val_loss: 0.4192 - val_accuracy: 0.8548\n",
      "Epoch 88/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5260 - accuracy: 0.8244 - val_loss: 0.4479 - val_accuracy: 0.8490\n",
      "Epoch 89/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5130 - accuracy: 0.8248 - val_loss: 0.4334 - val_accuracy: 0.8402\n",
      "Epoch 90/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5206 - accuracy: 0.8163 - val_loss: 0.5365 - val_accuracy: 0.8196\n",
      "Epoch 91/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5086 - accuracy: 0.8196 - val_loss: 1.3431 - val_accuracy: 0.6584\n",
      "Epoch 92/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5318 - accuracy: 0.8130 - val_loss: 0.4606 - val_accuracy: 0.8328\n",
      "Epoch 93/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.5126 - accuracy: 0.8156 - val_loss: 0.5864 - val_accuracy: 0.8182\n",
      "Epoch 94/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5055 - accuracy: 0.8240 - val_loss: 0.4304 - val_accuracy: 0.8636\n",
      "Epoch 95/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5044 - accuracy: 0.8207 - val_loss: 1.3065 - val_accuracy: 0.6760\n",
      "Epoch 96/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5065 - accuracy: 0.8226 - val_loss: 1.1178 - val_accuracy: 0.6965\n",
      "Epoch 97/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5210 - accuracy: 0.8251 - val_loss: 0.4059 - val_accuracy: 0.8607\n",
      "Epoch 98/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4995 - accuracy: 0.8207 - val_loss: 0.4428 - val_accuracy: 0.8475\n",
      "Epoch 99/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.5374 - accuracy: 0.8193 - val_loss: 0.4882 - val_accuracy: 0.8402\n",
      "Epoch 100/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4877 - accuracy: 0.8270 - val_loss: 0.5036 - val_accuracy: 0.8255\n",
      "Epoch 101/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4612 - accuracy: 0.8405 - val_loss: 0.3542 - val_accuracy: 0.8783\n",
      "Epoch 102/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4785 - accuracy: 0.8343 - val_loss: 0.4103 - val_accuracy: 0.8490\n",
      "Epoch 103/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4712 - accuracy: 0.8380 - val_loss: 0.7393 - val_accuracy: 0.7859\n",
      "Epoch 104/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5110 - accuracy: 0.8149 - val_loss: 0.4113 - val_accuracy: 0.8548\n",
      "Epoch 105/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4818 - accuracy: 0.8292 - val_loss: 0.5472 - val_accuracy: 0.8079\n",
      "Epoch 106/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4621 - accuracy: 0.8383 - val_loss: 0.7887 - val_accuracy: 0.7683\n",
      "Epoch 107/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4984 - accuracy: 0.8310 - val_loss: 0.4550 - val_accuracy: 0.8475\n",
      "Epoch 108/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4574 - accuracy: 0.8354 - val_loss: 0.4527 - val_accuracy: 0.8402\n",
      "Epoch 109/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4822 - accuracy: 0.8402 - val_loss: 0.6065 - val_accuracy: 0.8006\n",
      "Epoch 110/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4418 - accuracy: 0.8431 - val_loss: 0.5922 - val_accuracy: 0.8065\n",
      "Epoch 111/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4835 - accuracy: 0.8266 - val_loss: 0.3687 - val_accuracy: 0.8754\n",
      "Epoch 112/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4637 - accuracy: 0.8405 - val_loss: 0.5560 - val_accuracy: 0.8152\n",
      "Epoch 113/300\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4973 - accuracy: 0.8343 - val_loss: 0.7304 - val_accuracy: 0.7757\n",
      "Epoch 114/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.5030 - accuracy: 0.8248 - val_loss: 0.5659 - val_accuracy: 0.8094\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4509 - accuracy: 0.8347 - val_loss: 0.3447 - val_accuracy: 0.8680\n",
      "Epoch 116/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4455 - accuracy: 0.8435 - val_loss: 0.7935 - val_accuracy: 0.7625\n",
      "Epoch 117/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4182 - accuracy: 0.8537 - val_loss: 0.9914 - val_accuracy: 0.7419\n",
      "Epoch 118/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4560 - accuracy: 0.8409 - val_loss: 0.8938 - val_accuracy: 0.7229\n",
      "Epoch 119/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4686 - accuracy: 0.8372 - val_loss: 0.5534 - val_accuracy: 0.8211\n",
      "Epoch 120/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4615 - accuracy: 0.8405 - val_loss: 0.3864 - val_accuracy: 0.8607\n",
      "Epoch 121/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4909 - accuracy: 0.8295 - val_loss: 0.3610 - val_accuracy: 0.8783\n",
      "Epoch 122/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4952 - accuracy: 0.8354 - val_loss: 0.5281 - val_accuracy: 0.8211\n",
      "Epoch 123/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4984 - accuracy: 0.8262 - val_loss: 0.4381 - val_accuracy: 0.8460\n",
      "Epoch 124/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4709 - accuracy: 0.8446 - val_loss: 0.7516 - val_accuracy: 0.7639\n",
      "Epoch 125/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4886 - accuracy: 0.8277 - val_loss: 0.4997 - val_accuracy: 0.8167\n",
      "Epoch 126/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4703 - accuracy: 0.8387 - val_loss: 0.4100 - val_accuracy: 0.8387\n",
      "Epoch 127/300\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.4623 - accuracy: 0.8383 - val_loss: 1.2126 - val_accuracy: 0.7009\n",
      "Epoch 128/300\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4535 - accuracy: 0.8358 - val_loss: 0.5124 - val_accuracy: 0.8211\n",
      "Epoch 129/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4654 - accuracy: 0.8295 - val_loss: 0.3622 - val_accuracy: 0.8651\n",
      "Epoch 130/300\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4296 - accuracy: 0.8493 - val_loss: 0.8302 - val_accuracy: 0.7786\n",
      "Epoch 131/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4842 - accuracy: 0.8277 - val_loss: 0.7008 - val_accuracy: 0.7859\n",
      "Epoch 132/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5100 - accuracy: 0.8218 - val_loss: 0.5100 - val_accuracy: 0.8240\n",
      "Epoch 133/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4686 - accuracy: 0.8365 - val_loss: 0.3692 - val_accuracy: 0.8607\n",
      "Epoch 134/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4544 - accuracy: 0.8424 - val_loss: 0.3777 - val_accuracy: 0.8607\n",
      "Epoch 135/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4346 - accuracy: 0.8427 - val_loss: 0.4386 - val_accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe772cd2d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# import glob\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((28, 28))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))  # Adjusted Dropout\n",
    "\n",
    "# num_classes = len(set(numerical_labels))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# # Changed optimizer to SGD\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=10,\n",
    "#     zoom_range = 0.1,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1)\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "\n",
    "# # Model Checkpoint\n",
    "# checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "#           epochs=300,\n",
    "#           validation_data=(X_test, y_test),\n",
    "#           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "86/86 [==============================] - 2s 13ms/step - loss: 4.3221 - accuracy: 0.0707 - val_loss: 13.1139 - val_accuracy: 0.0088\n",
      "Epoch 2/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 3.4362 - accuracy: 0.1617 - val_loss: 4.4004 - val_accuracy: 0.0543\n",
      "Epoch 3/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 2.8848 - accuracy: 0.2485 - val_loss: 4.1243 - val_accuracy: 0.1026\n",
      "Epoch 4/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 2.4087 - accuracy: 0.3526 - val_loss: 4.1977 - val_accuracy: 0.1276\n",
      "Epoch 5/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 2.0448 - accuracy: 0.4183 - val_loss: 4.0060 - val_accuracy: 0.1774\n",
      "Epoch 6/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.8329 - accuracy: 0.4787 - val_loss: 3.3737 - val_accuracy: 0.2757\n",
      "Epoch 7/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.6217 - accuracy: 0.5282 - val_loss: 4.7254 - val_accuracy: 0.1979\n",
      "Epoch 8/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.4785 - accuracy: 0.5748 - val_loss: 3.8465 - val_accuracy: 0.2581\n",
      "Epoch 9/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.3957 - accuracy: 0.5891 - val_loss: 0.9544 - val_accuracy: 0.6965\n",
      "Epoch 10/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.2743 - accuracy: 0.6030 - val_loss: 2.7682 - val_accuracy: 0.3944\n",
      "Epoch 11/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.2048 - accuracy: 0.6360 - val_loss: 1.3660 - val_accuracy: 0.5982\n",
      "Epoch 12/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.1401 - accuracy: 0.6584 - val_loss: 2.1375 - val_accuracy: 0.4721\n",
      "Epoch 13/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.1060 - accuracy: 0.6573 - val_loss: 1.1780 - val_accuracy: 0.6525\n",
      "Epoch 14/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.0586 - accuracy: 0.6734 - val_loss: 5.5191 - val_accuracy: 0.2273\n",
      "Epoch 15/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.0144 - accuracy: 0.6840 - val_loss: 7.0711 - val_accuracy: 0.1833\n",
      "Epoch 16/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.9831 - accuracy: 0.6837 - val_loss: 1.7646 - val_accuracy: 0.5616\n",
      "Epoch 17/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.9535 - accuracy: 0.6990 - val_loss: 0.7052 - val_accuracy: 0.7874\n",
      "Epoch 18/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8960 - accuracy: 0.7078 - val_loss: 3.0758 - val_accuracy: 0.3739\n",
      "Epoch 19/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8974 - accuracy: 0.7086 - val_loss: 1.4476 - val_accuracy: 0.5968\n",
      "Epoch 20/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8923 - accuracy: 0.7119 - val_loss: 0.5918 - val_accuracy: 0.8138\n",
      "Epoch 21/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8292 - accuracy: 0.7335 - val_loss: 1.5188 - val_accuracy: 0.5601\n",
      "Epoch 22/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8093 - accuracy: 0.7368 - val_loss: 1.5631 - val_accuracy: 0.5821\n",
      "Epoch 23/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7957 - accuracy: 0.7298 - val_loss: 2.5243 - val_accuracy: 0.4223\n",
      "Epoch 24/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7530 - accuracy: 0.7529 - val_loss: 2.0410 - val_accuracy: 0.4795\n",
      "Epoch 25/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7943 - accuracy: 0.7408 - val_loss: 5.2376 - val_accuracy: 0.2317\n",
      "Epoch 26/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.7278 - accuracy: 0.7537 - val_loss: 2.3915 - val_accuracy: 0.4487\n",
      "Epoch 27/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7043 - accuracy: 0.7606 - val_loss: 0.7069 - val_accuracy: 0.7742\n",
      "Epoch 28/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7427 - accuracy: 0.7518 - val_loss: 3.3840 - val_accuracy: 0.3592\n",
      "Epoch 29/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7083 - accuracy: 0.7727 - val_loss: 6.9117 - val_accuracy: 0.2273\n",
      "Epoch 30/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7161 - accuracy: 0.7683 - val_loss: 1.2775 - val_accuracy: 0.6276\n",
      "Epoch 31/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6825 - accuracy: 0.7764 - val_loss: 1.9075 - val_accuracy: 0.4824\n",
      "Epoch 32/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6592 - accuracy: 0.7790 - val_loss: 0.4975 - val_accuracy: 0.8255\n",
      "Epoch 33/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6678 - accuracy: 0.7731 - val_loss: 0.5660 - val_accuracy: 0.8123\n",
      "Epoch 34/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6320 - accuracy: 0.7834 - val_loss: 1.3601 - val_accuracy: 0.6701\n",
      "Epoch 35/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6226 - accuracy: 0.7878 - val_loss: 0.9757 - val_accuracy: 0.7023\n",
      "Epoch 36/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6373 - accuracy: 0.7863 - val_loss: 0.6397 - val_accuracy: 0.7903\n",
      "Epoch 37/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5905 - accuracy: 0.7966 - val_loss: 0.6389 - val_accuracy: 0.7845\n",
      "Epoch 38/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6404 - accuracy: 0.7830 - val_loss: 1.1070 - val_accuracy: 0.6818\n",
      "Epoch 39/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6242 - accuracy: 0.7826 - val_loss: 1.2069 - val_accuracy: 0.6628\n",
      "Epoch 40/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6149 - accuracy: 0.7980 - val_loss: 2.7028 - val_accuracy: 0.4399\n",
      "Epoch 41/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6175 - accuracy: 0.7848 - val_loss: 0.6126 - val_accuracy: 0.8065\n",
      "Epoch 42/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5627 - accuracy: 0.8076 - val_loss: 1.0629 - val_accuracy: 0.7067\n",
      "Epoch 43/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6019 - accuracy: 0.7889 - val_loss: 0.6037 - val_accuracy: 0.8006\n",
      "Epoch 44/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5555 - accuracy: 0.8039 - val_loss: 0.8832 - val_accuracy: 0.7361\n",
      "Epoch 45/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5676 - accuracy: 0.7947 - val_loss: 0.7663 - val_accuracy: 0.7742\n",
      "Epoch 46/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5726 - accuracy: 0.7955 - val_loss: 0.4720 - val_accuracy: 0.8358\n",
      "Epoch 47/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5410 - accuracy: 0.8101 - val_loss: 0.7088 - val_accuracy: 0.7786\n",
      "Epoch 48/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5304 - accuracy: 0.8145 - val_loss: 0.4684 - val_accuracy: 0.8314\n",
      "Epoch 49/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5344 - accuracy: 0.8112 - val_loss: 0.7150 - val_accuracy: 0.7830\n",
      "Epoch 50/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5253 - accuracy: 0.8160 - val_loss: 0.8091 - val_accuracy: 0.7507\n",
      "Epoch 51/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5078 - accuracy: 0.8185 - val_loss: 0.7281 - val_accuracy: 0.7698\n",
      "Epoch 52/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5151 - accuracy: 0.8314 - val_loss: 0.4817 - val_accuracy: 0.8358\n",
      "Epoch 53/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5095 - accuracy: 0.8332 - val_loss: 0.5025 - val_accuracy: 0.8343\n",
      "Epoch 54/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4952 - accuracy: 0.8270 - val_loss: 0.5321 - val_accuracy: 0.8255\n",
      "Epoch 55/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5020 - accuracy: 0.8292 - val_loss: 1.0767 - val_accuracy: 0.6891\n",
      "Epoch 56/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4861 - accuracy: 0.8251 - val_loss: 0.7142 - val_accuracy: 0.7786\n",
      "Epoch 57/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4965 - accuracy: 0.8218 - val_loss: 0.6618 - val_accuracy: 0.7889\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4592 - accuracy: 0.8365 - val_loss: 0.5477 - val_accuracy: 0.8182\n",
      "Epoch 59/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4742 - accuracy: 0.8306 - val_loss: 1.6740 - val_accuracy: 0.5938\n",
      "Epoch 60/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4866 - accuracy: 0.8317 - val_loss: 0.5568 - val_accuracy: 0.8196\n",
      "Epoch 61/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4418 - accuracy: 0.8427 - val_loss: 0.5488 - val_accuracy: 0.8196\n",
      "Epoch 62/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4866 - accuracy: 0.8273 - val_loss: 1.5617 - val_accuracy: 0.5880\n",
      "Epoch 63/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4863 - accuracy: 0.8281 - val_loss: 0.7543 - val_accuracy: 0.7595\n",
      "Epoch 64/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4877 - accuracy: 0.8270 - val_loss: 0.5894 - val_accuracy: 0.8152\n",
      "Epoch 65/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4658 - accuracy: 0.8281 - val_loss: 0.5853 - val_accuracy: 0.8196\n",
      "Epoch 66/300\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.4697 - accuracy: 0.8402 - val_loss: 0.8514 - val_accuracy: 0.7493\n",
      "Epoch 67/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4339 - accuracy: 0.8504 - val_loss: 0.5626 - val_accuracy: 0.8138\n",
      "Epoch 68/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4172 - accuracy: 0.8490 - val_loss: 0.5106 - val_accuracy: 0.8196\n",
      "Epoch 69/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4443 - accuracy: 0.8416 - val_loss: 0.9536 - val_accuracy: 0.7214\n",
      "Epoch 70/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4392 - accuracy: 0.8438 - val_loss: 1.1400 - val_accuracy: 0.6906\n",
      "Epoch 71/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4214 - accuracy: 0.8475 - val_loss: 0.6974 - val_accuracy: 0.7683\n",
      "Epoch 72/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4461 - accuracy: 0.8391 - val_loss: 0.7378 - val_accuracy: 0.7801\n",
      "Epoch 73/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4380 - accuracy: 0.8435 - val_loss: 1.2224 - val_accuracy: 0.6716\n",
      "Epoch 74/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4219 - accuracy: 0.8438 - val_loss: 0.6283 - val_accuracy: 0.8006\n",
      "Epoch 75/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4318 - accuracy: 0.8493 - val_loss: 2.6814 - val_accuracy: 0.4648\n",
      "Epoch 76/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4242 - accuracy: 0.8497 - val_loss: 0.3986 - val_accuracy: 0.8578\n",
      "Epoch 77/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4431 - accuracy: 0.8416 - val_loss: 0.5725 - val_accuracy: 0.7947\n",
      "Epoch 78/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4384 - accuracy: 0.8453 - val_loss: 1.7535 - val_accuracy: 0.5733\n",
      "Epoch 79/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4451 - accuracy: 0.8339 - val_loss: 0.4026 - val_accuracy: 0.8578\n",
      "Epoch 80/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4042 - accuracy: 0.8600 - val_loss: 0.7412 - val_accuracy: 0.7551\n",
      "Epoch 81/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4207 - accuracy: 0.8479 - val_loss: 0.3894 - val_accuracy: 0.8651\n",
      "Epoch 82/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3968 - accuracy: 0.8537 - val_loss: 0.4534 - val_accuracy: 0.8431\n",
      "Epoch 83/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4143 - accuracy: 0.8497 - val_loss: 0.5579 - val_accuracy: 0.8138\n",
      "Epoch 84/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4258 - accuracy: 0.8427 - val_loss: 0.4576 - val_accuracy: 0.8328\n",
      "Epoch 85/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4074 - accuracy: 0.8482 - val_loss: 0.4847 - val_accuracy: 0.8343\n",
      "Epoch 86/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4085 - accuracy: 0.8512 - val_loss: 0.5642 - val_accuracy: 0.8167\n",
      "Epoch 87/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4006 - accuracy: 0.8633 - val_loss: 0.5858 - val_accuracy: 0.8123\n",
      "Epoch 88/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3921 - accuracy: 0.8512 - val_loss: 0.4670 - val_accuracy: 0.8372\n",
      "Epoch 89/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3932 - accuracy: 0.8611 - val_loss: 1.5277 - val_accuracy: 0.6056\n",
      "Epoch 90/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4017 - accuracy: 0.8490 - val_loss: 0.6122 - val_accuracy: 0.7889\n",
      "Epoch 91/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3705 - accuracy: 0.8640 - val_loss: 0.4579 - val_accuracy: 0.8416\n",
      "Epoch 92/300\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.3709 - accuracy: 0.8614 - val_loss: 0.4145 - val_accuracy: 0.8431\n",
      "Epoch 93/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3952 - accuracy: 0.8570 - val_loss: 5.2608 - val_accuracy: 0.3021\n",
      "Epoch 94/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3772 - accuracy: 0.8570 - val_loss: 0.4776 - val_accuracy: 0.8328\n",
      "Epoch 95/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3794 - accuracy: 0.8600 - val_loss: 0.4368 - val_accuracy: 0.8548\n",
      "Epoch 96/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3904 - accuracy: 0.8519 - val_loss: 0.4775 - val_accuracy: 0.8446\n",
      "Epoch 97/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3777 - accuracy: 0.8618 - val_loss: 0.4999 - val_accuracy: 0.8270\n",
      "Epoch 98/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3844 - accuracy: 0.8537 - val_loss: 0.5293 - val_accuracy: 0.8270\n",
      "Epoch 99/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3665 - accuracy: 0.8658 - val_loss: 0.4046 - val_accuracy: 0.8607\n",
      "Epoch 100/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3663 - accuracy: 0.8691 - val_loss: 0.4567 - val_accuracy: 0.8504\n",
      "Epoch 101/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3616 - accuracy: 0.8721 - val_loss: 0.5667 - val_accuracy: 0.8094\n",
      "Epoch 102/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3554 - accuracy: 0.8651 - val_loss: 0.4057 - val_accuracy: 0.8592\n",
      "Epoch 103/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3727 - accuracy: 0.8658 - val_loss: 0.4069 - val_accuracy: 0.8636\n",
      "Epoch 104/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3416 - accuracy: 0.8831 - val_loss: 0.7060 - val_accuracy: 0.8035\n",
      "Epoch 105/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3796 - accuracy: 0.8629 - val_loss: 0.4674 - val_accuracy: 0.8431\n",
      "Epoch 106/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3660 - accuracy: 0.8688 - val_loss: 1.1574 - val_accuracy: 0.7170\n",
      "Epoch 107/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3701 - accuracy: 0.8556 - val_loss: 0.4898 - val_accuracy: 0.8167\n",
      "Epoch 108/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3703 - accuracy: 0.8603 - val_loss: 0.4370 - val_accuracy: 0.8490\n",
      "Epoch 109/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3612 - accuracy: 0.8677 - val_loss: 0.3981 - val_accuracy: 0.8548\n",
      "Epoch 110/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3507 - accuracy: 0.8702 - val_loss: 0.9866 - val_accuracy: 0.7038\n",
      "Epoch 111/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3553 - accuracy: 0.8724 - val_loss: 0.4161 - val_accuracy: 0.8592\n",
      "Epoch 112/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3560 - accuracy: 0.8713 - val_loss: 0.5112 - val_accuracy: 0.8255\n",
      "Epoch 113/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3598 - accuracy: 0.8666 - val_loss: 0.4024 - val_accuracy: 0.8563\n",
      "Epoch 114/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3660 - accuracy: 0.8647 - val_loss: 0.4661 - val_accuracy: 0.8431\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4021 - accuracy: 0.8537 - val_loss: 0.4276 - val_accuracy: 0.8622\n",
      "Epoch 116/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3763 - accuracy: 0.8523 - val_loss: 0.4678 - val_accuracy: 0.8504\n",
      "Epoch 117/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3687 - accuracy: 0.8658 - val_loss: 0.4100 - val_accuracy: 0.8548\n",
      "Epoch 118/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3336 - accuracy: 0.8673 - val_loss: 0.4290 - val_accuracy: 0.8563\n",
      "Epoch 119/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3372 - accuracy: 0.8680 - val_loss: 0.4198 - val_accuracy: 0.8504\n",
      "Epoch 120/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3373 - accuracy: 0.8768 - val_loss: 0.8556 - val_accuracy: 0.7654\n",
      "Epoch 121/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3374 - accuracy: 0.8757 - val_loss: 0.3745 - val_accuracy: 0.8622\n",
      "Epoch 122/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3494 - accuracy: 0.8680 - val_loss: 0.4875 - val_accuracy: 0.8372\n",
      "Epoch 123/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3501 - accuracy: 0.8680 - val_loss: 0.4194 - val_accuracy: 0.8490\n",
      "Epoch 124/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3388 - accuracy: 0.8805 - val_loss: 0.4256 - val_accuracy: 0.8534\n",
      "Epoch 125/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3534 - accuracy: 0.8699 - val_loss: 1.4361 - val_accuracy: 0.6701\n",
      "Epoch 126/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3295 - accuracy: 0.8812 - val_loss: 0.3830 - val_accuracy: 0.8636\n",
      "Epoch 127/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3319 - accuracy: 0.8761 - val_loss: 0.4164 - val_accuracy: 0.8431\n",
      "Epoch 128/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3223 - accuracy: 0.8820 - val_loss: 1.0552 - val_accuracy: 0.7581\n",
      "Epoch 129/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3368 - accuracy: 0.8790 - val_loss: 0.5107 - val_accuracy: 0.8328\n",
      "Epoch 130/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3136 - accuracy: 0.8900 - val_loss: 2.4601 - val_accuracy: 0.5440\n",
      "Epoch 131/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3199 - accuracy: 0.8805 - val_loss: 1.1088 - val_accuracy: 0.7243\n",
      "Epoch 132/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3332 - accuracy: 0.8801 - val_loss: 0.4433 - val_accuracy: 0.8622\n",
      "Epoch 133/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3058 - accuracy: 0.8882 - val_loss: 0.3826 - val_accuracy: 0.8534\n",
      "Epoch 134/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3222 - accuracy: 0.8805 - val_loss: 0.4234 - val_accuracy: 0.8475\n",
      "Epoch 135/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3256 - accuracy: 0.8812 - val_loss: 0.3957 - val_accuracy: 0.8651\n",
      "Epoch 136/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3094 - accuracy: 0.8904 - val_loss: 0.3803 - val_accuracy: 0.8578\n",
      "Epoch 137/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3260 - accuracy: 0.8794 - val_loss: 0.3696 - val_accuracy: 0.8680\n",
      "Epoch 138/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3084 - accuracy: 0.8798 - val_loss: 0.4168 - val_accuracy: 0.8666\n",
      "Epoch 139/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3132 - accuracy: 0.8798 - val_loss: 0.5311 - val_accuracy: 0.8314\n",
      "Epoch 140/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3014 - accuracy: 0.8878 - val_loss: 0.3817 - val_accuracy: 0.8739\n",
      "Epoch 141/300\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.2921 - accuracy: 0.8897 - val_loss: 0.5281 - val_accuracy: 0.8138\n",
      "Epoch 142/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3347 - accuracy: 0.8724 - val_loss: 0.3877 - val_accuracy: 0.8622\n",
      "Epoch 143/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3189 - accuracy: 0.8827 - val_loss: 2.3136 - val_accuracy: 0.5528\n",
      "Epoch 144/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3283 - accuracy: 0.8754 - val_loss: 0.3843 - val_accuracy: 0.8724\n",
      "Epoch 145/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3039 - accuracy: 0.8864 - val_loss: 1.5805 - val_accuracy: 0.6554\n",
      "Epoch 146/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3029 - accuracy: 0.8893 - val_loss: 0.3899 - val_accuracy: 0.8695\n",
      "Epoch 147/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3019 - accuracy: 0.8853 - val_loss: 0.3824 - val_accuracy: 0.8651\n",
      "Epoch 148/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3182 - accuracy: 0.8849 - val_loss: 0.4444 - val_accuracy: 0.8490\n",
      "Epoch 149/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3170 - accuracy: 0.8816 - val_loss: 0.7344 - val_accuracy: 0.7698\n",
      "Epoch 150/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3220 - accuracy: 0.8765 - val_loss: 0.4062 - val_accuracy: 0.8548\n",
      "Epoch 151/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8809 - val_loss: 0.3873 - val_accuracy: 0.8592\n",
      "Epoch 152/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3111 - accuracy: 0.8823 - val_loss: 0.4128 - val_accuracy: 0.8578\n",
      "Epoch 153/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2807 - accuracy: 0.9003 - val_loss: 0.3792 - val_accuracy: 0.8666\n",
      "Epoch 154/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3066 - accuracy: 0.8849 - val_loss: 0.4763 - val_accuracy: 0.8299\n",
      "Epoch 155/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2822 - accuracy: 0.8900 - val_loss: 0.3851 - val_accuracy: 0.8504\n",
      "Epoch 156/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2958 - accuracy: 0.8864 - val_loss: 0.3528 - val_accuracy: 0.8651\n",
      "Epoch 157/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2806 - accuracy: 0.8955 - val_loss: 0.4318 - val_accuracy: 0.8548\n",
      "Epoch 158/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2929 - accuracy: 0.8937 - val_loss: 0.3972 - val_accuracy: 0.8607\n",
      "Epoch 159/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3001 - accuracy: 0.8856 - val_loss: 0.3527 - val_accuracy: 0.8563\n",
      "Epoch 160/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3021 - accuracy: 0.8823 - val_loss: 0.3569 - val_accuracy: 0.8578\n",
      "Epoch 161/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3081 - accuracy: 0.8849 - val_loss: 0.4101 - val_accuracy: 0.8592\n",
      "Epoch 162/300\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.2965 - accuracy: 0.8889 - val_loss: 0.4634 - val_accuracy: 0.8358\n",
      "Epoch 163/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2927 - accuracy: 0.8871 - val_loss: 0.3657 - val_accuracy: 0.8636\n",
      "Epoch 164/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2818 - accuracy: 0.8966 - val_loss: 0.3902 - val_accuracy: 0.8636\n",
      "Epoch 165/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3013 - accuracy: 0.8827 - val_loss: 0.4222 - val_accuracy: 0.8475\n",
      "Epoch 166/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2747 - accuracy: 0.8959 - val_loss: 0.3987 - val_accuracy: 0.8739\n",
      "Epoch 167/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2848 - accuracy: 0.8904 - val_loss: 3.8473 - val_accuracy: 0.4663\n",
      "Epoch 168/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2859 - accuracy: 0.8878 - val_loss: 1.0119 - val_accuracy: 0.7522\n",
      "Epoch 169/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2731 - accuracy: 0.8966 - val_loss: 0.6244 - val_accuracy: 0.7903\n",
      "Epoch 170/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2890 - accuracy: 0.8933 - val_loss: 0.4052 - val_accuracy: 0.8460\n",
      "Epoch 171/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2621 - accuracy: 0.9025 - val_loss: 0.3818 - val_accuracy: 0.8666\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2808 - accuracy: 0.8886 - val_loss: 0.4664 - val_accuracy: 0.8475\n",
      "Epoch 173/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3059 - accuracy: 0.8827 - val_loss: 0.4196 - val_accuracy: 0.8519\n",
      "Epoch 174/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2803 - accuracy: 0.8933 - val_loss: 0.3976 - val_accuracy: 0.8607\n",
      "Epoch 175/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2866 - accuracy: 0.8988 - val_loss: 0.4315 - val_accuracy: 0.8387\n",
      "Epoch 176/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2787 - accuracy: 0.8977 - val_loss: 0.3705 - val_accuracy: 0.8519\n",
      "Epoch 177/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2891 - accuracy: 0.8893 - val_loss: 0.4814 - val_accuracy: 0.8343\n",
      "Epoch 178/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2817 - accuracy: 0.8955 - val_loss: 0.3958 - val_accuracy: 0.8622\n",
      "Epoch 179/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2726 - accuracy: 0.8981 - val_loss: 0.4528 - val_accuracy: 0.8490\n",
      "Epoch 180/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2888 - accuracy: 0.8944 - val_loss: 0.4584 - val_accuracy: 0.8299\n",
      "Epoch 181/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2791 - accuracy: 0.8944 - val_loss: 1.5897 - val_accuracy: 0.6320\n",
      "Epoch 182/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2826 - accuracy: 0.8952 - val_loss: 0.4116 - val_accuracy: 0.8651\n",
      "Epoch 183/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2789 - accuracy: 0.8944 - val_loss: 0.3728 - val_accuracy: 0.8563\n",
      "Epoch 184/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2890 - accuracy: 0.8893 - val_loss: 0.3826 - val_accuracy: 0.8651\n",
      "Epoch 185/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2844 - accuracy: 0.8908 - val_loss: 1.2445 - val_accuracy: 0.6979\n",
      "Epoch 186/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2744 - accuracy: 0.8937 - val_loss: 0.4319 - val_accuracy: 0.8519\n",
      "Epoch 187/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2787 - accuracy: 0.8944 - val_loss: 0.4292 - val_accuracy: 0.8475\n",
      "Epoch 188/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2675 - accuracy: 0.8992 - val_loss: 0.4000 - val_accuracy: 0.8534\n",
      "Epoch 189/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2677 - accuracy: 0.8889 - val_loss: 0.3787 - val_accuracy: 0.8651\n",
      "Epoch 190/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2813 - accuracy: 0.8941 - val_loss: 0.4530 - val_accuracy: 0.8416\n",
      "Epoch 191/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2807 - accuracy: 0.9003 - val_loss: 0.4706 - val_accuracy: 0.8475\n",
      "Epoch 192/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2894 - accuracy: 0.8867 - val_loss: 0.4164 - val_accuracy: 0.8548\n",
      "Epoch 193/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2723 - accuracy: 0.8963 - val_loss: 0.4113 - val_accuracy: 0.8607\n",
      "Epoch 194/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2728 - accuracy: 0.8974 - val_loss: 0.4118 - val_accuracy: 0.8680\n",
      "Epoch 195/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2616 - accuracy: 0.8966 - val_loss: 0.3949 - val_accuracy: 0.8460\n",
      "Epoch 196/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2593 - accuracy: 0.9036 - val_loss: 0.3802 - val_accuracy: 0.8680\n",
      "Epoch 197/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2595 - accuracy: 0.9040 - val_loss: 0.5162 - val_accuracy: 0.8328\n",
      "Epoch 198/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2727 - accuracy: 0.8900 - val_loss: 0.5391 - val_accuracy: 0.8138\n",
      "Epoch 199/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2584 - accuracy: 0.8992 - val_loss: 0.3517 - val_accuracy: 0.8812\n",
      "Epoch 200/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2865 - accuracy: 0.8915 - val_loss: 0.3982 - val_accuracy: 0.8724\n",
      "Epoch 201/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2732 - accuracy: 0.8985 - val_loss: 0.3774 - val_accuracy: 0.8710\n",
      "Epoch 202/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2449 - accuracy: 0.9065 - val_loss: 0.3688 - val_accuracy: 0.8710\n",
      "Epoch 203/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2894 - accuracy: 0.8944 - val_loss: 1.5614 - val_accuracy: 0.6569\n",
      "Epoch 204/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2659 - accuracy: 0.8988 - val_loss: 0.3656 - val_accuracy: 0.8739\n",
      "Epoch 205/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2560 - accuracy: 0.9025 - val_loss: 0.3851 - val_accuracy: 0.8548\n",
      "Epoch 206/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2588 - accuracy: 0.9065 - val_loss: 0.3732 - val_accuracy: 0.8607\n",
      "Epoch 207/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2604 - accuracy: 0.8996 - val_loss: 0.3974 - val_accuracy: 0.8636\n",
      "Epoch 208/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2585 - accuracy: 0.9040 - val_loss: 0.4080 - val_accuracy: 0.8548\n",
      "Epoch 209/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2607 - accuracy: 0.9003 - val_loss: 0.4170 - val_accuracy: 0.8578\n",
      "Epoch 210/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2531 - accuracy: 0.9007 - val_loss: 0.3994 - val_accuracy: 0.8636\n",
      "Epoch 211/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2624 - accuracy: 0.8988 - val_loss: 2.9691 - val_accuracy: 0.5235\n",
      "Epoch 212/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2637 - accuracy: 0.8992 - val_loss: 0.4024 - val_accuracy: 0.8490\n",
      "Epoch 213/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2553 - accuracy: 0.9076 - val_loss: 0.3821 - val_accuracy: 0.8666\n",
      "Epoch 214/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2615 - accuracy: 0.9040 - val_loss: 0.5389 - val_accuracy: 0.8240\n",
      "Epoch 215/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2746 - accuracy: 0.8904 - val_loss: 1.1374 - val_accuracy: 0.7097\n",
      "Epoch 216/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2713 - accuracy: 0.8941 - val_loss: 0.3724 - val_accuracy: 0.8695\n",
      "Epoch 217/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2649 - accuracy: 0.8999 - val_loss: 0.3913 - val_accuracy: 0.8651\n",
      "Epoch 218/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2502 - accuracy: 0.9113 - val_loss: 0.3785 - val_accuracy: 0.8739\n",
      "Epoch 219/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2429 - accuracy: 0.9076 - val_loss: 0.4337 - val_accuracy: 0.8402\n",
      "Epoch 220/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2640 - accuracy: 0.9010 - val_loss: 0.4316 - val_accuracy: 0.8431\n",
      "Epoch 221/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2719 - accuracy: 0.8926 - val_loss: 0.4141 - val_accuracy: 0.8578\n",
      "Epoch 222/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2836 - accuracy: 0.8922 - val_loss: 0.3704 - val_accuracy: 0.8812\n",
      "Epoch 223/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2662 - accuracy: 0.9025 - val_loss: 0.3722 - val_accuracy: 0.8622\n",
      "Epoch 224/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2595 - accuracy: 0.8959 - val_loss: 1.1770 - val_accuracy: 0.7097\n",
      "Epoch 225/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2614 - accuracy: 0.8970 - val_loss: 0.3829 - val_accuracy: 0.8739\n",
      "Epoch 226/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2570 - accuracy: 0.9091 - val_loss: 0.3797 - val_accuracy: 0.8519\n",
      "Epoch 227/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2468 - accuracy: 0.9069 - val_loss: 0.6493 - val_accuracy: 0.8021\n",
      "Epoch 228/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2640 - accuracy: 0.8966 - val_loss: 0.5426 - val_accuracy: 0.8255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2657 - accuracy: 0.8988 - val_loss: 0.3737 - val_accuracy: 0.8607\n",
      "Epoch 230/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2442 - accuracy: 0.9084 - val_loss: 0.3476 - val_accuracy: 0.8622\n",
      "Epoch 231/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2503 - accuracy: 0.9007 - val_loss: 0.3571 - val_accuracy: 0.8739\n",
      "Epoch 232/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2710 - accuracy: 0.8933 - val_loss: 0.3579 - val_accuracy: 0.8695\n",
      "Epoch 233/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2583 - accuracy: 0.9032 - val_loss: 0.3519 - val_accuracy: 0.8798\n",
      "Epoch 234/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2497 - accuracy: 0.9069 - val_loss: 0.4290 - val_accuracy: 0.8490\n",
      "Epoch 235/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2283 - accuracy: 0.9168 - val_loss: 0.4317 - val_accuracy: 0.8519\n",
      "Epoch 236/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2497 - accuracy: 0.9069 - val_loss: 2.3858 - val_accuracy: 0.5469\n",
      "Epoch 237/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2618 - accuracy: 0.8977 - val_loss: 0.3948 - val_accuracy: 0.8578\n",
      "Epoch 238/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2413 - accuracy: 0.9043 - val_loss: 0.5864 - val_accuracy: 0.8138\n",
      "Epoch 239/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2403 - accuracy: 0.9095 - val_loss: 0.4319 - val_accuracy: 0.8666\n",
      "Epoch 240/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2585 - accuracy: 0.9014 - val_loss: 0.5431 - val_accuracy: 0.8328\n",
      "Epoch 241/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2472 - accuracy: 0.9029 - val_loss: 0.3581 - val_accuracy: 0.8710\n",
      "Epoch 242/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2401 - accuracy: 0.9073 - val_loss: 0.4128 - val_accuracy: 0.8666\n",
      "Epoch 243/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2673 - accuracy: 0.8985 - val_loss: 0.3433 - val_accuracy: 0.8724\n",
      "Epoch 244/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2473 - accuracy: 0.9029 - val_loss: 0.3952 - val_accuracy: 0.8578\n",
      "Epoch 245/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2469 - accuracy: 0.9091 - val_loss: 0.3496 - val_accuracy: 0.8710\n",
      "Epoch 246/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2451 - accuracy: 0.9047 - val_loss: 0.3530 - val_accuracy: 0.8592\n",
      "Epoch 247/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2424 - accuracy: 0.9029 - val_loss: 0.4360 - val_accuracy: 0.8578\n",
      "Epoch 248/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2316 - accuracy: 0.9172 - val_loss: 0.3553 - val_accuracy: 0.8680\n",
      "Epoch 249/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2518 - accuracy: 0.9018 - val_loss: 0.4506 - val_accuracy: 0.8446\n",
      "Epoch 250/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2456 - accuracy: 0.9010 - val_loss: 1.7339 - val_accuracy: 0.6261\n",
      "Epoch 251/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2433 - accuracy: 0.9043 - val_loss: 0.4662 - val_accuracy: 0.8475\n",
      "Epoch 252/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2450 - accuracy: 0.9043 - val_loss: 0.3484 - val_accuracy: 0.8783\n",
      "Epoch 253/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2367 - accuracy: 0.9087 - val_loss: 0.4185 - val_accuracy: 0.8475\n",
      "Epoch 254/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2455 - accuracy: 0.9113 - val_loss: 0.6199 - val_accuracy: 0.7977\n",
      "Epoch 255/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2290 - accuracy: 0.9113 - val_loss: 0.3688 - val_accuracy: 0.8695\n",
      "Epoch 256/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2328 - accuracy: 0.9087 - val_loss: 0.4470 - val_accuracy: 0.8563\n",
      "Epoch 257/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2388 - accuracy: 0.9087 - val_loss: 0.3857 - val_accuracy: 0.8739\n",
      "Epoch 258/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2463 - accuracy: 0.9106 - val_loss: 0.3507 - val_accuracy: 0.8754\n",
      "Epoch 259/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2207 - accuracy: 0.9161 - val_loss: 0.4964 - val_accuracy: 0.8343\n",
      "Epoch 260/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2192 - accuracy: 0.9153 - val_loss: 0.5062 - val_accuracy: 0.8387\n",
      "Epoch 261/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2342 - accuracy: 0.9109 - val_loss: 0.6621 - val_accuracy: 0.8065\n",
      "Epoch 262/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2446 - accuracy: 0.9157 - val_loss: 0.4180 - val_accuracy: 0.8534\n",
      "Epoch 263/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2390 - accuracy: 0.9069 - val_loss: 0.3679 - val_accuracy: 0.8724\n",
      "Epoch 264/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2338 - accuracy: 0.9120 - val_loss: 0.3577 - val_accuracy: 0.8739\n",
      "Epoch 265/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2367 - accuracy: 0.9032 - val_loss: 0.3200 - val_accuracy: 0.8827\n",
      "Epoch 266/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2331 - accuracy: 0.9080 - val_loss: 0.3274 - val_accuracy: 0.8754\n",
      "Epoch 267/300\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2381 - accuracy: 0.9095 - val_loss: 0.3528 - val_accuracy: 0.8724\n",
      "Epoch 268/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2292 - accuracy: 0.9205 - val_loss: 0.5905 - val_accuracy: 0.8196\n",
      "Epoch 269/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2156 - accuracy: 0.9183 - val_loss: 0.5138 - val_accuracy: 0.8226\n",
      "Epoch 270/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2292 - accuracy: 0.9084 - val_loss: 0.3866 - val_accuracy: 0.8695\n",
      "Epoch 271/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2550 - accuracy: 0.9021 - val_loss: 0.3697 - val_accuracy: 0.8622\n",
      "Epoch 272/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2349 - accuracy: 0.9062 - val_loss: 0.4497 - val_accuracy: 0.8504\n",
      "Epoch 273/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2100 - accuracy: 0.9161 - val_loss: 0.3411 - val_accuracy: 0.8739\n",
      "Epoch 274/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2253 - accuracy: 0.9153 - val_loss: 0.3796 - val_accuracy: 0.8710\n",
      "Epoch 275/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2080 - accuracy: 0.9216 - val_loss: 0.3851 - val_accuracy: 0.8666\n",
      "Epoch 276/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2190 - accuracy: 0.9124 - val_loss: 0.3890 - val_accuracy: 0.8636\n",
      "Epoch 277/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2320 - accuracy: 0.9113 - val_loss: 0.4701 - val_accuracy: 0.8402\n",
      "Epoch 278/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2214 - accuracy: 0.9135 - val_loss: 0.3620 - val_accuracy: 0.8768\n",
      "Epoch 279/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2150 - accuracy: 0.9172 - val_loss: 0.3418 - val_accuracy: 0.8724\n",
      "Epoch 280/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2174 - accuracy: 0.9194 - val_loss: 0.3473 - val_accuracy: 0.8710\n",
      "Epoch 281/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9080 - val_loss: 0.3557 - val_accuracy: 0.8666\n",
      "Epoch 282/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2101 - accuracy: 0.9238 - val_loss: 0.3463 - val_accuracy: 0.8783\n",
      "Epoch 283/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2176 - accuracy: 0.9190 - val_loss: 0.4051 - val_accuracy: 0.8548\n",
      "Epoch 284/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2204 - accuracy: 0.9157 - val_loss: 0.3810 - val_accuracy: 0.8827\n",
      "Epoch 285/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2340 - accuracy: 0.9054 - val_loss: 0.3746 - val_accuracy: 0.8768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2352 - accuracy: 0.9120 - val_loss: 0.3701 - val_accuracy: 0.8651\n",
      "Epoch 287/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2144 - accuracy: 0.9223 - val_loss: 0.3534 - val_accuracy: 0.8871\n",
      "Epoch 288/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2569 - accuracy: 0.9036 - val_loss: 0.3407 - val_accuracy: 0.8856\n",
      "Epoch 289/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2214 - accuracy: 0.9095 - val_loss: 0.3962 - val_accuracy: 0.8592\n",
      "Epoch 290/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2417 - accuracy: 0.9010 - val_loss: 0.4440 - val_accuracy: 0.8504\n",
      "Epoch 291/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2296 - accuracy: 0.9109 - val_loss: 0.4244 - val_accuracy: 0.8534\n",
      "Epoch 292/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2212 - accuracy: 0.9124 - val_loss: 0.5219 - val_accuracy: 0.8255\n",
      "Epoch 293/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2349 - accuracy: 0.9091 - val_loss: 0.3736 - val_accuracy: 0.8754\n",
      "Epoch 294/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2348 - accuracy: 0.9120 - val_loss: 0.3513 - val_accuracy: 0.8739\n",
      "Epoch 295/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2497 - accuracy: 0.9032 - val_loss: 0.4927 - val_accuracy: 0.8431\n",
      "Epoch 296/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2321 - accuracy: 0.9135 - val_loss: 0.3819 - val_accuracy: 0.8695\n",
      "Epoch 297/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2044 - accuracy: 0.9205 - val_loss: 0.4009 - val_accuracy: 0.8534\n",
      "Epoch 298/300\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2222 - accuracy: 0.9164 - val_loss: 1.4521 - val_accuracy: 0.6877\n",
      "Epoch 299/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2164 - accuracy: 0.9168 - val_loss: 0.3684 - val_accuracy: 0.8739\n",
      "Epoch 300/300\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2325 - accuracy: 0.9142 - val_loss: 0.3959 - val_accuracy: 0.8695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe0b9a7fa0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# import glob\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((28, 28))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))  # Adjusted Dropout\n",
    "\n",
    "# num_classes = len(set(numerical_labels))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# # Changed optimizer to SGD\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=10,\n",
    "#     zoom_range = 0.1,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1)\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=60)\n",
    "\n",
    "\n",
    "# # Model Checkpoint\n",
    "# checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "#           epochs=300,\n",
    "#           validation_data=(X_test, y_test),\n",
    "#           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "86/86 [==============================] - 2s 13ms/step - loss: 4.3260 - accuracy: 0.0740 - val_loss: 5.4168 - val_accuracy: 0.0191\n",
      "Epoch 2/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 3.2807 - accuracy: 0.1917 - val_loss: 4.7380 - val_accuracy: 0.0337\n",
      "Epoch 3/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 2.6762 - accuracy: 0.2947 - val_loss: 4.9761 - val_accuracy: 0.0616\n",
      "Epoch 4/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 2.2643 - accuracy: 0.3592 - val_loss: 5.2895 - val_accuracy: 0.0762\n",
      "Epoch 5/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.9992 - accuracy: 0.4274 - val_loss: 4.1944 - val_accuracy: 0.1437\n",
      "Epoch 6/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.7975 - accuracy: 0.4894 - val_loss: 3.0839 - val_accuracy: 0.2771\n",
      "Epoch 7/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.6553 - accuracy: 0.5132 - val_loss: 3.2669 - val_accuracy: 0.2889\n",
      "Epoch 8/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.4984 - accuracy: 0.5502 - val_loss: 0.9477 - val_accuracy: 0.7009\n",
      "Epoch 9/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 1.3120 - accuracy: 0.5993 - val_loss: 2.3899 - val_accuracy: 0.3974\n",
      "Epoch 10/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 1.2453 - accuracy: 0.6173 - val_loss: 1.3110 - val_accuracy: 0.5909\n",
      "Epoch 11/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.2265 - accuracy: 0.6180 - val_loss: 0.8403 - val_accuracy: 0.7126\n",
      "Epoch 12/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.1244 - accuracy: 0.6536 - val_loss: 0.7587 - val_accuracy: 0.7595\n",
      "Epoch 13/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.1129 - accuracy: 0.6452 - val_loss: 1.4231 - val_accuracy: 0.5689\n",
      "Epoch 14/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.0485 - accuracy: 0.6668 - val_loss: 0.7530 - val_accuracy: 0.7566\n",
      "Epoch 15/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.9946 - accuracy: 0.6840 - val_loss: 1.1238 - val_accuracy: 0.6378\n",
      "Epoch 16/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.9745 - accuracy: 0.6891 - val_loss: 1.3401 - val_accuracy: 0.6232\n",
      "Epoch 17/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.9208 - accuracy: 0.7078 - val_loss: 3.2237 - val_accuracy: 0.3930\n",
      "Epoch 18/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8705 - accuracy: 0.7306 - val_loss: 2.1406 - val_accuracy: 0.4971\n",
      "Epoch 19/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8565 - accuracy: 0.7302 - val_loss: 0.7682 - val_accuracy: 0.7478\n",
      "Epoch 20/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8342 - accuracy: 0.7309 - val_loss: 0.8605 - val_accuracy: 0.7097\n",
      "Epoch 21/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.8179 - accuracy: 0.7339 - val_loss: 0.6968 - val_accuracy: 0.7683\n",
      "Epoch 22/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8124 - accuracy: 0.7346 - val_loss: 1.3916 - val_accuracy: 0.6129\n",
      "Epoch 23/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7465 - accuracy: 0.7489 - val_loss: 0.9581 - val_accuracy: 0.7038\n",
      "Epoch 24/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7766 - accuracy: 0.7430 - val_loss: 0.8911 - val_accuracy: 0.7126\n",
      "Epoch 25/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7749 - accuracy: 0.7430 - val_loss: 0.7886 - val_accuracy: 0.7390\n",
      "Epoch 26/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7643 - accuracy: 0.7566 - val_loss: 1.2921 - val_accuracy: 0.6232\n",
      "Epoch 27/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7196 - accuracy: 0.7636 - val_loss: 1.0930 - val_accuracy: 0.6730\n",
      "Epoch 28/2000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.7194 - accuracy: 0.7617 - val_loss: 0.4994 - val_accuracy: 0.8196\n",
      "Epoch 29/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6782 - accuracy: 0.7757 - val_loss: 1.1102 - val_accuracy: 0.6804\n",
      "Epoch 30/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6686 - accuracy: 0.7694 - val_loss: 1.7213 - val_accuracy: 0.5806\n",
      "Epoch 31/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6600 - accuracy: 0.7852 - val_loss: 0.5316 - val_accuracy: 0.8270\n",
      "Epoch 32/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6592 - accuracy: 0.7779 - val_loss: 0.6831 - val_accuracy: 0.7859\n",
      "Epoch 33/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6397 - accuracy: 0.7900 - val_loss: 0.7184 - val_accuracy: 0.7566\n",
      "Epoch 34/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7214 - accuracy: 0.7599 - val_loss: 0.7204 - val_accuracy: 0.7654\n",
      "Epoch 35/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6717 - accuracy: 0.7790 - val_loss: 0.6324 - val_accuracy: 0.7962\n",
      "Epoch 36/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6292 - accuracy: 0.7907 - val_loss: 2.4245 - val_accuracy: 0.4311\n",
      "Epoch 37/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5941 - accuracy: 0.7955 - val_loss: 1.2822 - val_accuracy: 0.6716\n",
      "Epoch 38/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6464 - accuracy: 0.7837 - val_loss: 0.9934 - val_accuracy: 0.6979\n",
      "Epoch 39/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6264 - accuracy: 0.7859 - val_loss: 0.4537 - val_accuracy: 0.8504\n",
      "Epoch 40/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5677 - accuracy: 0.8076 - val_loss: 0.6498 - val_accuracy: 0.7947\n",
      "Epoch 41/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5738 - accuracy: 0.7991 - val_loss: 0.9050 - val_accuracy: 0.7097\n",
      "Epoch 42/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5794 - accuracy: 0.8076 - val_loss: 1.6762 - val_accuracy: 0.5968\n",
      "Epoch 43/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5672 - accuracy: 0.8068 - val_loss: 0.4529 - val_accuracy: 0.8460\n",
      "Epoch 44/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5231 - accuracy: 0.8229 - val_loss: 1.5281 - val_accuracy: 0.6496\n",
      "Epoch 45/2000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.5383 - accuracy: 0.8134 - val_loss: 0.9544 - val_accuracy: 0.7126\n",
      "Epoch 46/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5281 - accuracy: 0.8163 - val_loss: 1.2530 - val_accuracy: 0.6730\n",
      "Epoch 47/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5260 - accuracy: 0.8218 - val_loss: 0.5827 - val_accuracy: 0.8196\n",
      "Epoch 48/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4792 - accuracy: 0.8350 - val_loss: 1.4284 - val_accuracy: 0.6246\n",
      "Epoch 49/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5479 - accuracy: 0.8101 - val_loss: 0.5405 - val_accuracy: 0.8167\n",
      "Epoch 50/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5394 - accuracy: 0.8079 - val_loss: 1.1363 - val_accuracy: 0.7023\n",
      "Epoch 51/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5064 - accuracy: 0.8270 - val_loss: 1.2172 - val_accuracy: 0.6950\n",
      "Epoch 52/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4992 - accuracy: 0.8317 - val_loss: 0.6887 - val_accuracy: 0.7874\n",
      "Epoch 53/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4963 - accuracy: 0.8222 - val_loss: 1.0278 - val_accuracy: 0.7023\n",
      "Epoch 54/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4964 - accuracy: 0.8240 - val_loss: 0.8325 - val_accuracy: 0.7361\n",
      "Epoch 55/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4872 - accuracy: 0.8339 - val_loss: 0.4733 - val_accuracy: 0.8358\n",
      "Epoch 56/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5006 - accuracy: 0.8270 - val_loss: 0.4176 - val_accuracy: 0.8622\n",
      "Epoch 57/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4786 - accuracy: 0.8215 - val_loss: 0.6143 - val_accuracy: 0.8035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4531 - accuracy: 0.8420 - val_loss: 0.5067 - val_accuracy: 0.8431\n",
      "Epoch 59/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4761 - accuracy: 0.8336 - val_loss: 0.5886 - val_accuracy: 0.8196\n",
      "Epoch 60/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4540 - accuracy: 0.8358 - val_loss: 0.5805 - val_accuracy: 0.8182\n",
      "Epoch 61/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4543 - accuracy: 0.8424 - val_loss: 0.5067 - val_accuracy: 0.8416\n",
      "Epoch 62/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4833 - accuracy: 0.8277 - val_loss: 0.5419 - val_accuracy: 0.8226\n",
      "Epoch 63/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4613 - accuracy: 0.8361 - val_loss: 0.7050 - val_accuracy: 0.7771\n",
      "Epoch 64/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4495 - accuracy: 0.8383 - val_loss: 0.6196 - val_accuracy: 0.7962\n",
      "Epoch 65/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4391 - accuracy: 0.8394 - val_loss: 0.5203 - val_accuracy: 0.8240\n",
      "Epoch 66/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4373 - accuracy: 0.8398 - val_loss: 0.4790 - val_accuracy: 0.8490\n",
      "Epoch 67/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4445 - accuracy: 0.8409 - val_loss: 1.4099 - val_accuracy: 0.6584\n",
      "Epoch 68/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4407 - accuracy: 0.8420 - val_loss: 0.6878 - val_accuracy: 0.7815\n",
      "Epoch 69/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4512 - accuracy: 0.8420 - val_loss: 1.4989 - val_accuracy: 0.6290\n",
      "Epoch 70/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4266 - accuracy: 0.8556 - val_loss: 0.8022 - val_accuracy: 0.7449\n",
      "Epoch 71/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4599 - accuracy: 0.8339 - val_loss: 0.4316 - val_accuracy: 0.8548\n",
      "Epoch 72/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4444 - accuracy: 0.8424 - val_loss: 0.5094 - val_accuracy: 0.8284\n",
      "Epoch 73/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4151 - accuracy: 0.8537 - val_loss: 1.3235 - val_accuracy: 0.6965\n",
      "Epoch 74/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4509 - accuracy: 0.8446 - val_loss: 0.4511 - val_accuracy: 0.8534\n",
      "Epoch 75/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4347 - accuracy: 0.8413 - val_loss: 2.7688 - val_accuracy: 0.5176\n",
      "Epoch 76/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4302 - accuracy: 0.8490 - val_loss: 1.4398 - val_accuracy: 0.6760\n",
      "Epoch 77/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4229 - accuracy: 0.8545 - val_loss: 0.5333 - val_accuracy: 0.8284\n",
      "Epoch 78/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4294 - accuracy: 0.8442 - val_loss: 0.7394 - val_accuracy: 0.7786\n",
      "Epoch 79/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4108 - accuracy: 0.8526 - val_loss: 0.5810 - val_accuracy: 0.8167\n",
      "Epoch 80/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4092 - accuracy: 0.8519 - val_loss: 0.5944 - val_accuracy: 0.8123\n",
      "Epoch 81/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4538 - accuracy: 0.8372 - val_loss: 0.4655 - val_accuracy: 0.8475\n",
      "Epoch 82/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4404 - accuracy: 0.8471 - val_loss: 0.4322 - val_accuracy: 0.8416\n",
      "Epoch 83/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4247 - accuracy: 0.8523 - val_loss: 0.5757 - val_accuracy: 0.8270\n",
      "Epoch 84/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4067 - accuracy: 0.8519 - val_loss: 1.4004 - val_accuracy: 0.6540\n",
      "Epoch 85/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4187 - accuracy: 0.8497 - val_loss: 2.2494 - val_accuracy: 0.5396\n",
      "Epoch 86/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4457 - accuracy: 0.8438 - val_loss: 1.2428 - val_accuracy: 0.6818\n",
      "Epoch 87/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4111 - accuracy: 0.8541 - val_loss: 0.6061 - val_accuracy: 0.8182\n",
      "Epoch 88/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3851 - accuracy: 0.8662 - val_loss: 1.0333 - val_accuracy: 0.7053\n",
      "Epoch 89/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4110 - accuracy: 0.8486 - val_loss: 0.8797 - val_accuracy: 0.7493\n",
      "Epoch 90/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3629 - accuracy: 0.8651 - val_loss: 0.4321 - val_accuracy: 0.8402\n",
      "Epoch 91/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3755 - accuracy: 0.8523 - val_loss: 0.4942 - val_accuracy: 0.8387\n",
      "Epoch 92/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3934 - accuracy: 0.8581 - val_loss: 0.8765 - val_accuracy: 0.7610\n",
      "Epoch 93/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3894 - accuracy: 0.8607 - val_loss: 0.4664 - val_accuracy: 0.8460\n",
      "Epoch 94/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3817 - accuracy: 0.8600 - val_loss: 0.9585 - val_accuracy: 0.7287\n",
      "Epoch 95/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3774 - accuracy: 0.8658 - val_loss: 0.4178 - val_accuracy: 0.8534\n",
      "Epoch 96/2000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3556 - accuracy: 0.8614 - val_loss: 0.7824 - val_accuracy: 0.7493\n",
      "Epoch 97/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3860 - accuracy: 0.8666 - val_loss: 0.9007 - val_accuracy: 0.7434\n",
      "Epoch 98/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3465 - accuracy: 0.8699 - val_loss: 0.8818 - val_accuracy: 0.7551\n",
      "Epoch 99/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3730 - accuracy: 0.8669 - val_loss: 0.7161 - val_accuracy: 0.7801\n",
      "Epoch 100/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3792 - accuracy: 0.8578 - val_loss: 1.7565 - val_accuracy: 0.5953\n",
      "Epoch 101/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3724 - accuracy: 0.8647 - val_loss: 2.1155 - val_accuracy: 0.5645\n",
      "Epoch 102/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3497 - accuracy: 0.8680 - val_loss: 1.1511 - val_accuracy: 0.7302\n",
      "Epoch 103/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3658 - accuracy: 0.8673 - val_loss: 0.3968 - val_accuracy: 0.8504\n",
      "Epoch 104/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3594 - accuracy: 0.8684 - val_loss: 0.7979 - val_accuracy: 0.7771\n",
      "Epoch 105/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3809 - accuracy: 0.8603 - val_loss: 0.4779 - val_accuracy: 0.8402\n",
      "Epoch 106/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3568 - accuracy: 0.8721 - val_loss: 0.4380 - val_accuracy: 0.8504\n",
      "Epoch 107/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3547 - accuracy: 0.8658 - val_loss: 0.5366 - val_accuracy: 0.8182\n",
      "Epoch 108/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3510 - accuracy: 0.8710 - val_loss: 0.5086 - val_accuracy: 0.8284\n",
      "Epoch 109/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3789 - accuracy: 0.8673 - val_loss: 0.5015 - val_accuracy: 0.8431\n",
      "Epoch 110/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3529 - accuracy: 0.8721 - val_loss: 1.2276 - val_accuracy: 0.7023\n",
      "Epoch 111/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3523 - accuracy: 0.8647 - val_loss: 0.4213 - val_accuracy: 0.8724\n",
      "Epoch 112/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3470 - accuracy: 0.8787 - val_loss: 0.5313 - val_accuracy: 0.8270\n",
      "Epoch 113/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3892 - accuracy: 0.8600 - val_loss: 0.8241 - val_accuracy: 0.7493\n",
      "Epoch 114/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3591 - accuracy: 0.8713 - val_loss: 0.7526 - val_accuracy: 0.7625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3549 - accuracy: 0.8746 - val_loss: 1.1694 - val_accuracy: 0.6979\n",
      "Epoch 116/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3294 - accuracy: 0.8779 - val_loss: 0.3866 - val_accuracy: 0.8739\n",
      "Epoch 117/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3463 - accuracy: 0.8673 - val_loss: 0.5077 - val_accuracy: 0.8152\n",
      "Epoch 118/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3234 - accuracy: 0.8823 - val_loss: 1.2731 - val_accuracy: 0.6760\n",
      "Epoch 119/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3538 - accuracy: 0.8699 - val_loss: 0.3879 - val_accuracy: 0.8651\n",
      "Epoch 120/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3334 - accuracy: 0.8779 - val_loss: 0.4609 - val_accuracy: 0.8387\n",
      "Epoch 121/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3146 - accuracy: 0.8805 - val_loss: 0.3694 - val_accuracy: 0.8783\n",
      "Epoch 122/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3338 - accuracy: 0.8754 - val_loss: 0.6475 - val_accuracy: 0.8226\n",
      "Epoch 123/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3219 - accuracy: 0.8787 - val_loss: 0.4325 - val_accuracy: 0.8475\n",
      "Epoch 124/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3355 - accuracy: 0.8772 - val_loss: 0.6280 - val_accuracy: 0.8094\n",
      "Epoch 125/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3311 - accuracy: 0.8739 - val_loss: 0.3809 - val_accuracy: 0.8548\n",
      "Epoch 126/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3145 - accuracy: 0.8801 - val_loss: 0.4292 - val_accuracy: 0.8534\n",
      "Epoch 127/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3337 - accuracy: 0.8801 - val_loss: 0.8472 - val_accuracy: 0.7903\n",
      "Epoch 128/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3433 - accuracy: 0.8699 - val_loss: 0.8284 - val_accuracy: 0.7625\n",
      "Epoch 129/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3358 - accuracy: 0.8761 - val_loss: 0.4773 - val_accuracy: 0.8372\n",
      "Epoch 130/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3254 - accuracy: 0.8765 - val_loss: 0.4519 - val_accuracy: 0.8431\n",
      "Epoch 131/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2998 - accuracy: 0.8889 - val_loss: 0.7418 - val_accuracy: 0.7742\n",
      "Epoch 132/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3174 - accuracy: 0.8853 - val_loss: 1.1062 - val_accuracy: 0.7126\n",
      "Epoch 133/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3424 - accuracy: 0.8699 - val_loss: 0.9116 - val_accuracy: 0.7669\n",
      "Epoch 134/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3280 - accuracy: 0.8853 - val_loss: 0.5115 - val_accuracy: 0.8255\n",
      "Epoch 135/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3006 - accuracy: 0.8787 - val_loss: 0.4823 - val_accuracy: 0.8240\n",
      "Epoch 136/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3070 - accuracy: 0.8860 - val_loss: 0.3934 - val_accuracy: 0.8460\n",
      "Epoch 137/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3332 - accuracy: 0.8754 - val_loss: 0.4825 - val_accuracy: 0.8490\n",
      "Epoch 138/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3309 - accuracy: 0.8765 - val_loss: 0.3896 - val_accuracy: 0.8666\n",
      "Epoch 139/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3133 - accuracy: 0.8823 - val_loss: 0.8798 - val_accuracy: 0.7625\n",
      "Epoch 140/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3451 - accuracy: 0.8721 - val_loss: 1.6914 - val_accuracy: 0.6364\n",
      "Epoch 141/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3085 - accuracy: 0.8794 - val_loss: 0.4635 - val_accuracy: 0.8578\n",
      "Epoch 142/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2988 - accuracy: 0.8941 - val_loss: 0.4261 - val_accuracy: 0.8651\n",
      "Epoch 143/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3037 - accuracy: 0.8867 - val_loss: 0.4550 - val_accuracy: 0.8299\n",
      "Epoch 144/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3253 - accuracy: 0.8783 - val_loss: 0.6289 - val_accuracy: 0.8065\n",
      "Epoch 145/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3134 - accuracy: 0.8827 - val_loss: 0.4126 - val_accuracy: 0.8666\n",
      "Epoch 146/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3147 - accuracy: 0.8809 - val_loss: 0.4596 - val_accuracy: 0.8548\n",
      "Epoch 147/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3036 - accuracy: 0.8889 - val_loss: 0.4345 - val_accuracy: 0.8607\n",
      "Epoch 148/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3370 - accuracy: 0.8772 - val_loss: 0.4229 - val_accuracy: 0.8446\n",
      "Epoch 149/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3340 - accuracy: 0.8754 - val_loss: 0.6412 - val_accuracy: 0.8035\n",
      "Epoch 150/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2840 - accuracy: 0.8952 - val_loss: 1.9309 - val_accuracy: 0.6173\n",
      "Epoch 151/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3180 - accuracy: 0.8831 - val_loss: 0.3597 - val_accuracy: 0.8812\n",
      "Epoch 152/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2936 - accuracy: 0.8893 - val_loss: 0.3294 - val_accuracy: 0.8842\n",
      "Epoch 153/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2739 - accuracy: 0.8926 - val_loss: 0.6050 - val_accuracy: 0.8050\n",
      "Epoch 154/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3081 - accuracy: 0.8805 - val_loss: 0.4685 - val_accuracy: 0.8402\n",
      "Epoch 155/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2852 - accuracy: 0.8930 - val_loss: 0.3804 - val_accuracy: 0.8592\n",
      "Epoch 156/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2796 - accuracy: 0.8937 - val_loss: 0.6767 - val_accuracy: 0.7859\n",
      "Epoch 157/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2935 - accuracy: 0.8882 - val_loss: 0.4097 - val_accuracy: 0.8519\n",
      "Epoch 158/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3056 - accuracy: 0.8812 - val_loss: 0.4049 - val_accuracy: 0.8475\n",
      "Epoch 159/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3446 - accuracy: 0.8732 - val_loss: 0.9603 - val_accuracy: 0.7375\n",
      "Epoch 160/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3063 - accuracy: 0.8889 - val_loss: 0.3387 - val_accuracy: 0.8666\n",
      "Epoch 161/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3011 - accuracy: 0.8871 - val_loss: 0.4055 - val_accuracy: 0.8548\n",
      "Epoch 162/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2761 - accuracy: 0.8937 - val_loss: 0.4195 - val_accuracy: 0.8387\n",
      "Epoch 163/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2869 - accuracy: 0.8926 - val_loss: 0.4668 - val_accuracy: 0.8372\n",
      "Epoch 164/2000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2775 - accuracy: 0.8977 - val_loss: 0.3457 - val_accuracy: 0.8783\n",
      "Epoch 165/2000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2952 - accuracy: 0.8856 - val_loss: 0.4248 - val_accuracy: 0.8680\n",
      "Epoch 166/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2910 - accuracy: 0.8900 - val_loss: 0.3944 - val_accuracy: 0.8666\n",
      "Epoch 167/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2966 - accuracy: 0.8930 - val_loss: 0.6779 - val_accuracy: 0.7933\n",
      "Epoch 168/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3033 - accuracy: 0.8900 - val_loss: 0.5129 - val_accuracy: 0.8343\n",
      "Epoch 169/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3025 - accuracy: 0.8856 - val_loss: 0.9720 - val_accuracy: 0.7434\n",
      "Epoch 170/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2840 - accuracy: 0.8875 - val_loss: 0.3842 - val_accuracy: 0.8680\n",
      "Epoch 171/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2883 - accuracy: 0.8970 - val_loss: 0.5030 - val_accuracy: 0.8372\n",
      "Epoch 172/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2738 - accuracy: 0.8926 - val_loss: 0.9165 - val_accuracy: 0.7654\n",
      "Epoch 173/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3035 - accuracy: 0.8952 - val_loss: 0.4104 - val_accuracy: 0.8460\n",
      "Epoch 174/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3091 - accuracy: 0.8842 - val_loss: 0.4551 - val_accuracy: 0.8358\n",
      "Epoch 175/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3011 - accuracy: 0.8867 - val_loss: 0.3708 - val_accuracy: 0.8724\n",
      "Epoch 176/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2860 - accuracy: 0.8955 - val_loss: 0.8077 - val_accuracy: 0.7815\n",
      "Epoch 177/2000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.2945 - accuracy: 0.8842 - val_loss: 0.3669 - val_accuracy: 0.8490\n",
      "Epoch 178/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2925 - accuracy: 0.8963 - val_loss: 0.4222 - val_accuracy: 0.8578\n",
      "Epoch 179/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2689 - accuracy: 0.9018 - val_loss: 0.4203 - val_accuracy: 0.8548\n",
      "Epoch 180/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2954 - accuracy: 0.8864 - val_loss: 0.4028 - val_accuracy: 0.8592\n",
      "Epoch 181/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3007 - accuracy: 0.8886 - val_loss: 1.2933 - val_accuracy: 0.6921\n",
      "Epoch 182/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3098 - accuracy: 0.8838 - val_loss: 0.4203 - val_accuracy: 0.8724\n",
      "Epoch 183/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2858 - accuracy: 0.8966 - val_loss: 0.3920 - val_accuracy: 0.8651\n",
      "Epoch 184/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2818 - accuracy: 0.8882 - val_loss: 0.4035 - val_accuracy: 0.8607\n",
      "Epoch 185/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2486 - accuracy: 0.8999 - val_loss: 2.2587 - val_accuracy: 0.5748\n",
      "Epoch 186/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2988 - accuracy: 0.8823 - val_loss: 0.5138 - val_accuracy: 0.8270\n",
      "Epoch 187/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2776 - accuracy: 0.8952 - val_loss: 0.3945 - val_accuracy: 0.8695\n",
      "Epoch 188/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2617 - accuracy: 0.8999 - val_loss: 0.3819 - val_accuracy: 0.8651\n",
      "Epoch 189/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2849 - accuracy: 0.8926 - val_loss: 0.3652 - val_accuracy: 0.8710\n",
      "Epoch 190/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2821 - accuracy: 0.8952 - val_loss: 0.3549 - val_accuracy: 0.8783\n",
      "Epoch 191/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2698 - accuracy: 0.8981 - val_loss: 0.3582 - val_accuracy: 0.8710\n",
      "Epoch 192/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2611 - accuracy: 0.9036 - val_loss: 0.3412 - val_accuracy: 0.8695\n",
      "Epoch 193/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2679 - accuracy: 0.8955 - val_loss: 1.9668 - val_accuracy: 0.6041\n",
      "Epoch 194/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2884 - accuracy: 0.8937 - val_loss: 0.3892 - val_accuracy: 0.8563\n",
      "Epoch 195/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2807 - accuracy: 0.8970 - val_loss: 0.3467 - val_accuracy: 0.8798\n",
      "Epoch 196/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2554 - accuracy: 0.9014 - val_loss: 0.4915 - val_accuracy: 0.8226\n",
      "Epoch 197/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2615 - accuracy: 0.9069 - val_loss: 0.3807 - val_accuracy: 0.8578\n",
      "Epoch 198/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2767 - accuracy: 0.8933 - val_loss: 1.2586 - val_accuracy: 0.6935\n",
      "Epoch 199/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2735 - accuracy: 0.8937 - val_loss: 1.5651 - val_accuracy: 0.6598\n",
      "Epoch 200/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2712 - accuracy: 0.8992 - val_loss: 0.5042 - val_accuracy: 0.8299\n",
      "Epoch 201/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2580 - accuracy: 0.9065 - val_loss: 0.3483 - val_accuracy: 0.8739\n",
      "Epoch 202/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2857 - accuracy: 0.8820 - val_loss: 0.4212 - val_accuracy: 0.8578\n",
      "Epoch 203/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2736 - accuracy: 0.8955 - val_loss: 0.3828 - val_accuracy: 0.8622\n",
      "Epoch 204/2000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.2785 - accuracy: 0.8933 - val_loss: 0.4143 - val_accuracy: 0.8563\n",
      "Epoch 205/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2695 - accuracy: 0.8926 - val_loss: 0.4838 - val_accuracy: 0.8343\n",
      "Epoch 206/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2960 - accuracy: 0.8838 - val_loss: 0.5275 - val_accuracy: 0.8358\n",
      "Epoch 207/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2680 - accuracy: 0.9010 - val_loss: 0.3758 - val_accuracy: 0.8724\n",
      "Epoch 208/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2733 - accuracy: 0.8996 - val_loss: 0.6247 - val_accuracy: 0.7962\n",
      "Epoch 209/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2602 - accuracy: 0.9021 - val_loss: 0.3588 - val_accuracy: 0.8680\n",
      "Epoch 210/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2785 - accuracy: 0.8941 - val_loss: 0.7989 - val_accuracy: 0.7639\n",
      "Epoch 211/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2504 - accuracy: 0.9054 - val_loss: 0.4135 - val_accuracy: 0.8460\n",
      "Epoch 212/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2532 - accuracy: 0.9021 - val_loss: 0.4210 - val_accuracy: 0.8534\n",
      "Epoch 213/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2689 - accuracy: 0.9010 - val_loss: 0.3674 - val_accuracy: 0.8739\n",
      "Epoch 214/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2572 - accuracy: 0.9047 - val_loss: 0.3898 - val_accuracy: 0.8622\n",
      "Epoch 215/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2670 - accuracy: 0.8992 - val_loss: 0.3945 - val_accuracy: 0.8622\n",
      "Epoch 216/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2643 - accuracy: 0.8999 - val_loss: 0.3593 - val_accuracy: 0.8754\n",
      "Epoch 217/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2449 - accuracy: 0.9076 - val_loss: 0.3597 - val_accuracy: 0.8724\n",
      "Epoch 218/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2751 - accuracy: 0.8974 - val_loss: 0.7778 - val_accuracy: 0.7918\n",
      "Epoch 219/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2550 - accuracy: 0.9043 - val_loss: 0.7901 - val_accuracy: 0.7786\n",
      "Epoch 220/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2700 - accuracy: 0.8996 - val_loss: 0.5165 - val_accuracy: 0.8372\n",
      "Epoch 221/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2682 - accuracy: 0.8948 - val_loss: 0.4167 - val_accuracy: 0.8666\n",
      "Epoch 222/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2548 - accuracy: 0.9051 - val_loss: 0.4167 - val_accuracy: 0.8563\n",
      "Epoch 223/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2534 - accuracy: 0.8985 - val_loss: 0.6074 - val_accuracy: 0.8138\n",
      "Epoch 224/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2827 - accuracy: 0.8937 - val_loss: 0.3548 - val_accuracy: 0.8695\n",
      "Epoch 225/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2579 - accuracy: 0.9091 - val_loss: 0.5668 - val_accuracy: 0.8211\n",
      "Epoch 226/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2756 - accuracy: 0.9003 - val_loss: 0.3702 - val_accuracy: 0.8578\n",
      "Epoch 227/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2550 - accuracy: 0.9003 - val_loss: 0.5236 - val_accuracy: 0.8284\n",
      "Epoch 228/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2781 - accuracy: 0.9014 - val_loss: 0.4119 - val_accuracy: 0.8666\n",
      "Epoch 229/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2621 - accuracy: 0.8926 - val_loss: 0.5595 - val_accuracy: 0.8255\n",
      "Epoch 230/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2485 - accuracy: 0.9087 - val_loss: 0.4481 - val_accuracy: 0.8431\n",
      "Epoch 231/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2627 - accuracy: 0.8981 - val_loss: 0.7250 - val_accuracy: 0.7845\n",
      "Epoch 232/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2630 - accuracy: 0.9025 - val_loss: 0.6405 - val_accuracy: 0.8167\n",
      "Epoch 233/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2636 - accuracy: 0.9043 - val_loss: 0.4044 - val_accuracy: 0.8636\n",
      "Epoch 234/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2396 - accuracy: 0.9073 - val_loss: 0.5752 - val_accuracy: 0.8152\n",
      "Epoch 235/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2533 - accuracy: 0.9032 - val_loss: 0.7658 - val_accuracy: 0.7742\n",
      "Epoch 236/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2597 - accuracy: 0.9069 - val_loss: 0.4393 - val_accuracy: 0.8592\n",
      "Epoch 237/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2594 - accuracy: 0.9025 - val_loss: 0.4177 - val_accuracy: 0.8636\n",
      "Epoch 238/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2529 - accuracy: 0.9058 - val_loss: 0.7942 - val_accuracy: 0.7683\n",
      "Epoch 239/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2364 - accuracy: 0.9095 - val_loss: 0.5121 - val_accuracy: 0.8387\n",
      "Epoch 240/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2504 - accuracy: 0.9010 - val_loss: 0.4295 - val_accuracy: 0.8563\n",
      "Epoch 241/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2426 - accuracy: 0.9032 - val_loss: 0.3554 - val_accuracy: 0.8783\n",
      "Epoch 242/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2358 - accuracy: 0.9080 - val_loss: 0.3988 - val_accuracy: 0.8578\n",
      "Epoch 243/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2505 - accuracy: 0.9080 - val_loss: 0.5213 - val_accuracy: 0.8284\n",
      "Epoch 244/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2340 - accuracy: 0.9153 - val_loss: 0.3704 - val_accuracy: 0.8607\n",
      "Epoch 245/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2588 - accuracy: 0.9007 - val_loss: 0.3700 - val_accuracy: 0.8592\n",
      "Epoch 246/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2645 - accuracy: 0.8941 - val_loss: 0.3552 - val_accuracy: 0.8710\n",
      "Epoch 247/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2266 - accuracy: 0.9142 - val_loss: 0.4137 - val_accuracy: 0.8534\n",
      "Epoch 248/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2301 - accuracy: 0.9117 - val_loss: 0.6283 - val_accuracy: 0.8021\n",
      "Epoch 249/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2445 - accuracy: 0.9043 - val_loss: 0.4210 - val_accuracy: 0.8622\n",
      "Epoch 250/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2276 - accuracy: 0.9153 - val_loss: 0.5224 - val_accuracy: 0.8211\n",
      "Epoch 251/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2410 - accuracy: 0.9058 - val_loss: 0.3485 - val_accuracy: 0.8827\n",
      "Epoch 252/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2339 - accuracy: 0.9102 - val_loss: 0.3731 - val_accuracy: 0.8739\n",
      "Epoch 253/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2336 - accuracy: 0.9128 - val_loss: 1.8337 - val_accuracy: 0.6452\n",
      "Epoch 254/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2396 - accuracy: 0.9047 - val_loss: 0.3888 - val_accuracy: 0.8563\n",
      "Epoch 255/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2303 - accuracy: 0.9142 - val_loss: 0.3639 - val_accuracy: 0.8724\n",
      "Epoch 256/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2329 - accuracy: 0.9120 - val_loss: 0.4753 - val_accuracy: 0.8402\n",
      "Epoch 257/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2386 - accuracy: 0.9080 - val_loss: 0.7953 - val_accuracy: 0.7830\n",
      "Epoch 258/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2404 - accuracy: 0.9062 - val_loss: 0.4054 - val_accuracy: 0.8548\n",
      "Epoch 259/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2441 - accuracy: 0.9106 - val_loss: 0.3702 - val_accuracy: 0.8710\n",
      "Epoch 260/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2374 - accuracy: 0.9109 - val_loss: 1.3179 - val_accuracy: 0.7038\n",
      "Epoch 261/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2413 - accuracy: 0.9091 - val_loss: 0.6622 - val_accuracy: 0.8021\n",
      "Epoch 262/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2362 - accuracy: 0.9142 - val_loss: 0.4758 - val_accuracy: 0.8460\n",
      "Epoch 263/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2428 - accuracy: 0.9091 - val_loss: 0.4220 - val_accuracy: 0.8563\n",
      "Epoch 264/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2360 - accuracy: 0.9036 - val_loss: 0.4597 - val_accuracy: 0.8416\n",
      "Epoch 265/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2480 - accuracy: 0.9062 - val_loss: 0.4557 - val_accuracy: 0.8490\n",
      "Epoch 266/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2357 - accuracy: 0.9131 - val_loss: 0.9975 - val_accuracy: 0.7537\n",
      "Epoch 267/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2191 - accuracy: 0.9230 - val_loss: 0.4606 - val_accuracy: 0.8460\n",
      "Epoch 268/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2199 - accuracy: 0.9139 - val_loss: 0.3627 - val_accuracy: 0.8680\n",
      "Epoch 269/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2425 - accuracy: 0.9054 - val_loss: 0.4450 - val_accuracy: 0.8475\n",
      "Epoch 270/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2321 - accuracy: 0.9139 - val_loss: 0.4362 - val_accuracy: 0.8460\n",
      "Epoch 271/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2290 - accuracy: 0.9146 - val_loss: 0.5410 - val_accuracy: 0.8270\n",
      "Epoch 272/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2277 - accuracy: 0.9113 - val_loss: 0.3799 - val_accuracy: 0.8783\n",
      "Epoch 273/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2445 - accuracy: 0.9069 - val_loss: 0.3825 - val_accuracy: 0.8592\n",
      "Epoch 274/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2216 - accuracy: 0.9142 - val_loss: 0.3637 - val_accuracy: 0.8651\n",
      "Epoch 275/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2419 - accuracy: 0.9073 - val_loss: 2.6943 - val_accuracy: 0.5367\n",
      "Epoch 276/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2349 - accuracy: 0.9095 - val_loss: 0.3862 - val_accuracy: 0.8724\n",
      "Epoch 277/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2476 - accuracy: 0.9073 - val_loss: 0.4136 - val_accuracy: 0.8578\n",
      "Epoch 278/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2233 - accuracy: 0.9091 - val_loss: 0.8909 - val_accuracy: 0.7639\n",
      "Epoch 279/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2217 - accuracy: 0.9153 - val_loss: 0.5096 - val_accuracy: 0.8328\n",
      "Epoch 280/2000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.2111 - accuracy: 0.9153 - val_loss: 0.3765 - val_accuracy: 0.8651\n",
      "Epoch 281/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2331 - accuracy: 0.9076 - val_loss: 1.2679 - val_accuracy: 0.7185\n",
      "Epoch 282/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2451 - accuracy: 0.9091 - val_loss: 0.7756 - val_accuracy: 0.7947\n",
      "Epoch 283/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2457 - accuracy: 0.9058 - val_loss: 0.3461 - val_accuracy: 0.8842\n",
      "Epoch 284/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2074 - accuracy: 0.9201 - val_loss: 0.7781 - val_accuracy: 0.7801\n",
      "Epoch 285/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2191 - accuracy: 0.9150 - val_loss: 2.6546 - val_accuracy: 0.5660\n",
      "Epoch 286/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2412 - accuracy: 0.9047 - val_loss: 1.4990 - val_accuracy: 0.6921\n",
      "Epoch 287/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2372 - accuracy: 0.9054 - val_loss: 0.4275 - val_accuracy: 0.8607\n",
      "Epoch 288/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2269 - accuracy: 0.9131 - val_loss: 0.3486 - val_accuracy: 0.8710\n",
      "Epoch 289/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2293 - accuracy: 0.9102 - val_loss: 0.4514 - val_accuracy: 0.8416\n",
      "Epoch 290/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2356 - accuracy: 0.9124 - val_loss: 0.6450 - val_accuracy: 0.8021\n",
      "Epoch 291/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2358 - accuracy: 0.9131 - val_loss: 0.3865 - val_accuracy: 0.8710\n",
      "Epoch 292/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2152 - accuracy: 0.9150 - val_loss: 0.4136 - val_accuracy: 0.8607\n",
      "Epoch 293/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2160 - accuracy: 0.9201 - val_loss: 0.3903 - val_accuracy: 0.8578\n",
      "Epoch 294/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2257 - accuracy: 0.9117 - val_loss: 0.6599 - val_accuracy: 0.8065\n",
      "Epoch 295/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2221 - accuracy: 0.9120 - val_loss: 0.3995 - val_accuracy: 0.8710\n",
      "Epoch 296/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2407 - accuracy: 0.9073 - val_loss: 0.7056 - val_accuracy: 0.7874\n",
      "Epoch 297/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2199 - accuracy: 0.9172 - val_loss: 0.4509 - val_accuracy: 0.8592\n",
      "Epoch 298/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2363 - accuracy: 0.9113 - val_loss: 0.4735 - val_accuracy: 0.8475\n",
      "Epoch 299/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2641 - accuracy: 0.8992 - val_loss: 0.3914 - val_accuracy: 0.8710\n",
      "Epoch 300/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2274 - accuracy: 0.9161 - val_loss: 0.4333 - val_accuracy: 0.8578\n",
      "Epoch 301/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2154 - accuracy: 0.9150 - val_loss: 0.3941 - val_accuracy: 0.8739\n",
      "Epoch 302/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2301 - accuracy: 0.9120 - val_loss: 0.4321 - val_accuracy: 0.8490\n",
      "Epoch 303/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2359 - accuracy: 0.9106 - val_loss: 0.3830 - val_accuracy: 0.8724\n",
      "Epoch 304/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2224 - accuracy: 0.9095 - val_loss: 0.4457 - val_accuracy: 0.8578\n",
      "Epoch 305/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2314 - accuracy: 0.9117 - val_loss: 0.4216 - val_accuracy: 0.8519\n",
      "Epoch 306/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2203 - accuracy: 0.9234 - val_loss: 0.3824 - val_accuracy: 0.8680\n",
      "Epoch 307/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2359 - accuracy: 0.9135 - val_loss: 0.3816 - val_accuracy: 0.8739\n",
      "Epoch 308/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2388 - accuracy: 0.9062 - val_loss: 0.6126 - val_accuracy: 0.8255\n",
      "Epoch 309/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2297 - accuracy: 0.9084 - val_loss: 0.3713 - val_accuracy: 0.8783\n",
      "Epoch 310/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2309 - accuracy: 0.9142 - val_loss: 0.3596 - val_accuracy: 0.8695\n",
      "Epoch 311/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2074 - accuracy: 0.9205 - val_loss: 0.4102 - val_accuracy: 0.8666\n",
      "Epoch 312/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2186 - accuracy: 0.9135 - val_loss: 0.3920 - val_accuracy: 0.8710\n",
      "Epoch 313/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9161 - val_loss: 0.4006 - val_accuracy: 0.8578\n",
      "Epoch 314/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2223 - accuracy: 0.9142 - val_loss: 0.3618 - val_accuracy: 0.8798\n",
      "Epoch 315/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2893 - accuracy: 0.8911 - val_loss: 1.0246 - val_accuracy: 0.7434\n",
      "Epoch 316/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2238 - accuracy: 0.9131 - val_loss: 0.4089 - val_accuracy: 0.8592\n",
      "Epoch 317/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2289 - accuracy: 0.9109 - val_loss: 0.5351 - val_accuracy: 0.8314\n",
      "Epoch 318/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2116 - accuracy: 0.9095 - val_loss: 0.5342 - val_accuracy: 0.8402\n",
      "Epoch 319/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2169 - accuracy: 0.9142 - val_loss: 0.4173 - val_accuracy: 0.8636\n",
      "Epoch 320/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2212 - accuracy: 0.9164 - val_loss: 0.6037 - val_accuracy: 0.8167\n",
      "Epoch 321/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2269 - accuracy: 0.9076 - val_loss: 0.5792 - val_accuracy: 0.8138\n",
      "Epoch 322/2000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2125 - accuracy: 0.9175 - val_loss: 0.3768 - val_accuracy: 0.8695\n",
      "Epoch 323/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2276 - accuracy: 0.9087 - val_loss: 0.6250 - val_accuracy: 0.8182\n",
      "Epoch 324/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2144 - accuracy: 0.9131 - val_loss: 0.3976 - val_accuracy: 0.8724\n",
      "Epoch 325/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2298 - accuracy: 0.9146 - val_loss: 0.3984 - val_accuracy: 0.8622\n",
      "Epoch 326/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2338 - accuracy: 0.9076 - val_loss: 0.4499 - val_accuracy: 0.8402\n",
      "Epoch 327/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2250 - accuracy: 0.9135 - val_loss: 0.4106 - val_accuracy: 0.8651\n",
      "Epoch 328/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2021 - accuracy: 0.9230 - val_loss: 0.5467 - val_accuracy: 0.8328\n",
      "Epoch 329/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2168 - accuracy: 0.9183 - val_loss: 0.4874 - val_accuracy: 0.8519\n",
      "Epoch 330/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9227 - val_loss: 0.4678 - val_accuracy: 0.8592\n",
      "Epoch 331/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2122 - accuracy: 0.9175 - val_loss: 0.3702 - val_accuracy: 0.8812\n",
      "Epoch 332/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2091 - accuracy: 0.9205 - val_loss: 0.3747 - val_accuracy: 0.8768\n",
      "Epoch 333/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2244 - accuracy: 0.9065 - val_loss: 0.3975 - val_accuracy: 0.8768\n",
      "Epoch 334/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2154 - accuracy: 0.9164 - val_loss: 0.4030 - val_accuracy: 0.8607\n",
      "Epoch 335/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2174 - accuracy: 0.9161 - val_loss: 0.9378 - val_accuracy: 0.7610\n",
      "Epoch 336/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2084 - accuracy: 0.9212 - val_loss: 0.3783 - val_accuracy: 0.8710\n",
      "Epoch 337/2000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2139 - accuracy: 0.9190 - val_loss: 0.3816 - val_accuracy: 0.8739\n",
      "Epoch 338/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2227 - accuracy: 0.9150 - val_loss: 0.3564 - val_accuracy: 0.8754\n",
      "Epoch 339/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2238 - accuracy: 0.9205 - val_loss: 0.4482 - val_accuracy: 0.8534\n",
      "Epoch 340/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2033 - accuracy: 0.9190 - val_loss: 0.3703 - val_accuracy: 0.8724\n",
      "Epoch 341/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2215 - accuracy: 0.9117 - val_loss: 0.4607 - val_accuracy: 0.8460\n",
      "Epoch 342/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2041 - accuracy: 0.9205 - val_loss: 0.5177 - val_accuracy: 0.8504\n",
      "Epoch 343/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2285 - accuracy: 0.9076 - val_loss: 0.4323 - val_accuracy: 0.8578\n",
      "Epoch 344/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2142 - accuracy: 0.9219 - val_loss: 0.3794 - val_accuracy: 0.8622\n",
      "Epoch 345/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2270 - accuracy: 0.9128 - val_loss: 0.3902 - val_accuracy: 0.8636\n",
      "Epoch 346/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2093 - accuracy: 0.9161 - val_loss: 0.3859 - val_accuracy: 0.8592\n",
      "Epoch 347/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2085 - accuracy: 0.9208 - val_loss: 0.4648 - val_accuracy: 0.8504\n",
      "Epoch 348/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2115 - accuracy: 0.9124 - val_loss: 0.5593 - val_accuracy: 0.8182\n",
      "Epoch 349/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9216 - val_loss: 0.4706 - val_accuracy: 0.8592\n",
      "Epoch 350/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2077 - accuracy: 0.9197 - val_loss: 1.3082 - val_accuracy: 0.6979\n",
      "Epoch 351/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2265 - accuracy: 0.9128 - val_loss: 0.3760 - val_accuracy: 0.8695\n",
      "Epoch 352/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2150 - accuracy: 0.9186 - val_loss: 0.4433 - val_accuracy: 0.8446\n",
      "Epoch 353/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2323 - accuracy: 0.9095 - val_loss: 0.8928 - val_accuracy: 0.7595\n",
      "Epoch 354/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2113 - accuracy: 0.9142 - val_loss: 0.3970 - val_accuracy: 0.8666\n",
      "Epoch 355/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2049 - accuracy: 0.9161 - val_loss: 0.3921 - val_accuracy: 0.8680\n",
      "Epoch 356/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2026 - accuracy: 0.9179 - val_loss: 0.3875 - val_accuracy: 0.8739\n",
      "Epoch 357/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2222 - accuracy: 0.9194 - val_loss: 0.3794 - val_accuracy: 0.8680\n",
      "Epoch 358/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2037 - accuracy: 0.9230 - val_loss: 0.6170 - val_accuracy: 0.8299\n",
      "Epoch 359/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2068 - accuracy: 0.9183 - val_loss: 0.6531 - val_accuracy: 0.7962\n",
      "Epoch 360/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2035 - accuracy: 0.9183 - val_loss: 0.5040 - val_accuracy: 0.8431\n",
      "Epoch 361/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2015 - accuracy: 0.9172 - val_loss: 0.7352 - val_accuracy: 0.8109\n",
      "Epoch 362/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2204 - accuracy: 0.9175 - val_loss: 0.3925 - val_accuracy: 0.8695\n",
      "Epoch 363/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2056 - accuracy: 0.9285 - val_loss: 0.6956 - val_accuracy: 0.8065\n",
      "Epoch 364/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2159 - accuracy: 0.9142 - val_loss: 0.3962 - val_accuracy: 0.8607\n",
      "Epoch 365/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2142 - accuracy: 0.9194 - val_loss: 0.7393 - val_accuracy: 0.7933\n",
      "Epoch 366/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2141 - accuracy: 0.9172 - val_loss: 0.6099 - val_accuracy: 0.8109\n",
      "Epoch 367/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2067 - accuracy: 0.9216 - val_loss: 0.5295 - val_accuracy: 0.8431\n",
      "Epoch 368/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1900 - accuracy: 0.9245 - val_loss: 0.3918 - val_accuracy: 0.8548\n",
      "Epoch 369/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2156 - accuracy: 0.9194 - val_loss: 0.4292 - val_accuracy: 0.8534\n",
      "Epoch 370/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2038 - accuracy: 0.9183 - val_loss: 2.1250 - val_accuracy: 0.6188\n",
      "Epoch 371/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2055 - accuracy: 0.9267 - val_loss: 0.4701 - val_accuracy: 0.8519\n",
      "Epoch 372/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2090 - accuracy: 0.9164 - val_loss: 0.3913 - val_accuracy: 0.8622\n",
      "Epoch 373/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2094 - accuracy: 0.9153 - val_loss: 0.6188 - val_accuracy: 0.8211\n",
      "Epoch 374/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2194 - accuracy: 0.9109 - val_loss: 0.4499 - val_accuracy: 0.8548\n",
      "Epoch 375/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1984 - accuracy: 0.9201 - val_loss: 0.4114 - val_accuracy: 0.8651\n",
      "Epoch 376/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1887 - accuracy: 0.9267 - val_loss: 0.5393 - val_accuracy: 0.8416\n",
      "Epoch 377/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2048 - accuracy: 0.9230 - val_loss: 0.3826 - val_accuracy: 0.8607\n",
      "Epoch 378/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2065 - accuracy: 0.9146 - val_loss: 0.3516 - val_accuracy: 0.8695\n",
      "Epoch 379/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1820 - accuracy: 0.9278 - val_loss: 0.7589 - val_accuracy: 0.7859\n",
      "Epoch 380/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1948 - accuracy: 0.9274 - val_loss: 0.3729 - val_accuracy: 0.8651\n",
      "Epoch 381/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2308 - accuracy: 0.9080 - val_loss: 0.3526 - val_accuracy: 0.8739\n",
      "Epoch 382/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2100 - accuracy: 0.9190 - val_loss: 0.3552 - val_accuracy: 0.8724\n",
      "Epoch 383/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1995 - accuracy: 0.9234 - val_loss: 0.4687 - val_accuracy: 0.8563\n",
      "Epoch 384/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2039 - accuracy: 0.9223 - val_loss: 0.4179 - val_accuracy: 0.8563\n",
      "Epoch 385/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2055 - accuracy: 0.9241 - val_loss: 0.3937 - val_accuracy: 0.8592\n",
      "Epoch 386/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1998 - accuracy: 0.9216 - val_loss: 0.3805 - val_accuracy: 0.8622\n",
      "Epoch 387/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2091 - accuracy: 0.9194 - val_loss: 0.3850 - val_accuracy: 0.8607\n",
      "Epoch 388/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1967 - accuracy: 0.9256 - val_loss: 1.3272 - val_accuracy: 0.7302\n",
      "Epoch 389/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1954 - accuracy: 0.9205 - val_loss: 0.4728 - val_accuracy: 0.8475\n",
      "Epoch 390/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2015 - accuracy: 0.9234 - val_loss: 0.4043 - val_accuracy: 0.8651\n",
      "Epoch 391/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2071 - accuracy: 0.9183 - val_loss: 0.3893 - val_accuracy: 0.8754\n",
      "Epoch 392/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1943 - accuracy: 0.9223 - val_loss: 0.3987 - val_accuracy: 0.8592\n",
      "Epoch 393/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2011 - accuracy: 0.9216 - val_loss: 0.8284 - val_accuracy: 0.7815\n",
      "Epoch 394/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2080 - accuracy: 0.9227 - val_loss: 0.4777 - val_accuracy: 0.8563\n",
      "Epoch 395/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1846 - accuracy: 0.9252 - val_loss: 0.3771 - val_accuracy: 0.8783\n",
      "Epoch 396/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2117 - accuracy: 0.9208 - val_loss: 0.4511 - val_accuracy: 0.8548\n",
      "Epoch 397/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9157 - val_loss: 0.4751 - val_accuracy: 0.8504\n",
      "Epoch 398/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9241 - val_loss: 0.3846 - val_accuracy: 0.8680\n",
      "Epoch 399/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2073 - accuracy: 0.9194 - val_loss: 1.1712 - val_accuracy: 0.7287\n",
      "Epoch 400/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: 0.4975 - val_accuracy: 0.8534\n",
      "Epoch 401/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1849 - accuracy: 0.9296 - val_loss: 0.4367 - val_accuracy: 0.8563\n",
      "Epoch 402/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2001 - accuracy: 0.9230 - val_loss: 0.4735 - val_accuracy: 0.8548\n",
      "Epoch 403/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1905 - accuracy: 0.9263 - val_loss: 1.5562 - val_accuracy: 0.6921\n",
      "Epoch 404/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2074 - accuracy: 0.9205 - val_loss: 0.3878 - val_accuracy: 0.8710\n",
      "Epoch 405/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2116 - accuracy: 0.9131 - val_loss: 0.4445 - val_accuracy: 0.8710\n",
      "Epoch 406/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1921 - accuracy: 0.9293 - val_loss: 0.5021 - val_accuracy: 0.8416\n",
      "Epoch 407/2000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1991 - accuracy: 0.9241 - val_loss: 0.4486 - val_accuracy: 0.8504\n",
      "Epoch 408/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2011 - accuracy: 0.9315 - val_loss: 0.5052 - val_accuracy: 0.8387\n",
      "Epoch 409/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2075 - accuracy: 0.9256 - val_loss: 1.2520 - val_accuracy: 0.7155\n",
      "Epoch 410/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1885 - accuracy: 0.9223 - val_loss: 0.5539 - val_accuracy: 0.8534\n",
      "Epoch 411/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1938 - accuracy: 0.9197 - val_loss: 0.3605 - val_accuracy: 0.8827\n",
      "Epoch 412/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2149 - accuracy: 0.9153 - val_loss: 0.4145 - val_accuracy: 0.8622\n",
      "Epoch 413/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1824 - accuracy: 0.9307 - val_loss: 0.4157 - val_accuracy: 0.8666\n",
      "Epoch 414/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2097 - accuracy: 0.9117 - val_loss: 0.8488 - val_accuracy: 0.7977\n",
      "Epoch 415/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1866 - accuracy: 0.9285 - val_loss: 0.3725 - val_accuracy: 0.8798\n",
      "Epoch 416/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1927 - accuracy: 0.9249 - val_loss: 0.3946 - val_accuracy: 0.8636\n",
      "Epoch 417/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1912 - accuracy: 0.9216 - val_loss: 0.4280 - val_accuracy: 0.8680\n",
      "Epoch 418/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2015 - accuracy: 0.9238 - val_loss: 0.4414 - val_accuracy: 0.8490\n",
      "Epoch 419/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2138 - accuracy: 0.9238 - val_loss: 0.4950 - val_accuracy: 0.8402\n",
      "Epoch 420/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2230 - accuracy: 0.9175 - val_loss: 0.4831 - val_accuracy: 0.8416\n",
      "Epoch 421/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1772 - accuracy: 0.9311 - val_loss: 0.3824 - val_accuracy: 0.8666\n",
      "Epoch 422/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1951 - accuracy: 0.9223 - val_loss: 0.4140 - val_accuracy: 0.8680\n",
      "Epoch 423/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1949 - accuracy: 0.9227 - val_loss: 0.4251 - val_accuracy: 0.8622\n",
      "Epoch 424/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1992 - accuracy: 0.9256 - val_loss: 0.4259 - val_accuracy: 0.8622\n",
      "Epoch 425/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1993 - accuracy: 0.9197 - val_loss: 0.8306 - val_accuracy: 0.7654\n",
      "Epoch 426/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1940 - accuracy: 0.9245 - val_loss: 0.5004 - val_accuracy: 0.8490\n",
      "Epoch 427/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1840 - accuracy: 0.9252 - val_loss: 0.5614 - val_accuracy: 0.8255\n",
      "Epoch 428/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1895 - accuracy: 0.9271 - val_loss: 0.3984 - val_accuracy: 0.8592\n",
      "Epoch 429/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1925 - accuracy: 0.9256 - val_loss: 0.3678 - val_accuracy: 0.8710\n",
      "Epoch 430/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1994 - accuracy: 0.9245 - val_loss: 0.4312 - val_accuracy: 0.8534\n",
      "Epoch 431/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1974 - accuracy: 0.9219 - val_loss: 0.4124 - val_accuracy: 0.8651\n",
      "Epoch 432/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1963 - accuracy: 0.9230 - val_loss: 0.4725 - val_accuracy: 0.8548\n",
      "Epoch 433/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1903 - accuracy: 0.9282 - val_loss: 0.3968 - val_accuracy: 0.8607\n",
      "Epoch 434/2000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1992 - accuracy: 0.9230 - val_loss: 0.4180 - val_accuracy: 0.8607\n",
      "Epoch 435/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1885 - accuracy: 0.9260 - val_loss: 0.3639 - val_accuracy: 0.8710\n",
      "Epoch 436/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1957 - accuracy: 0.9263 - val_loss: 0.4821 - val_accuracy: 0.8475\n",
      "Epoch 437/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1911 - accuracy: 0.9296 - val_loss: 0.7707 - val_accuracy: 0.7815\n",
      "Epoch 438/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1900 - accuracy: 0.9274 - val_loss: 0.4304 - val_accuracy: 0.8607\n",
      "Epoch 439/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2096 - accuracy: 0.9102 - val_loss: 0.4513 - val_accuracy: 0.8416\n",
      "Epoch 440/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1839 - accuracy: 0.9267 - val_loss: 0.3654 - val_accuracy: 0.8739\n",
      "Epoch 441/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1916 - accuracy: 0.9245 - val_loss: 0.3639 - val_accuracy: 0.8798\n",
      "Epoch 442/2000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1970 - accuracy: 0.9216 - val_loss: 0.3828 - val_accuracy: 0.8798\n",
      "Epoch 443/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1856 - accuracy: 0.9230 - val_loss: 0.3690 - val_accuracy: 0.8680\n",
      "Epoch 444/2000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1872 - accuracy: 0.9307 - val_loss: 0.4305 - val_accuracy: 0.8460\n",
      "Epoch 445/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1993 - accuracy: 0.9245 - val_loss: 0.4312 - val_accuracy: 0.8592\n",
      "Epoch 446/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2002 - accuracy: 0.9216 - val_loss: 0.3899 - val_accuracy: 0.8680\n",
      "Epoch 447/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1998 - accuracy: 0.9227 - val_loss: 0.5343 - val_accuracy: 0.8240\n",
      "Epoch 448/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1957 - accuracy: 0.9230 - val_loss: 0.4124 - val_accuracy: 0.8519\n",
      "Epoch 449/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1814 - accuracy: 0.9296 - val_loss: 0.3707 - val_accuracy: 0.8695\n",
      "Epoch 450/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2068 - accuracy: 0.9183 - val_loss: 0.3751 - val_accuracy: 0.8827\n",
      "Epoch 451/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1796 - accuracy: 0.9307 - val_loss: 0.4547 - val_accuracy: 0.8534\n",
      "Epoch 452/2000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2087 - accuracy: 0.9146 - val_loss: 0.3703 - val_accuracy: 0.8695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe190f5180>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# import glob\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((28, 28))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))  # Adjusted Dropout\n",
    "\n",
    "# num_classes = len(set(numerical_labels))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# # Changed optimizer to SGD\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=10,\n",
    "#     zoom_range = 0.1,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1)\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=300)\n",
    "\n",
    "\n",
    "# # Model Checkpoint\n",
    "# checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "#           epochs=2000,\n",
    "#           validation_data=(X_test, y_test),\n",
    "#           callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# # 86/86 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9721\n",
    "# # Train Loss: 0.06979891657829285\n",
    "# # Train Accuracy: 0.9721407890319824\n",
    "    \n",
    "# # 22/22 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8695\n",
    "# # Test Loss: 0.3703301250934601\n",
    "# # Test Accuracy: 0.8695014715194702\n",
    "# # 22/22 [==============================] - 0s 3ms/step    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7000\n",
      "86/86 [==============================] - 2s 13ms/step - loss: 4.2816 - accuracy: 0.0817 - val_loss: 4.3826 - val_accuracy: 0.0249\n",
      "Epoch 2/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 3.2055 - accuracy: 0.2012 - val_loss: 5.1543 - val_accuracy: 0.0235\n",
      "Epoch 3/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 2.5330 - accuracy: 0.3233 - val_loss: 4.3870 - val_accuracy: 0.0425\n",
      "Epoch 4/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 2.0558 - accuracy: 0.4113 - val_loss: 2.7714 - val_accuracy: 0.2918\n",
      "Epoch 5/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.7766 - accuracy: 0.4828 - val_loss: 2.8039 - val_accuracy: 0.2903\n",
      "Epoch 6/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.4997 - accuracy: 0.5583 - val_loss: 1.6759 - val_accuracy: 0.5176\n",
      "Epoch 7/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.3566 - accuracy: 0.6037 - val_loss: 2.4170 - val_accuracy: 0.3988\n",
      "Epoch 8/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.3225 - accuracy: 0.6026 - val_loss: 4.4663 - val_accuracy: 0.2713\n",
      "Epoch 9/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.2023 - accuracy: 0.6254 - val_loss: 1.2364 - val_accuracy: 0.6144\n",
      "Epoch 10/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 1.1228 - accuracy: 0.6514 - val_loss: 2.2659 - val_accuracy: 0.4296\n",
      "Epoch 11/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.0861 - accuracy: 0.6609 - val_loss: 2.5648 - val_accuracy: 0.4443\n",
      "Epoch 12/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.0229 - accuracy: 0.6844 - val_loss: 1.2135 - val_accuracy: 0.6613\n",
      "Epoch 13/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.0032 - accuracy: 0.6778 - val_loss: 0.9226 - val_accuracy: 0.7053\n",
      "Epoch 14/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.9484 - accuracy: 0.6961 - val_loss: 1.0478 - val_accuracy: 0.6598\n",
      "Epoch 15/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.9014 - accuracy: 0.7093 - val_loss: 7.8079 - val_accuracy: 0.1056\n",
      "Epoch 16/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8641 - accuracy: 0.7236 - val_loss: 1.1474 - val_accuracy: 0.6481\n",
      "Epoch 17/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8837 - accuracy: 0.7148 - val_loss: 2.3567 - val_accuracy: 0.4457\n",
      "Epoch 18/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7738 - accuracy: 0.7463 - val_loss: 1.1312 - val_accuracy: 0.6730\n",
      "Epoch 19/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7799 - accuracy: 0.7474 - val_loss: 1.1081 - val_accuracy: 0.6554\n",
      "Epoch 20/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7737 - accuracy: 0.7471 - val_loss: 0.8830 - val_accuracy: 0.7258\n",
      "Epoch 21/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7504 - accuracy: 0.7478 - val_loss: 0.7449 - val_accuracy: 0.7595\n",
      "Epoch 22/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7501 - accuracy: 0.7500 - val_loss: 2.8163 - val_accuracy: 0.4076\n",
      "Epoch 23/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7181 - accuracy: 0.7603 - val_loss: 2.6841 - val_accuracy: 0.3812\n",
      "Epoch 24/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.7368 - accuracy: 0.7507 - val_loss: 1.9153 - val_accuracy: 0.4985\n",
      "Epoch 25/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6892 - accuracy: 0.7727 - val_loss: 0.7063 - val_accuracy: 0.7757\n",
      "Epoch 26/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6593 - accuracy: 0.7786 - val_loss: 0.9659 - val_accuracy: 0.7390\n",
      "Epoch 27/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6607 - accuracy: 0.7830 - val_loss: 1.2023 - val_accuracy: 0.6774\n",
      "Epoch 28/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6751 - accuracy: 0.7804 - val_loss: 0.9853 - val_accuracy: 0.6848\n",
      "Epoch 29/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6478 - accuracy: 0.7812 - val_loss: 1.4133 - val_accuracy: 0.6144\n",
      "Epoch 30/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6566 - accuracy: 0.7837 - val_loss: 0.5670 - val_accuracy: 0.8211\n",
      "Epoch 31/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6084 - accuracy: 0.7892 - val_loss: 0.7320 - val_accuracy: 0.7669\n",
      "Epoch 32/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5784 - accuracy: 0.8065 - val_loss: 2.4857 - val_accuracy: 0.5264\n",
      "Epoch 33/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6086 - accuracy: 0.7870 - val_loss: 0.8307 - val_accuracy: 0.7375\n",
      "Epoch 34/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5689 - accuracy: 0.8072 - val_loss: 0.8519 - val_accuracy: 0.7258\n",
      "Epoch 35/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5953 - accuracy: 0.7940 - val_loss: 1.4781 - val_accuracy: 0.5953\n",
      "Epoch 36/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.5853 - accuracy: 0.8021 - val_loss: 3.3325 - val_accuracy: 0.3827\n",
      "Epoch 37/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5619 - accuracy: 0.8061 - val_loss: 0.9526 - val_accuracy: 0.7155\n",
      "Epoch 38/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5825 - accuracy: 0.8017 - val_loss: 2.9015 - val_accuracy: 0.4164\n",
      "Epoch 39/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5245 - accuracy: 0.8163 - val_loss: 1.1783 - val_accuracy: 0.6701\n",
      "Epoch 40/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5381 - accuracy: 0.8156 - val_loss: 4.7637 - val_accuracy: 0.3021\n",
      "Epoch 41/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5390 - accuracy: 0.8127 - val_loss: 1.5837 - val_accuracy: 0.5850\n",
      "Epoch 42/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5340 - accuracy: 0.8098 - val_loss: 0.5812 - val_accuracy: 0.7874\n",
      "Epoch 43/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5221 - accuracy: 0.8215 - val_loss: 0.4998 - val_accuracy: 0.8328\n",
      "Epoch 44/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5525 - accuracy: 0.8130 - val_loss: 0.5257 - val_accuracy: 0.8255\n",
      "Epoch 45/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.5259 - accuracy: 0.8204 - val_loss: 0.8461 - val_accuracy: 0.7273\n",
      "Epoch 46/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5327 - accuracy: 0.8189 - val_loss: 0.6572 - val_accuracy: 0.7918\n",
      "Epoch 47/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4903 - accuracy: 0.8336 - val_loss: 0.5954 - val_accuracy: 0.7903\n",
      "Epoch 48/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5093 - accuracy: 0.8196 - val_loss: 1.8845 - val_accuracy: 0.5293\n",
      "Epoch 49/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4826 - accuracy: 0.8288 - val_loss: 1.0606 - val_accuracy: 0.7170\n",
      "Epoch 50/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4879 - accuracy: 0.8288 - val_loss: 0.4755 - val_accuracy: 0.8343\n",
      "Epoch 51/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4525 - accuracy: 0.8383 - val_loss: 1.7099 - val_accuracy: 0.5616\n",
      "Epoch 52/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4844 - accuracy: 0.8310 - val_loss: 1.8492 - val_accuracy: 0.6144\n",
      "Epoch 53/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4590 - accuracy: 0.8409 - val_loss: 1.9928 - val_accuracy: 0.5982\n",
      "Epoch 54/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5031 - accuracy: 0.8226 - val_loss: 0.7268 - val_accuracy: 0.7493\n",
      "Epoch 55/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5041 - accuracy: 0.8251 - val_loss: 0.5291 - val_accuracy: 0.8240\n",
      "Epoch 56/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4628 - accuracy: 0.8427 - val_loss: 0.4522 - val_accuracy: 0.8328\n",
      "Epoch 57/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4472 - accuracy: 0.8383 - val_loss: 1.1636 - val_accuracy: 0.6642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.5000 - accuracy: 0.8266 - val_loss: 0.8047 - val_accuracy: 0.7463\n",
      "Epoch 59/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.5147 - accuracy: 0.8207 - val_loss: 0.6546 - val_accuracy: 0.7859\n",
      "Epoch 60/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4643 - accuracy: 0.8310 - val_loss: 0.8193 - val_accuracy: 0.7683\n",
      "Epoch 61/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4517 - accuracy: 0.8339 - val_loss: 1.9631 - val_accuracy: 0.5176\n",
      "Epoch 62/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4498 - accuracy: 0.8387 - val_loss: 0.4505 - val_accuracy: 0.8460\n",
      "Epoch 63/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4274 - accuracy: 0.8457 - val_loss: 0.9166 - val_accuracy: 0.7331\n",
      "Epoch 64/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4455 - accuracy: 0.8413 - val_loss: 1.6240 - val_accuracy: 0.5894\n",
      "Epoch 65/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4230 - accuracy: 0.8442 - val_loss: 1.7276 - val_accuracy: 0.5660\n",
      "Epoch 66/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4194 - accuracy: 0.8541 - val_loss: 0.6722 - val_accuracy: 0.7903\n",
      "Epoch 67/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4469 - accuracy: 0.8358 - val_loss: 0.4878 - val_accuracy: 0.8343\n",
      "Epoch 68/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4110 - accuracy: 0.8482 - val_loss: 0.6555 - val_accuracy: 0.7947\n",
      "Epoch 69/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4138 - accuracy: 0.8490 - val_loss: 0.5103 - val_accuracy: 0.8358\n",
      "Epoch 70/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4393 - accuracy: 0.8398 - val_loss: 0.6918 - val_accuracy: 0.7874\n",
      "Epoch 71/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4122 - accuracy: 0.8523 - val_loss: 1.1376 - val_accuracy: 0.6965\n",
      "Epoch 72/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3961 - accuracy: 0.8611 - val_loss: 1.6169 - val_accuracy: 0.6114\n",
      "Epoch 73/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4146 - accuracy: 0.8479 - val_loss: 1.0922 - val_accuracy: 0.7067\n",
      "Epoch 74/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4075 - accuracy: 0.8563 - val_loss: 0.5204 - val_accuracy: 0.8226\n",
      "Epoch 75/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3983 - accuracy: 0.8537 - val_loss: 0.4050 - val_accuracy: 0.8592\n",
      "Epoch 76/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4047 - accuracy: 0.8552 - val_loss: 2.8094 - val_accuracy: 0.4560\n",
      "Epoch 77/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4231 - accuracy: 0.8468 - val_loss: 0.4761 - val_accuracy: 0.8358\n",
      "Epoch 78/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3831 - accuracy: 0.8585 - val_loss: 0.4407 - val_accuracy: 0.8490\n",
      "Epoch 79/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4040 - accuracy: 0.8515 - val_loss: 0.8000 - val_accuracy: 0.7507\n",
      "Epoch 80/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4286 - accuracy: 0.8431 - val_loss: 2.4281 - val_accuracy: 0.5059\n",
      "Epoch 81/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4055 - accuracy: 0.8486 - val_loss: 0.4074 - val_accuracy: 0.8548\n",
      "Epoch 82/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3897 - accuracy: 0.8614 - val_loss: 0.5665 - val_accuracy: 0.8226\n",
      "Epoch 83/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3822 - accuracy: 0.8589 - val_loss: 4.3396 - val_accuracy: 0.3475\n",
      "Epoch 84/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3942 - accuracy: 0.8519 - val_loss: 1.6182 - val_accuracy: 0.6364\n",
      "Epoch 85/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3863 - accuracy: 0.8574 - val_loss: 0.6134 - val_accuracy: 0.8035\n",
      "Epoch 86/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3776 - accuracy: 0.8574 - val_loss: 1.6755 - val_accuracy: 0.6349\n",
      "Epoch 87/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3790 - accuracy: 0.8559 - val_loss: 0.7204 - val_accuracy: 0.7903\n",
      "Epoch 88/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4114 - accuracy: 0.8493 - val_loss: 1.0753 - val_accuracy: 0.6862\n",
      "Epoch 89/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3784 - accuracy: 0.8545 - val_loss: 0.4751 - val_accuracy: 0.8372\n",
      "Epoch 90/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4080 - accuracy: 0.8490 - val_loss: 0.4702 - val_accuracy: 0.8431\n",
      "Epoch 91/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3955 - accuracy: 0.8545 - val_loss: 0.4600 - val_accuracy: 0.8431\n",
      "Epoch 92/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3829 - accuracy: 0.8666 - val_loss: 0.7208 - val_accuracy: 0.7903\n",
      "Epoch 93/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3614 - accuracy: 0.8713 - val_loss: 0.4414 - val_accuracy: 0.8416\n",
      "Epoch 94/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3648 - accuracy: 0.8629 - val_loss: 0.4270 - val_accuracy: 0.8607\n",
      "Epoch 95/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3687 - accuracy: 0.8578 - val_loss: 0.5623 - val_accuracy: 0.8123\n",
      "Epoch 96/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3435 - accuracy: 0.8750 - val_loss: 2.0108 - val_accuracy: 0.5513\n",
      "Epoch 97/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3489 - accuracy: 0.8743 - val_loss: 1.0436 - val_accuracy: 0.7273\n",
      "Epoch 98/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3388 - accuracy: 0.8783 - val_loss: 0.4579 - val_accuracy: 0.8519\n",
      "Epoch 99/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3718 - accuracy: 0.8695 - val_loss: 1.6190 - val_accuracy: 0.6144\n",
      "Epoch 100/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3887 - accuracy: 0.8592 - val_loss: 1.1093 - val_accuracy: 0.6716\n",
      "Epoch 101/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3917 - accuracy: 0.8622 - val_loss: 2.6324 - val_accuracy: 0.4956\n",
      "Epoch 102/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3683 - accuracy: 0.8732 - val_loss: 1.5181 - val_accuracy: 0.6408\n",
      "Epoch 103/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3414 - accuracy: 0.8713 - val_loss: 1.8448 - val_accuracy: 0.5792\n",
      "Epoch 104/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.8750 - val_loss: 0.4778 - val_accuracy: 0.8299\n",
      "Epoch 105/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3482 - accuracy: 0.8695 - val_loss: 0.9137 - val_accuracy: 0.7493\n",
      "Epoch 106/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3559 - accuracy: 0.8713 - val_loss: 0.4634 - val_accuracy: 0.8343\n",
      "Epoch 107/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3646 - accuracy: 0.8625 - val_loss: 0.7756 - val_accuracy: 0.7771\n",
      "Epoch 108/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3490 - accuracy: 0.8673 - val_loss: 5.4853 - val_accuracy: 0.2947\n",
      "Epoch 109/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3416 - accuracy: 0.8768 - val_loss: 0.5392 - val_accuracy: 0.8328\n",
      "Epoch 110/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3399 - accuracy: 0.8754 - val_loss: 0.5500 - val_accuracy: 0.8372\n",
      "Epoch 111/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3185 - accuracy: 0.8776 - val_loss: 0.4399 - val_accuracy: 0.8460\n",
      "Epoch 112/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3572 - accuracy: 0.8647 - val_loss: 0.6821 - val_accuracy: 0.8065\n",
      "Epoch 113/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3340 - accuracy: 0.8710 - val_loss: 0.5127 - val_accuracy: 0.8240\n",
      "Epoch 114/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3360 - accuracy: 0.8750 - val_loss: 0.3682 - val_accuracy: 0.8578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3340 - accuracy: 0.8750 - val_loss: 2.0561 - val_accuracy: 0.5909\n",
      "Epoch 116/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3398 - accuracy: 0.8717 - val_loss: 0.8122 - val_accuracy: 0.7830\n",
      "Epoch 117/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3770 - accuracy: 0.8585 - val_loss: 2.0519 - val_accuracy: 0.5704\n",
      "Epoch 118/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3449 - accuracy: 0.8787 - val_loss: 2.6766 - val_accuracy: 0.4736\n",
      "Epoch 119/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3083 - accuracy: 0.8834 - val_loss: 0.4697 - val_accuracy: 0.8475\n",
      "Epoch 120/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3185 - accuracy: 0.8721 - val_loss: 0.5245 - val_accuracy: 0.8314\n",
      "Epoch 121/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3160 - accuracy: 0.8875 - val_loss: 0.7051 - val_accuracy: 0.7933\n",
      "Epoch 122/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3268 - accuracy: 0.8798 - val_loss: 1.5477 - val_accuracy: 0.6349\n",
      "Epoch 123/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3092 - accuracy: 0.8794 - val_loss: 0.5723 - val_accuracy: 0.8314\n",
      "Epoch 124/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8765 - val_loss: 0.5425 - val_accuracy: 0.8196\n",
      "Epoch 125/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3422 - accuracy: 0.8691 - val_loss: 0.4340 - val_accuracy: 0.8519\n",
      "Epoch 126/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3339 - accuracy: 0.8768 - val_loss: 0.4519 - val_accuracy: 0.8563\n",
      "Epoch 127/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3037 - accuracy: 0.8820 - val_loss: 0.8883 - val_accuracy: 0.7742\n",
      "Epoch 128/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3439 - accuracy: 0.8776 - val_loss: 2.3846 - val_accuracy: 0.5396\n",
      "Epoch 129/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3318 - accuracy: 0.8776 - val_loss: 0.4783 - val_accuracy: 0.8402\n",
      "Epoch 130/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3380 - accuracy: 0.8732 - val_loss: 1.1437 - val_accuracy: 0.7493\n",
      "Epoch 131/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3153 - accuracy: 0.8871 - val_loss: 1.4688 - val_accuracy: 0.6833\n",
      "Epoch 132/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3101 - accuracy: 0.8816 - val_loss: 0.3914 - val_accuracy: 0.8578\n",
      "Epoch 133/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2976 - accuracy: 0.8849 - val_loss: 0.3813 - val_accuracy: 0.8695\n",
      "Epoch 134/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3185 - accuracy: 0.8900 - val_loss: 1.1952 - val_accuracy: 0.7199\n",
      "Epoch 135/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3152 - accuracy: 0.8827 - val_loss: 0.4061 - val_accuracy: 0.8504\n",
      "Epoch 136/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3293 - accuracy: 0.8765 - val_loss: 0.5088 - val_accuracy: 0.8416\n",
      "Epoch 137/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2984 - accuracy: 0.8937 - val_loss: 2.0185 - val_accuracy: 0.6261\n",
      "Epoch 138/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3030 - accuracy: 0.8875 - val_loss: 0.6266 - val_accuracy: 0.8065\n",
      "Epoch 139/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3007 - accuracy: 0.8911 - val_loss: 0.4049 - val_accuracy: 0.8519\n",
      "Epoch 140/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2981 - accuracy: 0.8838 - val_loss: 0.7575 - val_accuracy: 0.7977\n",
      "Epoch 141/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3208 - accuracy: 0.8757 - val_loss: 0.4199 - val_accuracy: 0.8592\n",
      "Epoch 142/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3179 - accuracy: 0.8790 - val_loss: 0.4250 - val_accuracy: 0.8607\n",
      "Epoch 143/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3091 - accuracy: 0.8776 - val_loss: 0.4437 - val_accuracy: 0.8475\n",
      "Epoch 144/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3016 - accuracy: 0.8904 - val_loss: 0.4645 - val_accuracy: 0.8548\n",
      "Epoch 145/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2990 - accuracy: 0.8853 - val_loss: 2.1202 - val_accuracy: 0.5762\n",
      "Epoch 146/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3025 - accuracy: 0.8860 - val_loss: 0.5191 - val_accuracy: 0.8123\n",
      "Epoch 147/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2995 - accuracy: 0.8893 - val_loss: 0.4175 - val_accuracy: 0.8446\n",
      "Epoch 148/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3356 - accuracy: 0.8746 - val_loss: 0.5585 - val_accuracy: 0.8196\n",
      "Epoch 149/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2937 - accuracy: 0.8842 - val_loss: 1.4030 - val_accuracy: 0.6554\n",
      "Epoch 150/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2966 - accuracy: 0.8849 - val_loss: 1.5229 - val_accuracy: 0.6598\n",
      "Epoch 151/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2847 - accuracy: 0.9003 - val_loss: 0.4935 - val_accuracy: 0.8358\n",
      "Epoch 152/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2883 - accuracy: 0.8853 - val_loss: 0.4140 - val_accuracy: 0.8548\n",
      "Epoch 153/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3080 - accuracy: 0.8864 - val_loss: 1.2855 - val_accuracy: 0.6965\n",
      "Epoch 154/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3043 - accuracy: 0.8805 - val_loss: 0.4133 - val_accuracy: 0.8563\n",
      "Epoch 155/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2845 - accuracy: 0.8944 - val_loss: 0.3742 - val_accuracy: 0.8651\n",
      "Epoch 156/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2798 - accuracy: 0.8930 - val_loss: 0.4347 - val_accuracy: 0.8431\n",
      "Epoch 157/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2844 - accuracy: 0.8959 - val_loss: 1.4572 - val_accuracy: 0.6716\n",
      "Epoch 158/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2923 - accuracy: 0.8904 - val_loss: 2.4719 - val_accuracy: 0.5616\n",
      "Epoch 159/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2671 - accuracy: 0.8988 - val_loss: 0.4287 - val_accuracy: 0.8563\n",
      "Epoch 160/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2713 - accuracy: 0.9014 - val_loss: 0.5198 - val_accuracy: 0.8358\n",
      "Epoch 161/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2728 - accuracy: 0.8955 - val_loss: 0.3991 - val_accuracy: 0.8710\n",
      "Epoch 162/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2947 - accuracy: 0.8966 - val_loss: 1.7884 - val_accuracy: 0.6466\n",
      "Epoch 163/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2890 - accuracy: 0.8915 - val_loss: 0.4012 - val_accuracy: 0.8607\n",
      "Epoch 164/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2909 - accuracy: 0.8889 - val_loss: 0.4575 - val_accuracy: 0.8372\n",
      "Epoch 165/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2770 - accuracy: 0.8974 - val_loss: 0.4005 - val_accuracy: 0.8548\n",
      "Epoch 166/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2756 - accuracy: 0.8919 - val_loss: 1.2079 - val_accuracy: 0.6950\n",
      "Epoch 167/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2668 - accuracy: 0.9051 - val_loss: 0.4745 - val_accuracy: 0.8402\n",
      "Epoch 168/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3008 - accuracy: 0.8882 - val_loss: 4.4383 - val_accuracy: 0.3871\n",
      "Epoch 169/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2828 - accuracy: 0.8904 - val_loss: 0.5583 - val_accuracy: 0.8123\n",
      "Epoch 170/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2734 - accuracy: 0.8952 - val_loss: 0.4301 - val_accuracy: 0.8519\n",
      "Epoch 171/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2655 - accuracy: 0.8985 - val_loss: 2.7513 - val_accuracy: 0.5909\n",
      "Epoch 172/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2591 - accuracy: 0.8963 - val_loss: 7.2291 - val_accuracy: 0.2551\n",
      "Epoch 173/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2930 - accuracy: 0.8955 - val_loss: 0.4377 - val_accuracy: 0.8607\n",
      "Epoch 174/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2882 - accuracy: 0.8926 - val_loss: 0.4541 - val_accuracy: 0.8490\n",
      "Epoch 175/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2775 - accuracy: 0.8893 - val_loss: 0.4252 - val_accuracy: 0.8636\n",
      "Epoch 176/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2898 - accuracy: 0.8889 - val_loss: 0.4980 - val_accuracy: 0.8387\n",
      "Epoch 177/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2841 - accuracy: 0.8871 - val_loss: 0.7823 - val_accuracy: 0.7918\n",
      "Epoch 178/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2710 - accuracy: 0.8944 - val_loss: 0.4760 - val_accuracy: 0.8431\n",
      "Epoch 179/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2656 - accuracy: 0.9021 - val_loss: 3.1584 - val_accuracy: 0.4472\n",
      "Epoch 180/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2614 - accuracy: 0.8974 - val_loss: 0.5409 - val_accuracy: 0.8138\n",
      "Epoch 181/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2840 - accuracy: 0.8922 - val_loss: 0.4428 - val_accuracy: 0.8548\n",
      "Epoch 182/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2771 - accuracy: 0.8897 - val_loss: 0.8154 - val_accuracy: 0.7786\n",
      "Epoch 183/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2761 - accuracy: 0.8919 - val_loss: 0.6123 - val_accuracy: 0.8094\n",
      "Epoch 184/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2752 - accuracy: 0.8926 - val_loss: 0.5963 - val_accuracy: 0.8079\n",
      "Epoch 185/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2637 - accuracy: 0.9029 - val_loss: 0.5138 - val_accuracy: 0.8226\n",
      "Epoch 186/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2683 - accuracy: 0.8981 - val_loss: 0.7439 - val_accuracy: 0.7859\n",
      "Epoch 187/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2445 - accuracy: 0.9087 - val_loss: 0.4400 - val_accuracy: 0.8504\n",
      "Epoch 188/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2727 - accuracy: 0.8999 - val_loss: 0.5663 - val_accuracy: 0.8372\n",
      "Epoch 189/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2511 - accuracy: 0.9021 - val_loss: 0.6811 - val_accuracy: 0.7918\n",
      "Epoch 190/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2654 - accuracy: 0.8985 - val_loss: 3.4883 - val_accuracy: 0.4355\n",
      "Epoch 191/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2533 - accuracy: 0.9014 - val_loss: 2.1592 - val_accuracy: 0.5953\n",
      "Epoch 192/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2861 - accuracy: 0.8856 - val_loss: 1.3354 - val_accuracy: 0.7082\n",
      "Epoch 193/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2820 - accuracy: 0.8897 - val_loss: 0.4185 - val_accuracy: 0.8592\n",
      "Epoch 194/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2627 - accuracy: 0.9029 - val_loss: 0.4413 - val_accuracy: 0.8636\n",
      "Epoch 195/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2715 - accuracy: 0.9007 - val_loss: 0.4346 - val_accuracy: 0.8431\n",
      "Epoch 196/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2726 - accuracy: 0.8966 - val_loss: 0.4710 - val_accuracy: 0.8490\n",
      "Epoch 197/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2587 - accuracy: 0.9014 - val_loss: 0.3993 - val_accuracy: 0.8651\n",
      "Epoch 198/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2604 - accuracy: 0.8999 - val_loss: 1.5442 - val_accuracy: 0.6554\n",
      "Epoch 199/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2794 - accuracy: 0.8959 - val_loss: 0.9069 - val_accuracy: 0.7859\n",
      "Epoch 200/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2601 - accuracy: 0.8992 - val_loss: 2.4590 - val_accuracy: 0.5938\n",
      "Epoch 201/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2564 - accuracy: 0.9036 - val_loss: 0.4751 - val_accuracy: 0.8490\n",
      "Epoch 202/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2431 - accuracy: 0.9087 - val_loss: 0.3527 - val_accuracy: 0.8871\n",
      "Epoch 203/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2533 - accuracy: 0.9007 - val_loss: 1.0217 - val_accuracy: 0.7302\n",
      "Epoch 204/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2680 - accuracy: 0.8977 - val_loss: 1.2095 - val_accuracy: 0.7214\n",
      "Epoch 205/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2702 - accuracy: 0.8970 - val_loss: 0.4023 - val_accuracy: 0.8592\n",
      "Epoch 206/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2660 - accuracy: 0.9065 - val_loss: 0.6166 - val_accuracy: 0.8240\n",
      "Epoch 207/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2709 - accuracy: 0.8970 - val_loss: 0.4431 - val_accuracy: 0.8563\n",
      "Epoch 208/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2611 - accuracy: 0.8977 - val_loss: 0.4352 - val_accuracy: 0.8548\n",
      "Epoch 209/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2671 - accuracy: 0.9021 - val_loss: 0.5240 - val_accuracy: 0.8387\n",
      "Epoch 210/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2465 - accuracy: 0.8999 - val_loss: 0.5480 - val_accuracy: 0.8255\n",
      "Epoch 211/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2562 - accuracy: 0.9047 - val_loss: 0.4836 - val_accuracy: 0.8402\n",
      "Epoch 212/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2576 - accuracy: 0.8996 - val_loss: 0.5362 - val_accuracy: 0.8460\n",
      "Epoch 213/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2363 - accuracy: 0.9098 - val_loss: 2.0642 - val_accuracy: 0.5674\n",
      "Epoch 214/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2575 - accuracy: 0.9051 - val_loss: 0.8409 - val_accuracy: 0.7918\n",
      "Epoch 215/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2528 - accuracy: 0.9054 - val_loss: 0.4123 - val_accuracy: 0.8563\n",
      "Epoch 216/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2598 - accuracy: 0.8992 - val_loss: 1.8761 - val_accuracy: 0.6378\n",
      "Epoch 217/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2581 - accuracy: 0.8981 - val_loss: 1.3820 - val_accuracy: 0.7346\n",
      "Epoch 218/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2416 - accuracy: 0.9095 - val_loss: 1.7856 - val_accuracy: 0.6261\n",
      "Epoch 219/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2593 - accuracy: 0.9065 - val_loss: 0.3557 - val_accuracy: 0.8695\n",
      "Epoch 220/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2474 - accuracy: 0.9102 - val_loss: 0.5416 - val_accuracy: 0.8416\n",
      "Epoch 221/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2367 - accuracy: 0.9084 - val_loss: 0.5512 - val_accuracy: 0.8460\n",
      "Epoch 222/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2622 - accuracy: 0.9073 - val_loss: 0.4090 - val_accuracy: 0.8695\n",
      "Epoch 223/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2578 - accuracy: 0.9032 - val_loss: 3.3701 - val_accuracy: 0.4633\n",
      "Epoch 224/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2478 - accuracy: 0.9036 - val_loss: 0.5838 - val_accuracy: 0.8255\n",
      "Epoch 225/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2579 - accuracy: 0.9029 - val_loss: 1.5372 - val_accuracy: 0.6818\n",
      "Epoch 226/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2394 - accuracy: 0.9150 - val_loss: 0.4530 - val_accuracy: 0.8651\n",
      "Epoch 227/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2243 - accuracy: 0.9161 - val_loss: 0.3937 - val_accuracy: 0.8666\n",
      "Epoch 228/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2413 - accuracy: 0.9084 - val_loss: 0.3583 - val_accuracy: 0.8724\n",
      "Epoch 229/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2711 - accuracy: 0.9010 - val_loss: 0.3798 - val_accuracy: 0.8812\n",
      "Epoch 230/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2460 - accuracy: 0.9095 - val_loss: 0.3827 - val_accuracy: 0.8636\n",
      "Epoch 231/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2440 - accuracy: 0.9120 - val_loss: 1.2970 - val_accuracy: 0.7302\n",
      "Epoch 232/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2235 - accuracy: 0.9146 - val_loss: 1.2972 - val_accuracy: 0.6950\n",
      "Epoch 233/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2488 - accuracy: 0.9010 - val_loss: 0.6157 - val_accuracy: 0.8328\n",
      "Epoch 234/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2206 - accuracy: 0.9161 - val_loss: 0.4786 - val_accuracy: 0.8446\n",
      "Epoch 235/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2373 - accuracy: 0.9128 - val_loss: 0.4516 - val_accuracy: 0.8387\n",
      "Epoch 236/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2545 - accuracy: 0.9043 - val_loss: 1.5955 - val_accuracy: 0.6510\n",
      "Epoch 237/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2212 - accuracy: 0.9135 - val_loss: 0.4981 - val_accuracy: 0.8328\n",
      "Epoch 238/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2290 - accuracy: 0.9124 - val_loss: 0.4601 - val_accuracy: 0.8548\n",
      "Epoch 239/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2359 - accuracy: 0.9051 - val_loss: 0.3975 - val_accuracy: 0.8710\n",
      "Epoch 240/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2281 - accuracy: 0.9135 - val_loss: 0.6088 - val_accuracy: 0.8314\n",
      "Epoch 241/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2396 - accuracy: 0.9139 - val_loss: 1.7032 - val_accuracy: 0.6525\n",
      "Epoch 242/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2511 - accuracy: 0.9032 - val_loss: 0.6109 - val_accuracy: 0.8255\n",
      "Epoch 243/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2240 - accuracy: 0.9131 - val_loss: 0.4719 - val_accuracy: 0.8431\n",
      "Epoch 244/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2371 - accuracy: 0.9058 - val_loss: 0.8272 - val_accuracy: 0.7903\n",
      "Epoch 245/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1935 - accuracy: 0.9326 - val_loss: 0.4895 - val_accuracy: 0.8270\n",
      "Epoch 246/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2308 - accuracy: 0.9069 - val_loss: 0.4967 - val_accuracy: 0.8387\n",
      "Epoch 247/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2375 - accuracy: 0.9102 - val_loss: 0.7302 - val_accuracy: 0.8021\n",
      "Epoch 248/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2463 - accuracy: 0.9058 - val_loss: 0.8180 - val_accuracy: 0.7625\n",
      "Epoch 249/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2404 - accuracy: 0.9095 - val_loss: 0.3899 - val_accuracy: 0.8563\n",
      "Epoch 250/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2363 - accuracy: 0.9128 - val_loss: 0.5249 - val_accuracy: 0.8460\n",
      "Epoch 251/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2673 - accuracy: 0.9047 - val_loss: 2.0283 - val_accuracy: 0.5982\n",
      "Epoch 252/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2400 - accuracy: 0.9080 - val_loss: 0.5560 - val_accuracy: 0.8167\n",
      "Epoch 253/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2567 - accuracy: 0.9040 - val_loss: 0.5369 - val_accuracy: 0.8372\n",
      "Epoch 254/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2424 - accuracy: 0.9120 - val_loss: 1.0087 - val_accuracy: 0.7713\n",
      "Epoch 255/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2188 - accuracy: 0.9168 - val_loss: 0.5984 - val_accuracy: 0.8446\n",
      "Epoch 256/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2393 - accuracy: 0.9080 - val_loss: 0.4043 - val_accuracy: 0.8666\n",
      "Epoch 257/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2336 - accuracy: 0.9047 - val_loss: 0.3767 - val_accuracy: 0.8754\n",
      "Epoch 258/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2295 - accuracy: 0.9120 - val_loss: 5.3500 - val_accuracy: 0.3680\n",
      "Epoch 259/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2288 - accuracy: 0.9113 - val_loss: 2.1870 - val_accuracy: 0.5894\n",
      "Epoch 260/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2433 - accuracy: 0.9040 - val_loss: 0.4491 - val_accuracy: 0.8504\n",
      "Epoch 261/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2299 - accuracy: 0.9164 - val_loss: 0.4482 - val_accuracy: 0.8534\n",
      "Epoch 262/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2135 - accuracy: 0.9161 - val_loss: 0.8071 - val_accuracy: 0.7815\n",
      "Epoch 263/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2301 - accuracy: 0.9146 - val_loss: 1.9665 - val_accuracy: 0.5894\n",
      "Epoch 264/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2264 - accuracy: 0.9179 - val_loss: 0.8802 - val_accuracy: 0.7845\n",
      "Epoch 265/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2339 - accuracy: 0.9076 - val_loss: 0.4458 - val_accuracy: 0.8460\n",
      "Epoch 266/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2036 - accuracy: 0.9241 - val_loss: 0.4302 - val_accuracy: 0.8592\n",
      "Epoch 267/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2516 - accuracy: 0.9029 - val_loss: 1.6700 - val_accuracy: 0.6408\n",
      "Epoch 268/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2212 - accuracy: 0.9153 - val_loss: 0.4711 - val_accuracy: 0.8548\n",
      "Epoch 269/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2086 - accuracy: 0.9131 - val_loss: 1.1539 - val_accuracy: 0.7419\n",
      "Epoch 270/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2144 - accuracy: 0.9120 - val_loss: 0.4078 - val_accuracy: 0.8622\n",
      "Epoch 271/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2123 - accuracy: 0.9227 - val_loss: 0.5179 - val_accuracy: 0.8402\n",
      "Epoch 272/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1995 - accuracy: 0.9223 - val_loss: 1.0655 - val_accuracy: 0.7698\n",
      "Epoch 273/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2403 - accuracy: 0.9091 - val_loss: 0.5340 - val_accuracy: 0.8284\n",
      "Epoch 274/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2170 - accuracy: 0.9175 - val_loss: 1.7241 - val_accuracy: 0.6261\n",
      "Epoch 275/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2485 - accuracy: 0.9014 - val_loss: 0.4162 - val_accuracy: 0.8710\n",
      "Epoch 276/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2148 - accuracy: 0.9183 - val_loss: 0.6635 - val_accuracy: 0.8240\n",
      "Epoch 277/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1994 - accuracy: 0.9172 - val_loss: 3.0258 - val_accuracy: 0.4971\n",
      "Epoch 278/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2204 - accuracy: 0.9208 - val_loss: 0.5678 - val_accuracy: 0.8387\n",
      "Epoch 279/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2354 - accuracy: 0.9084 - val_loss: 1.0183 - val_accuracy: 0.7507\n",
      "Epoch 280/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2288 - accuracy: 0.9080 - val_loss: 0.4781 - val_accuracy: 0.8372\n",
      "Epoch 281/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2293 - accuracy: 0.9146 - val_loss: 0.3974 - val_accuracy: 0.8534\n",
      "Epoch 282/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2110 - accuracy: 0.9194 - val_loss: 0.5126 - val_accuracy: 0.8431\n",
      "Epoch 283/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2164 - accuracy: 0.9128 - val_loss: 0.4969 - val_accuracy: 0.8490\n",
      "Epoch 284/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2205 - accuracy: 0.9183 - val_loss: 0.7215 - val_accuracy: 0.7977\n",
      "Epoch 285/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2152 - accuracy: 0.9186 - val_loss: 0.4899 - val_accuracy: 0.8534\n",
      "Epoch 286/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2233 - accuracy: 0.9172 - val_loss: 0.7793 - val_accuracy: 0.7889\n",
      "Epoch 287/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2362 - accuracy: 0.9128 - val_loss: 0.7908 - val_accuracy: 0.7947\n",
      "Epoch 288/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.9164 - val_loss: 0.4150 - val_accuracy: 0.8578\n",
      "Epoch 289/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2349 - accuracy: 0.9117 - val_loss: 0.4322 - val_accuracy: 0.8607\n",
      "Epoch 290/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2193 - accuracy: 0.9157 - val_loss: 0.9615 - val_accuracy: 0.7654\n",
      "Epoch 291/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2214 - accuracy: 0.9164 - val_loss: 0.4251 - val_accuracy: 0.8622\n",
      "Epoch 292/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2191 - accuracy: 0.9164 - val_loss: 0.5014 - val_accuracy: 0.8490\n",
      "Epoch 293/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2286 - accuracy: 0.9117 - val_loss: 0.4129 - val_accuracy: 0.8592\n",
      "Epoch 294/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2078 - accuracy: 0.9139 - val_loss: 0.3893 - val_accuracy: 0.8607\n",
      "Epoch 295/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2004 - accuracy: 0.9208 - val_loss: 0.3843 - val_accuracy: 0.8710\n",
      "Epoch 296/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2223 - accuracy: 0.9095 - val_loss: 0.7282 - val_accuracy: 0.8138\n",
      "Epoch 297/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2236 - accuracy: 0.9168 - val_loss: 0.5004 - val_accuracy: 0.8534\n",
      "Epoch 298/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2229 - accuracy: 0.9128 - val_loss: 0.4516 - val_accuracy: 0.8534\n",
      "Epoch 299/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2147 - accuracy: 0.9139 - val_loss: 0.3860 - val_accuracy: 0.8666\n",
      "Epoch 300/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2162 - accuracy: 0.9168 - val_loss: 0.8208 - val_accuracy: 0.7566\n",
      "Epoch 301/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2223 - accuracy: 0.9142 - val_loss: 0.4038 - val_accuracy: 0.8666\n",
      "Epoch 302/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2278 - accuracy: 0.9161 - val_loss: 0.4117 - val_accuracy: 0.8636\n",
      "Epoch 303/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1972 - accuracy: 0.9186 - val_loss: 0.4081 - val_accuracy: 0.8607\n",
      "Epoch 304/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2164 - accuracy: 0.9186 - val_loss: 0.4007 - val_accuracy: 0.8607\n",
      "Epoch 305/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2260 - accuracy: 0.9139 - val_loss: 0.8929 - val_accuracy: 0.7610\n",
      "Epoch 306/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2312 - accuracy: 0.9106 - val_loss: 0.4188 - val_accuracy: 0.8695\n",
      "Epoch 307/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2074 - accuracy: 0.9142 - val_loss: 0.6283 - val_accuracy: 0.8211\n",
      "Epoch 308/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2032 - accuracy: 0.9183 - val_loss: 0.5013 - val_accuracy: 0.8446\n",
      "Epoch 309/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2100 - accuracy: 0.9157 - val_loss: 0.4600 - val_accuracy: 0.8534\n",
      "Epoch 310/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2150 - accuracy: 0.9212 - val_loss: 0.3919 - val_accuracy: 0.8739\n",
      "Epoch 311/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2290 - accuracy: 0.9142 - val_loss: 0.4876 - val_accuracy: 0.8431\n",
      "Epoch 312/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2082 - accuracy: 0.9197 - val_loss: 0.5231 - val_accuracy: 0.8270\n",
      "Epoch 313/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2213 - accuracy: 0.9139 - val_loss: 0.3978 - val_accuracy: 0.8636\n",
      "Epoch 314/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2029 - accuracy: 0.9161 - val_loss: 0.4174 - val_accuracy: 0.8548\n",
      "Epoch 315/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2130 - accuracy: 0.9205 - val_loss: 0.5201 - val_accuracy: 0.8431\n",
      "Epoch 316/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2233 - accuracy: 0.9102 - val_loss: 1.0895 - val_accuracy: 0.7287\n",
      "Epoch 317/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1996 - accuracy: 0.9256 - val_loss: 0.3791 - val_accuracy: 0.8666\n",
      "Epoch 318/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2126 - accuracy: 0.9139 - val_loss: 0.4752 - val_accuracy: 0.8490\n",
      "Epoch 319/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2028 - accuracy: 0.9245 - val_loss: 0.3986 - val_accuracy: 0.8592\n",
      "Epoch 320/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2207 - accuracy: 0.9172 - val_loss: 1.2834 - val_accuracy: 0.7449\n",
      "Epoch 321/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2159 - accuracy: 0.9109 - val_loss: 0.4047 - val_accuracy: 0.8666\n",
      "Epoch 322/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1937 - accuracy: 0.9263 - val_loss: 0.4391 - val_accuracy: 0.8607\n",
      "Epoch 323/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2058 - accuracy: 0.9175 - val_loss: 0.4036 - val_accuracy: 0.8710\n",
      "Epoch 324/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2031 - accuracy: 0.9208 - val_loss: 0.4352 - val_accuracy: 0.8680\n",
      "Epoch 325/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1931 - accuracy: 0.9326 - val_loss: 0.5364 - val_accuracy: 0.8299\n",
      "Epoch 326/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2096 - accuracy: 0.9212 - val_loss: 0.6263 - val_accuracy: 0.8270\n",
      "Epoch 327/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1954 - accuracy: 0.9212 - val_loss: 0.4674 - val_accuracy: 0.8460\n",
      "Epoch 328/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2066 - accuracy: 0.9223 - val_loss: 0.6914 - val_accuracy: 0.8211\n",
      "Epoch 329/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2843 - accuracy: 0.8974 - val_loss: 1.2080 - val_accuracy: 0.7346\n",
      "Epoch 330/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2291 - accuracy: 0.9135 - val_loss: 0.3886 - val_accuracy: 0.8607\n",
      "Epoch 331/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2209 - accuracy: 0.9164 - val_loss: 0.4262 - val_accuracy: 0.8548\n",
      "Epoch 332/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2199 - accuracy: 0.9117 - val_loss: 0.7976 - val_accuracy: 0.7713\n",
      "Epoch 333/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2036 - accuracy: 0.9216 - val_loss: 0.4086 - val_accuracy: 0.8592\n",
      "Epoch 334/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2318 - accuracy: 0.9084 - val_loss: 0.4600 - val_accuracy: 0.8460\n",
      "Epoch 335/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2206 - accuracy: 0.9135 - val_loss: 0.4155 - val_accuracy: 0.8592\n",
      "Epoch 336/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2229 - accuracy: 0.9109 - val_loss: 1.3647 - val_accuracy: 0.7038\n",
      "Epoch 337/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2116 - accuracy: 0.9175 - val_loss: 0.5948 - val_accuracy: 0.8372\n",
      "Epoch 338/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2155 - accuracy: 0.9172 - val_loss: 1.0481 - val_accuracy: 0.7654\n",
      "Epoch 339/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1892 - accuracy: 0.9263 - val_loss: 0.3898 - val_accuracy: 0.8636\n",
      "Epoch 340/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2120 - accuracy: 0.9161 - val_loss: 0.7478 - val_accuracy: 0.8109\n",
      "Epoch 341/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2083 - accuracy: 0.9212 - val_loss: 0.3906 - val_accuracy: 0.8783\n",
      "Epoch 342/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2099 - accuracy: 0.9157 - val_loss: 4.2164 - val_accuracy: 0.4164\n",
      "Epoch 343/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2245 - accuracy: 0.9113 - val_loss: 0.5341 - val_accuracy: 0.8358\n",
      "Epoch 344/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2235 - accuracy: 0.9146 - val_loss: 0.5141 - val_accuracy: 0.8402\n",
      "Epoch 345/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2113 - accuracy: 0.9168 - val_loss: 0.3997 - val_accuracy: 0.8680\n",
      "Epoch 346/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2203 - accuracy: 0.9164 - val_loss: 0.4451 - val_accuracy: 0.8548\n",
      "Epoch 347/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2035 - accuracy: 0.9245 - val_loss: 0.3776 - val_accuracy: 0.8695\n",
      "Epoch 348/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2064 - accuracy: 0.9168 - val_loss: 0.4730 - val_accuracy: 0.8607\n",
      "Epoch 349/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2063 - accuracy: 0.9194 - val_loss: 0.4483 - val_accuracy: 0.8607\n",
      "Epoch 350/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1997 - accuracy: 0.9179 - val_loss: 0.4549 - val_accuracy: 0.8446\n",
      "Epoch 351/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2038 - accuracy: 0.9212 - val_loss: 0.4084 - val_accuracy: 0.8724\n",
      "Epoch 352/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2077 - accuracy: 0.9227 - val_loss: 2.3958 - val_accuracy: 0.5396\n",
      "Epoch 353/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1987 - accuracy: 0.9238 - val_loss: 0.4050 - val_accuracy: 0.8607\n",
      "Epoch 354/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2134 - accuracy: 0.9201 - val_loss: 0.4831 - val_accuracy: 0.8490\n",
      "Epoch 355/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2037 - accuracy: 0.9131 - val_loss: 0.5069 - val_accuracy: 0.8416\n",
      "Epoch 356/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2084 - accuracy: 0.9157 - val_loss: 0.4459 - val_accuracy: 0.8710\n",
      "Epoch 357/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2097 - accuracy: 0.9164 - val_loss: 0.4111 - val_accuracy: 0.8592\n",
      "Epoch 358/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2093 - accuracy: 0.9208 - val_loss: 0.4077 - val_accuracy: 0.8680\n",
      "Epoch 359/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2158 - accuracy: 0.9150 - val_loss: 0.3829 - val_accuracy: 0.8636\n",
      "Epoch 360/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2164 - accuracy: 0.9153 - val_loss: 0.7448 - val_accuracy: 0.8050\n",
      "Epoch 361/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2140 - accuracy: 0.9219 - val_loss: 0.4006 - val_accuracy: 0.8607\n",
      "Epoch 362/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2053 - accuracy: 0.9186 - val_loss: 0.4715 - val_accuracy: 0.8519\n",
      "Epoch 363/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1962 - accuracy: 0.9234 - val_loss: 0.3956 - val_accuracy: 0.8710\n",
      "Epoch 364/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2160 - accuracy: 0.9186 - val_loss: 0.3993 - val_accuracy: 0.8695\n",
      "Epoch 365/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1982 - accuracy: 0.9252 - val_loss: 0.4206 - val_accuracy: 0.8666\n",
      "Epoch 366/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1986 - accuracy: 0.9234 - val_loss: 0.4718 - val_accuracy: 0.8431\n",
      "Epoch 367/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2024 - accuracy: 0.9190 - val_loss: 0.4023 - val_accuracy: 0.8739\n",
      "Epoch 368/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2169 - accuracy: 0.9216 - val_loss: 0.3964 - val_accuracy: 0.8636\n",
      "Epoch 369/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2079 - accuracy: 0.9227 - val_loss: 0.6218 - val_accuracy: 0.8138\n",
      "Epoch 370/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2012 - accuracy: 0.9267 - val_loss: 0.7985 - val_accuracy: 0.7962\n",
      "Epoch 371/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1883 - accuracy: 0.9263 - val_loss: 1.0658 - val_accuracy: 0.7346\n",
      "Epoch 372/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1984 - accuracy: 0.9197 - val_loss: 0.5641 - val_accuracy: 0.8255\n",
      "Epoch 373/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1934 - accuracy: 0.9190 - val_loss: 0.4251 - val_accuracy: 0.8504\n",
      "Epoch 374/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1789 - accuracy: 0.9234 - val_loss: 1.1249 - val_accuracy: 0.7302\n",
      "Epoch 375/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2003 - accuracy: 0.9227 - val_loss: 0.3964 - val_accuracy: 0.8607\n",
      "Epoch 376/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1950 - accuracy: 0.9271 - val_loss: 0.5609 - val_accuracy: 0.8299\n",
      "Epoch 377/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2153 - accuracy: 0.9161 - val_loss: 0.6825 - val_accuracy: 0.8079\n",
      "Epoch 378/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1832 - accuracy: 0.9285 - val_loss: 0.4339 - val_accuracy: 0.8622\n",
      "Epoch 379/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2042 - accuracy: 0.9260 - val_loss: 0.3752 - val_accuracy: 0.8666\n",
      "Epoch 380/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2081 - accuracy: 0.9234 - val_loss: 0.5795 - val_accuracy: 0.8182\n",
      "Epoch 381/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1927 - accuracy: 0.9274 - val_loss: 0.6258 - val_accuracy: 0.8299\n",
      "Epoch 382/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2064 - accuracy: 0.9190 - val_loss: 0.5183 - val_accuracy: 0.8358\n",
      "Epoch 383/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2180 - accuracy: 0.9142 - val_loss: 0.4393 - val_accuracy: 0.8548\n",
      "Epoch 384/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1948 - accuracy: 0.9249 - val_loss: 0.4917 - val_accuracy: 0.8255\n",
      "Epoch 385/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2098 - accuracy: 0.9120 - val_loss: 0.5174 - val_accuracy: 0.8416\n",
      "Epoch 386/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2065 - accuracy: 0.9208 - val_loss: 0.4731 - val_accuracy: 0.8431\n",
      "Epoch 387/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1905 - accuracy: 0.9304 - val_loss: 0.5257 - val_accuracy: 0.8416\n",
      "Epoch 388/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9311 - val_loss: 0.4932 - val_accuracy: 0.8534\n",
      "Epoch 389/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2050 - accuracy: 0.9238 - val_loss: 0.5753 - val_accuracy: 0.8314\n",
      "Epoch 390/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2480 - accuracy: 0.9095 - val_loss: 1.5944 - val_accuracy: 0.6481\n",
      "Epoch 391/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2196 - accuracy: 0.9164 - val_loss: 0.4924 - val_accuracy: 0.8563\n",
      "Epoch 392/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2185 - accuracy: 0.9124 - val_loss: 2.3833 - val_accuracy: 0.5572\n",
      "Epoch 393/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2135 - accuracy: 0.9142 - val_loss: 0.6583 - val_accuracy: 0.8270\n",
      "Epoch 394/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2038 - accuracy: 0.9197 - val_loss: 0.4296 - val_accuracy: 0.8548\n",
      "Epoch 395/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2099 - accuracy: 0.9234 - val_loss: 0.4397 - val_accuracy: 0.8578\n",
      "Epoch 396/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1902 - accuracy: 0.9205 - val_loss: 0.6066 - val_accuracy: 0.8226\n",
      "Epoch 397/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1939 - accuracy: 0.9201 - val_loss: 0.3867 - val_accuracy: 0.8622\n",
      "Epoch 398/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2061 - accuracy: 0.9190 - val_loss: 0.4181 - val_accuracy: 0.8607\n",
      "Epoch 399/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2037 - accuracy: 0.9197 - val_loss: 0.4020 - val_accuracy: 0.8636\n",
      "Epoch 400/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1762 - accuracy: 0.9337 - val_loss: 0.4025 - val_accuracy: 0.8563\n",
      "Epoch 401/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2104 - accuracy: 0.9179 - val_loss: 0.6433 - val_accuracy: 0.8167\n",
      "Epoch 402/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1989 - accuracy: 0.9194 - val_loss: 0.6347 - val_accuracy: 0.8109\n",
      "Epoch 403/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1895 - accuracy: 0.9212 - val_loss: 0.3933 - val_accuracy: 0.8768\n",
      "Epoch 404/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1934 - accuracy: 0.9263 - val_loss: 0.4530 - val_accuracy: 0.8548\n",
      "Epoch 405/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1901 - accuracy: 0.9249 - val_loss: 0.6150 - val_accuracy: 0.8196\n",
      "Epoch 406/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2064 - accuracy: 0.9183 - val_loss: 0.4031 - val_accuracy: 0.8680\n",
      "Epoch 407/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1962 - accuracy: 0.9212 - val_loss: 0.5907 - val_accuracy: 0.8416\n",
      "Epoch 408/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2306 - accuracy: 0.9153 - val_loss: 1.0876 - val_accuracy: 0.7170\n",
      "Epoch 409/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2594 - accuracy: 0.8999 - val_loss: 0.9331 - val_accuracy: 0.7639\n",
      "Epoch 410/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2419 - accuracy: 0.9040 - val_loss: 0.4941 - val_accuracy: 0.8475\n",
      "Epoch 411/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2368 - accuracy: 0.9135 - val_loss: 0.4308 - val_accuracy: 0.8724\n",
      "Epoch 412/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2209 - accuracy: 0.9153 - val_loss: 0.4441 - val_accuracy: 0.8592\n",
      "Epoch 413/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2228 - accuracy: 0.9124 - val_loss: 0.4480 - val_accuracy: 0.8578\n",
      "Epoch 414/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2132 - accuracy: 0.9146 - val_loss: 0.5298 - val_accuracy: 0.8211\n",
      "Epoch 415/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2100 - accuracy: 0.9208 - val_loss: 0.3857 - val_accuracy: 0.8695\n",
      "Epoch 416/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2084 - accuracy: 0.9175 - val_loss: 0.5424 - val_accuracy: 0.8328\n",
      "Epoch 417/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1995 - accuracy: 0.9223 - val_loss: 0.4711 - val_accuracy: 0.8446\n",
      "Epoch 418/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1934 - accuracy: 0.9230 - val_loss: 0.3971 - val_accuracy: 0.8666\n",
      "Epoch 419/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1924 - accuracy: 0.9223 - val_loss: 0.6423 - val_accuracy: 0.8094\n",
      "Epoch 420/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1886 - accuracy: 0.9234 - val_loss: 0.3961 - val_accuracy: 0.8710\n",
      "Epoch 421/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1861 - accuracy: 0.9267 - val_loss: 0.4363 - val_accuracy: 0.8622\n",
      "Epoch 422/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2036 - accuracy: 0.9234 - val_loss: 0.3957 - val_accuracy: 0.8680\n",
      "Epoch 423/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1865 - accuracy: 0.9274 - val_loss: 0.5626 - val_accuracy: 0.8109\n",
      "Epoch 424/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1954 - accuracy: 0.9245 - val_loss: 0.4865 - val_accuracy: 0.8402\n",
      "Epoch 425/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1954 - accuracy: 0.9256 - val_loss: 0.4289 - val_accuracy: 0.8651\n",
      "Epoch 426/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2002 - accuracy: 0.9249 - val_loss: 0.3972 - val_accuracy: 0.8695\n",
      "Epoch 427/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1873 - accuracy: 0.9263 - val_loss: 0.5023 - val_accuracy: 0.8504\n",
      "Epoch 428/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1913 - accuracy: 0.9304 - val_loss: 0.6714 - val_accuracy: 0.8065\n",
      "Epoch 429/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1891 - accuracy: 0.9245 - val_loss: 0.3858 - val_accuracy: 0.8768\n",
      "Epoch 430/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2045 - accuracy: 0.9293 - val_loss: 0.4110 - val_accuracy: 0.8636\n",
      "Epoch 431/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1980 - accuracy: 0.9230 - val_loss: 0.5000 - val_accuracy: 0.8358\n",
      "Epoch 432/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2026 - accuracy: 0.9227 - val_loss: 0.4010 - val_accuracy: 0.8578\n",
      "Epoch 433/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.2004 - accuracy: 0.9260 - val_loss: 0.3918 - val_accuracy: 0.8710\n",
      "Epoch 434/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1819 - accuracy: 0.9293 - val_loss: 0.4010 - val_accuracy: 0.8636\n",
      "Epoch 435/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2087 - accuracy: 0.9190 - val_loss: 0.3884 - val_accuracy: 0.8798\n",
      "Epoch 436/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1901 - accuracy: 0.9282 - val_loss: 0.4099 - val_accuracy: 0.8724\n",
      "Epoch 437/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1801 - accuracy: 0.9271 - val_loss: 0.4196 - val_accuracy: 0.8739\n",
      "Epoch 438/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1937 - accuracy: 0.9201 - val_loss: 0.4883 - val_accuracy: 0.8519\n",
      "Epoch 439/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1963 - accuracy: 0.9260 - val_loss: 0.4116 - val_accuracy: 0.8636\n",
      "Epoch 440/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1767 - accuracy: 0.9315 - val_loss: 0.4253 - val_accuracy: 0.8578\n",
      "Epoch 441/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1753 - accuracy: 0.9282 - val_loss: 0.4615 - val_accuracy: 0.8519\n",
      "Epoch 442/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1934 - accuracy: 0.9256 - val_loss: 0.4130 - val_accuracy: 0.8592\n",
      "Epoch 443/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2011 - accuracy: 0.9190 - val_loss: 0.4398 - val_accuracy: 0.8519\n",
      "Epoch 444/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1828 - accuracy: 0.9252 - val_loss: 0.3972 - val_accuracy: 0.8768\n",
      "Epoch 445/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1883 - accuracy: 0.9282 - val_loss: 0.4124 - val_accuracy: 0.8636\n",
      "Epoch 446/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2086 - accuracy: 0.9216 - val_loss: 0.5428 - val_accuracy: 0.8196\n",
      "Epoch 447/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1958 - accuracy: 0.9227 - val_loss: 0.4269 - val_accuracy: 0.8695\n",
      "Epoch 448/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1802 - accuracy: 0.9322 - val_loss: 0.4351 - val_accuracy: 0.8534\n",
      "Epoch 449/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1727 - accuracy: 0.9271 - val_loss: 0.5383 - val_accuracy: 0.8284\n",
      "Epoch 450/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1744 - accuracy: 0.9289 - val_loss: 1.1273 - val_accuracy: 0.7581\n",
      "Epoch 451/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1756 - accuracy: 0.9278 - val_loss: 0.5557 - val_accuracy: 0.8255\n",
      "Epoch 452/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1696 - accuracy: 0.9329 - val_loss: 0.4449 - val_accuracy: 0.8592\n",
      "Epoch 453/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1718 - accuracy: 0.9315 - val_loss: 0.4123 - val_accuracy: 0.8724\n",
      "Epoch 454/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1834 - accuracy: 0.9296 - val_loss: 0.3849 - val_accuracy: 0.8695\n",
      "Epoch 455/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1965 - accuracy: 0.9227 - val_loss: 1.9485 - val_accuracy: 0.5982\n",
      "Epoch 456/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1847 - accuracy: 0.9241 - val_loss: 0.3948 - val_accuracy: 0.8622\n",
      "Epoch 457/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1866 - accuracy: 0.9267 - val_loss: 0.4760 - val_accuracy: 0.8460\n",
      "Epoch 458/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1944 - accuracy: 0.9274 - val_loss: 0.4491 - val_accuracy: 0.8563\n",
      "Epoch 459/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1852 - accuracy: 0.9282 - val_loss: 0.4901 - val_accuracy: 0.8519\n",
      "Epoch 460/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1838 - accuracy: 0.9271 - val_loss: 0.3680 - val_accuracy: 0.8827\n",
      "Epoch 461/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1960 - accuracy: 0.9300 - val_loss: 0.4001 - val_accuracy: 0.8592\n",
      "Epoch 462/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1944 - accuracy: 0.9285 - val_loss: 0.7279 - val_accuracy: 0.7889\n",
      "Epoch 463/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1724 - accuracy: 0.9362 - val_loss: 0.3765 - val_accuracy: 0.8739\n",
      "Epoch 464/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1924 - accuracy: 0.9219 - val_loss: 0.4000 - val_accuracy: 0.8666\n",
      "Epoch 465/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1820 - accuracy: 0.9293 - val_loss: 0.4999 - val_accuracy: 0.8416\n",
      "Epoch 466/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1857 - accuracy: 0.9249 - val_loss: 0.5820 - val_accuracy: 0.8314\n",
      "Epoch 467/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1854 - accuracy: 0.9274 - val_loss: 0.6124 - val_accuracy: 0.7991\n",
      "Epoch 468/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1958 - accuracy: 0.9238 - val_loss: 0.4823 - val_accuracy: 0.8519\n",
      "Epoch 469/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1824 - accuracy: 0.9267 - val_loss: 0.3861 - val_accuracy: 0.8636\n",
      "Epoch 470/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1655 - accuracy: 0.9373 - val_loss: 0.4722 - val_accuracy: 0.8592\n",
      "Epoch 471/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1850 - accuracy: 0.9223 - val_loss: 0.3817 - val_accuracy: 0.8607\n",
      "Epoch 472/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1929 - accuracy: 0.9256 - val_loss: 0.4926 - val_accuracy: 0.8284\n",
      "Epoch 473/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1815 - accuracy: 0.9289 - val_loss: 0.3674 - val_accuracy: 0.8739\n",
      "Epoch 474/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1840 - accuracy: 0.9234 - val_loss: 0.7032 - val_accuracy: 0.7991\n",
      "Epoch 475/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1791 - accuracy: 0.9304 - val_loss: 0.4308 - val_accuracy: 0.8607\n",
      "Epoch 476/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1672 - accuracy: 0.9366 - val_loss: 0.4028 - val_accuracy: 0.8651\n",
      "Epoch 477/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9304 - val_loss: 0.4875 - val_accuracy: 0.8387\n",
      "Epoch 478/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1760 - accuracy: 0.9296 - val_loss: 0.4908 - val_accuracy: 0.8431\n",
      "Epoch 479/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1808 - accuracy: 0.9285 - val_loss: 0.4702 - val_accuracy: 0.8490\n",
      "Epoch 480/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1778 - accuracy: 0.9252 - val_loss: 0.4489 - val_accuracy: 0.8592\n",
      "Epoch 481/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1817 - accuracy: 0.9260 - val_loss: 0.5655 - val_accuracy: 0.8270\n",
      "Epoch 482/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1745 - accuracy: 0.9348 - val_loss: 0.3746 - val_accuracy: 0.8666\n",
      "Epoch 483/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1884 - accuracy: 0.9260 - val_loss: 1.8888 - val_accuracy: 0.6261\n",
      "Epoch 484/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1828 - accuracy: 0.9293 - val_loss: 0.4413 - val_accuracy: 0.8607\n",
      "Epoch 485/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1839 - accuracy: 0.9249 - val_loss: 1.6020 - val_accuracy: 0.6393\n",
      "Epoch 486/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1911 - accuracy: 0.9293 - val_loss: 0.4179 - val_accuracy: 0.8651\n",
      "Epoch 487/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1740 - accuracy: 0.9263 - val_loss: 0.5498 - val_accuracy: 0.8343\n",
      "Epoch 488/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1958 - accuracy: 0.9230 - val_loss: 0.3963 - val_accuracy: 0.8651\n",
      "Epoch 489/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1889 - accuracy: 0.9230 - val_loss: 0.4325 - val_accuracy: 0.8578\n",
      "Epoch 490/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1945 - accuracy: 0.9230 - val_loss: 0.9998 - val_accuracy: 0.7757\n",
      "Epoch 491/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1643 - accuracy: 0.9322 - val_loss: 0.3921 - val_accuracy: 0.8710\n",
      "Epoch 492/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1717 - accuracy: 0.9300 - val_loss: 0.5949 - val_accuracy: 0.8328\n",
      "Epoch 493/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1704 - accuracy: 0.9322 - val_loss: 1.2367 - val_accuracy: 0.7243\n",
      "Epoch 494/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1808 - accuracy: 0.9252 - val_loss: 0.4918 - val_accuracy: 0.8490\n",
      "Epoch 495/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1791 - accuracy: 0.9318 - val_loss: 0.5755 - val_accuracy: 0.8314\n",
      "Epoch 496/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1791 - accuracy: 0.9289 - val_loss: 0.3837 - val_accuracy: 0.8827\n",
      "Epoch 497/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1827 - accuracy: 0.9274 - val_loss: 0.4366 - val_accuracy: 0.8592\n",
      "Epoch 498/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1671 - accuracy: 0.9322 - val_loss: 0.4406 - val_accuracy: 0.8534\n",
      "Epoch 499/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1816 - accuracy: 0.9307 - val_loss: 0.8193 - val_accuracy: 0.7742\n",
      "Epoch 500/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1678 - accuracy: 0.9351 - val_loss: 0.4359 - val_accuracy: 0.8548\n",
      "Epoch 501/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1723 - accuracy: 0.9351 - val_loss: 0.4139 - val_accuracy: 0.8680\n",
      "Epoch 502/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1848 - accuracy: 0.9296 - val_loss: 0.5565 - val_accuracy: 0.8328\n",
      "Epoch 503/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1731 - accuracy: 0.9282 - val_loss: 0.4136 - val_accuracy: 0.8563\n",
      "Epoch 504/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1709 - accuracy: 0.9373 - val_loss: 0.4161 - val_accuracy: 0.8724\n",
      "Epoch 505/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1823 - accuracy: 0.9296 - val_loss: 2.8785 - val_accuracy: 0.5191\n",
      "Epoch 506/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1846 - accuracy: 0.9329 - val_loss: 0.3743 - val_accuracy: 0.8783\n",
      "Epoch 507/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1891 - accuracy: 0.9238 - val_loss: 0.4252 - val_accuracy: 0.8592\n",
      "Epoch 508/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1738 - accuracy: 0.9311 - val_loss: 0.4145 - val_accuracy: 0.8651\n",
      "Epoch 509/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1731 - accuracy: 0.9315 - val_loss: 0.6425 - val_accuracy: 0.8196\n",
      "Epoch 510/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1909 - accuracy: 0.9260 - val_loss: 0.5816 - val_accuracy: 0.8182\n",
      "Epoch 511/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1892 - accuracy: 0.9329 - val_loss: 0.4093 - val_accuracy: 0.8710\n",
      "Epoch 512/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1810 - accuracy: 0.9252 - val_loss: 0.5280 - val_accuracy: 0.8460\n",
      "Epoch 513/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9282 - val_loss: 0.3830 - val_accuracy: 0.8754\n",
      "Epoch 514/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1887 - accuracy: 0.9282 - val_loss: 0.5779 - val_accuracy: 0.8358\n",
      "Epoch 515/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1916 - accuracy: 0.9230 - val_loss: 0.4919 - val_accuracy: 0.8504\n",
      "Epoch 516/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1714 - accuracy: 0.9282 - val_loss: 0.4427 - val_accuracy: 0.8578\n",
      "Epoch 517/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1691 - accuracy: 0.9315 - val_loss: 0.8394 - val_accuracy: 0.8094\n",
      "Epoch 518/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1772 - accuracy: 0.9344 - val_loss: 1.0002 - val_accuracy: 0.7566\n",
      "Epoch 519/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1860 - accuracy: 0.9285 - val_loss: 0.6471 - val_accuracy: 0.8167\n",
      "Epoch 520/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1591 - accuracy: 0.9370 - val_loss: 1.0687 - val_accuracy: 0.7625\n",
      "Epoch 521/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1854 - accuracy: 0.9252 - val_loss: 0.5713 - val_accuracy: 0.8358\n",
      "Epoch 522/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1957 - accuracy: 0.9234 - val_loss: 0.9044 - val_accuracy: 0.7639\n",
      "Epoch 523/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1604 - accuracy: 0.9359 - val_loss: 0.4026 - val_accuracy: 0.8592\n",
      "Epoch 524/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1588 - accuracy: 0.9380 - val_loss: 0.3765 - val_accuracy: 0.8768\n",
      "Epoch 525/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1642 - accuracy: 0.9326 - val_loss: 0.4364 - val_accuracy: 0.8563\n",
      "Epoch 526/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1684 - accuracy: 0.9362 - val_loss: 0.4453 - val_accuracy: 0.8578\n",
      "Epoch 527/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1681 - accuracy: 0.9348 - val_loss: 0.3753 - val_accuracy: 0.8695\n",
      "Epoch 528/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1835 - accuracy: 0.9351 - val_loss: 0.3959 - val_accuracy: 0.8622\n",
      "Epoch 529/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1837 - accuracy: 0.9238 - val_loss: 0.4311 - val_accuracy: 0.8578\n",
      "Epoch 530/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1655 - accuracy: 0.9315 - val_loss: 0.4035 - val_accuracy: 0.8622\n",
      "Epoch 531/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1642 - accuracy: 0.9337 - val_loss: 0.4178 - val_accuracy: 0.8607\n",
      "Epoch 532/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9326 - val_loss: 0.3768 - val_accuracy: 0.8827\n",
      "Epoch 533/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1763 - accuracy: 0.9344 - val_loss: 0.4582 - val_accuracy: 0.8519\n",
      "Epoch 534/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1923 - accuracy: 0.9245 - val_loss: 0.4776 - val_accuracy: 0.8519\n",
      "Epoch 535/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1814 - accuracy: 0.9234 - val_loss: 0.4523 - val_accuracy: 0.8548\n",
      "Epoch 536/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1505 - accuracy: 0.9417 - val_loss: 0.3930 - val_accuracy: 0.8812\n",
      "Epoch 537/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1601 - accuracy: 0.9388 - val_loss: 0.4098 - val_accuracy: 0.8534\n",
      "Epoch 538/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1659 - accuracy: 0.9296 - val_loss: 0.6476 - val_accuracy: 0.8270\n",
      "Epoch 539/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1719 - accuracy: 0.9362 - val_loss: 0.4144 - val_accuracy: 0.8636\n",
      "Epoch 540/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1811 - accuracy: 0.9278 - val_loss: 0.4326 - val_accuracy: 0.8783\n",
      "Epoch 541/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1820 - accuracy: 0.9355 - val_loss: 0.4211 - val_accuracy: 0.8666\n",
      "Epoch 542/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1613 - accuracy: 0.9370 - val_loss: 0.4766 - val_accuracy: 0.8431\n",
      "Epoch 543/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1865 - accuracy: 0.9285 - val_loss: 0.4097 - val_accuracy: 0.8695\n",
      "Epoch 544/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1687 - accuracy: 0.9373 - val_loss: 0.5270 - val_accuracy: 0.8402\n",
      "Epoch 545/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1761 - accuracy: 0.9315 - val_loss: 0.4032 - val_accuracy: 0.8666\n",
      "Epoch 546/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9307 - val_loss: 0.5465 - val_accuracy: 0.8372\n",
      "Epoch 547/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1616 - accuracy: 0.9351 - val_loss: 0.4142 - val_accuracy: 0.8680\n",
      "Epoch 548/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.9322 - val_loss: 0.6426 - val_accuracy: 0.8226\n",
      "Epoch 549/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1701 - accuracy: 0.9318 - val_loss: 0.4636 - val_accuracy: 0.8504\n",
      "Epoch 550/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1711 - accuracy: 0.9337 - val_loss: 0.4589 - val_accuracy: 0.8446\n",
      "Epoch 551/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1667 - accuracy: 0.9355 - val_loss: 0.4008 - val_accuracy: 0.8695\n",
      "Epoch 552/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1852 - accuracy: 0.9307 - val_loss: 0.3856 - val_accuracy: 0.8680\n",
      "Epoch 553/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1685 - accuracy: 0.9351 - val_loss: 0.5202 - val_accuracy: 0.8519\n",
      "Epoch 554/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1885 - accuracy: 0.9289 - val_loss: 0.3835 - val_accuracy: 0.8724\n",
      "Epoch 555/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1859 - accuracy: 0.9241 - val_loss: 0.4412 - val_accuracy: 0.8563\n",
      "Epoch 556/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1761 - accuracy: 0.9289 - val_loss: 0.8268 - val_accuracy: 0.8006\n",
      "Epoch 557/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1505 - accuracy: 0.9421 - val_loss: 0.3907 - val_accuracy: 0.8724\n",
      "Epoch 558/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1650 - accuracy: 0.9355 - val_loss: 0.5209 - val_accuracy: 0.8358\n",
      "Epoch 559/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1667 - accuracy: 0.9282 - val_loss: 6.9478 - val_accuracy: 0.2889\n",
      "Epoch 560/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2163 - accuracy: 0.9194 - val_loss: 0.4730 - val_accuracy: 0.8446\n",
      "Epoch 561/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1809 - accuracy: 0.9315 - val_loss: 0.4939 - val_accuracy: 0.8460\n",
      "Epoch 562/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1731 - accuracy: 0.9344 - val_loss: 0.3930 - val_accuracy: 0.8724\n",
      "Epoch 563/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1712 - accuracy: 0.9329 - val_loss: 0.4190 - val_accuracy: 0.8680\n",
      "Epoch 564/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1916 - accuracy: 0.9252 - val_loss: 0.4903 - val_accuracy: 0.8534\n",
      "Epoch 565/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1707 - accuracy: 0.9307 - val_loss: 0.4299 - val_accuracy: 0.8548\n",
      "Epoch 566/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1778 - accuracy: 0.9318 - val_loss: 0.6865 - val_accuracy: 0.8109\n",
      "Epoch 567/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1662 - accuracy: 0.9362 - val_loss: 0.6814 - val_accuracy: 0.8050\n",
      "Epoch 568/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1669 - accuracy: 0.9333 - val_loss: 0.4335 - val_accuracy: 0.8592\n",
      "Epoch 569/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1537 - accuracy: 0.9351 - val_loss: 0.4689 - val_accuracy: 0.8490\n",
      "Epoch 570/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1852 - accuracy: 0.9274 - val_loss: 0.4384 - val_accuracy: 0.8578\n",
      "Epoch 571/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1679 - accuracy: 0.9326 - val_loss: 0.4836 - val_accuracy: 0.8387\n",
      "Epoch 572/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1660 - accuracy: 0.9377 - val_loss: 0.4155 - val_accuracy: 0.8592\n",
      "Epoch 573/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1650 - accuracy: 0.9362 - val_loss: 0.4679 - val_accuracy: 0.8622\n",
      "Epoch 574/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1589 - accuracy: 0.9424 - val_loss: 0.3911 - val_accuracy: 0.8710\n",
      "Epoch 575/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1671 - accuracy: 0.9351 - val_loss: 0.4295 - val_accuracy: 0.8578\n",
      "Epoch 576/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1925 - accuracy: 0.9245 - val_loss: 0.4516 - val_accuracy: 0.8710\n",
      "Epoch 577/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1812 - accuracy: 0.9274 - val_loss: 0.4522 - val_accuracy: 0.8504\n",
      "Epoch 578/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1810 - accuracy: 0.9300 - val_loss: 0.4331 - val_accuracy: 0.8563\n",
      "Epoch 579/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9370 - val_loss: 0.4090 - val_accuracy: 0.8783\n",
      "Epoch 580/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1678 - accuracy: 0.9377 - val_loss: 0.4728 - val_accuracy: 0.8504\n",
      "Epoch 581/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1830 - accuracy: 0.9293 - val_loss: 0.4077 - val_accuracy: 0.8754\n",
      "Epoch 582/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1743 - accuracy: 0.9340 - val_loss: 0.4284 - val_accuracy: 0.8548\n",
      "Epoch 583/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1804 - accuracy: 0.9289 - val_loss: 0.3706 - val_accuracy: 0.8680\n",
      "Epoch 584/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1661 - accuracy: 0.9348 - val_loss: 0.4700 - val_accuracy: 0.8548\n",
      "Epoch 585/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1669 - accuracy: 0.9322 - val_loss: 0.4348 - val_accuracy: 0.8636\n",
      "Epoch 586/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1606 - accuracy: 0.9410 - val_loss: 1.6042 - val_accuracy: 0.6642\n",
      "Epoch 587/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1693 - accuracy: 0.9300 - val_loss: 0.4150 - val_accuracy: 0.8827\n",
      "Epoch 588/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1633 - accuracy: 0.9359 - val_loss: 0.4079 - val_accuracy: 0.8695\n",
      "Epoch 589/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1627 - accuracy: 0.9340 - val_loss: 0.4914 - val_accuracy: 0.8548\n",
      "Epoch 590/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1717 - accuracy: 0.9318 - val_loss: 1.0056 - val_accuracy: 0.7331\n",
      "Epoch 591/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1642 - accuracy: 0.9318 - val_loss: 0.3811 - val_accuracy: 0.8636\n",
      "Epoch 592/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1582 - accuracy: 0.9384 - val_loss: 0.6381 - val_accuracy: 0.8299\n",
      "Epoch 593/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1613 - accuracy: 0.9377 - val_loss: 0.4003 - val_accuracy: 0.8651\n",
      "Epoch 594/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1674 - accuracy: 0.9296 - val_loss: 0.4019 - val_accuracy: 0.8680\n",
      "Epoch 595/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9285 - val_loss: 0.4917 - val_accuracy: 0.8431\n",
      "Epoch 596/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1673 - accuracy: 0.9329 - val_loss: 0.5389 - val_accuracy: 0.8358\n",
      "Epoch 597/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1602 - accuracy: 0.9362 - val_loss: 0.7446 - val_accuracy: 0.7874\n",
      "Epoch 598/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9395 - val_loss: 0.3790 - val_accuracy: 0.8827\n",
      "Epoch 599/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1632 - accuracy: 0.9293 - val_loss: 0.3768 - val_accuracy: 0.8754\n",
      "Epoch 600/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1570 - accuracy: 0.9340 - val_loss: 0.3989 - val_accuracy: 0.8798\n",
      "Epoch 601/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1768 - accuracy: 0.9285 - val_loss: 0.4014 - val_accuracy: 0.8724\n",
      "Epoch 602/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1464 - accuracy: 0.9421 - val_loss: 0.3848 - val_accuracy: 0.8680\n",
      "Epoch 603/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1609 - accuracy: 0.9380 - val_loss: 0.6150 - val_accuracy: 0.8372\n",
      "Epoch 604/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1678 - accuracy: 0.9315 - val_loss: 0.6238 - val_accuracy: 0.8240\n",
      "Epoch 605/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1628 - accuracy: 0.9373 - val_loss: 0.3875 - val_accuracy: 0.8680\n",
      "Epoch 606/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.9344 - val_loss: 0.3970 - val_accuracy: 0.8680\n",
      "Epoch 607/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1590 - accuracy: 0.9395 - val_loss: 0.7045 - val_accuracy: 0.8211\n",
      "Epoch 608/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9322 - val_loss: 0.3415 - val_accuracy: 0.8900\n",
      "Epoch 609/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1579 - accuracy: 0.9402 - val_loss: 0.5185 - val_accuracy: 0.8519\n",
      "Epoch 610/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1490 - accuracy: 0.9413 - val_loss: 0.4099 - val_accuracy: 0.8666\n",
      "Epoch 611/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1430 - accuracy: 0.9410 - val_loss: 0.4588 - val_accuracy: 0.8607\n",
      "Epoch 612/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1542 - accuracy: 0.9406 - val_loss: 0.4456 - val_accuracy: 0.8563\n",
      "Epoch 613/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1630 - accuracy: 0.9329 - val_loss: 0.4337 - val_accuracy: 0.8563\n",
      "Epoch 614/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1623 - accuracy: 0.9340 - val_loss: 0.4330 - val_accuracy: 0.8607\n",
      "Epoch 615/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1792 - accuracy: 0.9326 - val_loss: 0.5578 - val_accuracy: 0.8372\n",
      "Epoch 616/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1620 - accuracy: 0.9366 - val_loss: 0.4163 - val_accuracy: 0.8680\n",
      "Epoch 617/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1670 - accuracy: 0.9315 - val_loss: 0.3869 - val_accuracy: 0.8724\n",
      "Epoch 618/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1582 - accuracy: 0.9370 - val_loss: 0.3739 - val_accuracy: 0.8812\n",
      "Epoch 619/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1608 - accuracy: 0.9413 - val_loss: 0.4170 - val_accuracy: 0.8680\n",
      "Epoch 620/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1633 - accuracy: 0.9366 - val_loss: 1.0260 - val_accuracy: 0.7419\n",
      "Epoch 621/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1588 - accuracy: 0.9388 - val_loss: 0.3927 - val_accuracy: 0.8710\n",
      "Epoch 622/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1469 - accuracy: 0.9391 - val_loss: 0.5708 - val_accuracy: 0.8431\n",
      "Epoch 623/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1649 - accuracy: 0.9351 - val_loss: 0.4004 - val_accuracy: 0.8739\n",
      "Epoch 624/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1471 - accuracy: 0.9370 - val_loss: 0.4273 - val_accuracy: 0.8607\n",
      "Epoch 625/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1464 - accuracy: 0.9380 - val_loss: 0.4037 - val_accuracy: 0.8636\n",
      "Epoch 626/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9428 - val_loss: 0.5003 - val_accuracy: 0.8387\n",
      "Epoch 627/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1512 - accuracy: 0.9454 - val_loss: 0.4120 - val_accuracy: 0.8592\n",
      "Epoch 628/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1538 - accuracy: 0.9359 - val_loss: 0.4147 - val_accuracy: 0.8519\n",
      "Epoch 629/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1549 - accuracy: 0.9384 - val_loss: 0.4022 - val_accuracy: 0.8607\n",
      "Epoch 630/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1583 - accuracy: 0.9388 - val_loss: 0.4789 - val_accuracy: 0.8519\n",
      "Epoch 631/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1645 - accuracy: 0.9340 - val_loss: 0.4315 - val_accuracy: 0.8651\n",
      "Epoch 632/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1567 - accuracy: 0.9355 - val_loss: 0.3977 - val_accuracy: 0.8666\n",
      "Epoch 633/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1463 - accuracy: 0.9417 - val_loss: 0.3941 - val_accuracy: 0.8724\n",
      "Epoch 634/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1469 - accuracy: 0.9435 - val_loss: 0.8321 - val_accuracy: 0.8006\n",
      "Epoch 635/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1630 - accuracy: 0.9359 - val_loss: 0.3741 - val_accuracy: 0.8739\n",
      "Epoch 636/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1490 - accuracy: 0.9402 - val_loss: 0.5314 - val_accuracy: 0.8387\n",
      "Epoch 637/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1734 - accuracy: 0.9370 - val_loss: 0.5011 - val_accuracy: 0.8534\n",
      "Epoch 638/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1318 - accuracy: 0.9472 - val_loss: 0.3785 - val_accuracy: 0.8724\n",
      "Epoch 639/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1579 - accuracy: 0.9399 - val_loss: 0.4374 - val_accuracy: 0.8607\n",
      "Epoch 640/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1590 - accuracy: 0.9366 - val_loss: 0.4406 - val_accuracy: 0.8651\n",
      "Epoch 641/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1548 - accuracy: 0.9355 - val_loss: 0.4754 - val_accuracy: 0.8504\n",
      "Epoch 642/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1552 - accuracy: 0.9413 - val_loss: 0.3915 - val_accuracy: 0.8754\n",
      "Epoch 643/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1513 - accuracy: 0.9380 - val_loss: 0.4494 - val_accuracy: 0.8622\n",
      "Epoch 644/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1601 - accuracy: 0.9388 - val_loss: 0.4184 - val_accuracy: 0.8666\n",
      "Epoch 645/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1717 - accuracy: 0.9318 - val_loss: 0.6236 - val_accuracy: 0.8284\n",
      "Epoch 646/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1613 - accuracy: 0.9388 - val_loss: 0.4037 - val_accuracy: 0.8666\n",
      "Epoch 647/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1456 - accuracy: 0.9446 - val_loss: 0.4317 - val_accuracy: 0.8710\n",
      "Epoch 648/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1500 - accuracy: 0.9399 - val_loss: 0.4173 - val_accuracy: 0.8563\n",
      "Epoch 649/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1449 - accuracy: 0.9446 - val_loss: 0.6098 - val_accuracy: 0.8328\n",
      "Epoch 650/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1641 - accuracy: 0.9388 - val_loss: 0.7399 - val_accuracy: 0.7918\n",
      "Epoch 651/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1538 - accuracy: 0.9417 - val_loss: 0.4909 - val_accuracy: 0.8578\n",
      "Epoch 652/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1589 - accuracy: 0.9402 - val_loss: 0.5076 - val_accuracy: 0.8548\n",
      "Epoch 653/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1538 - accuracy: 0.9391 - val_loss: 0.3893 - val_accuracy: 0.8636\n",
      "Epoch 654/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9370 - val_loss: 0.5178 - val_accuracy: 0.8460\n",
      "Epoch 655/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1560 - accuracy: 0.9370 - val_loss: 0.3847 - val_accuracy: 0.8739\n",
      "Epoch 656/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1638 - accuracy: 0.9318 - val_loss: 0.4439 - val_accuracy: 0.8592\n",
      "Epoch 657/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1708 - accuracy: 0.9351 - val_loss: 0.4628 - val_accuracy: 0.8460\n",
      "Epoch 658/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1499 - accuracy: 0.9457 - val_loss: 0.4792 - val_accuracy: 0.8680\n",
      "Epoch 659/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1377 - accuracy: 0.9435 - val_loss: 0.3849 - val_accuracy: 0.8783\n",
      "Epoch 660/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1596 - accuracy: 0.9377 - val_loss: 1.1109 - val_accuracy: 0.7199\n",
      "Epoch 661/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1538 - accuracy: 0.9370 - val_loss: 0.4191 - val_accuracy: 0.8680\n",
      "Epoch 662/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1481 - accuracy: 0.9428 - val_loss: 0.4591 - val_accuracy: 0.8592\n",
      "Epoch 663/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1565 - accuracy: 0.9406 - val_loss: 1.1085 - val_accuracy: 0.7405\n",
      "Epoch 664/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1684 - accuracy: 0.9362 - val_loss: 0.4156 - val_accuracy: 0.8695\n",
      "Epoch 665/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1574 - accuracy: 0.9377 - val_loss: 0.4645 - val_accuracy: 0.8578\n",
      "Epoch 666/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1553 - accuracy: 0.9362 - val_loss: 0.5051 - val_accuracy: 0.8431\n",
      "Epoch 667/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1631 - accuracy: 0.9355 - val_loss: 0.3696 - val_accuracy: 0.8812\n",
      "Epoch 668/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1497 - accuracy: 0.9395 - val_loss: 0.3861 - val_accuracy: 0.8724\n",
      "Epoch 669/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1557 - accuracy: 0.9366 - val_loss: 0.3956 - val_accuracy: 0.8754\n",
      "Epoch 670/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1484 - accuracy: 0.9399 - val_loss: 0.5794 - val_accuracy: 0.8284\n",
      "Epoch 671/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1737 - accuracy: 0.9296 - val_loss: 0.5289 - val_accuracy: 0.8460\n",
      "Epoch 672/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1670 - accuracy: 0.9362 - val_loss: 0.3708 - val_accuracy: 0.8754\n",
      "Epoch 673/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1481 - accuracy: 0.9366 - val_loss: 0.3690 - val_accuracy: 0.8754\n",
      "Epoch 674/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1311 - accuracy: 0.9443 - val_loss: 0.4706 - val_accuracy: 0.8636\n",
      "Epoch 675/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1482 - accuracy: 0.9388 - val_loss: 0.3835 - val_accuracy: 0.8754\n",
      "Epoch 676/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1569 - accuracy: 0.9399 - val_loss: 0.4089 - val_accuracy: 0.8651\n",
      "Epoch 677/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1587 - accuracy: 0.9315 - val_loss: 0.5466 - val_accuracy: 0.8240\n",
      "Epoch 678/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1747 - accuracy: 0.9348 - val_loss: 0.5086 - val_accuracy: 0.8416\n",
      "Epoch 679/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1626 - accuracy: 0.9326 - val_loss: 0.5127 - val_accuracy: 0.8299\n",
      "Epoch 680/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1636 - accuracy: 0.9370 - val_loss: 0.3818 - val_accuracy: 0.8695\n",
      "Epoch 681/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1458 - accuracy: 0.9406 - val_loss: 0.4807 - val_accuracy: 0.8490\n",
      "Epoch 682/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1593 - accuracy: 0.9391 - val_loss: 0.4045 - val_accuracy: 0.8695\n",
      "Epoch 683/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1597 - accuracy: 0.9377 - val_loss: 0.4174 - val_accuracy: 0.8636\n",
      "Epoch 684/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1544 - accuracy: 0.9384 - val_loss: 1.1945 - val_accuracy: 0.7199\n",
      "Epoch 685/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1576 - accuracy: 0.9391 - val_loss: 0.4005 - val_accuracy: 0.8666\n",
      "Epoch 686/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1452 - accuracy: 0.9479 - val_loss: 0.4114 - val_accuracy: 0.8651\n",
      "Epoch 687/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1445 - accuracy: 0.9424 - val_loss: 0.3966 - val_accuracy: 0.8783\n",
      "Epoch 688/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1587 - accuracy: 0.9377 - val_loss: 0.4593 - val_accuracy: 0.8578\n",
      "Epoch 689/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1519 - accuracy: 0.9391 - val_loss: 0.4504 - val_accuracy: 0.8636\n",
      "Epoch 690/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1537 - accuracy: 0.9413 - val_loss: 0.4341 - val_accuracy: 0.8592\n",
      "Epoch 691/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1564 - accuracy: 0.9446 - val_loss: 0.4268 - val_accuracy: 0.8651\n",
      "Epoch 692/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1490 - accuracy: 0.9380 - val_loss: 0.4005 - val_accuracy: 0.8754\n",
      "Epoch 693/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1439 - accuracy: 0.9457 - val_loss: 0.4162 - val_accuracy: 0.8783\n",
      "Epoch 694/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1468 - accuracy: 0.9457 - val_loss: 0.4368 - val_accuracy: 0.8651\n",
      "Epoch 695/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1484 - accuracy: 0.9413 - val_loss: 0.4474 - val_accuracy: 0.8563\n",
      "Epoch 696/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1499 - accuracy: 0.9395 - val_loss: 0.4025 - val_accuracy: 0.8739\n",
      "Epoch 697/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1734 - accuracy: 0.9333 - val_loss: 0.4182 - val_accuracy: 0.8636\n",
      "Epoch 698/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1398 - accuracy: 0.9432 - val_loss: 0.4221 - val_accuracy: 0.8695\n",
      "Epoch 699/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1478 - accuracy: 0.9432 - val_loss: 0.4159 - val_accuracy: 0.8798\n",
      "Epoch 700/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1568 - accuracy: 0.9410 - val_loss: 0.4103 - val_accuracy: 0.8636\n",
      "Epoch 701/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1435 - accuracy: 0.9443 - val_loss: 0.4688 - val_accuracy: 0.8519\n",
      "Epoch 702/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1598 - accuracy: 0.9384 - val_loss: 0.5273 - val_accuracy: 0.8446\n",
      "Epoch 703/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1623 - accuracy: 0.9373 - val_loss: 0.4591 - val_accuracy: 0.8651\n",
      "Epoch 704/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1582 - accuracy: 0.9355 - val_loss: 0.4522 - val_accuracy: 0.8592\n",
      "Epoch 705/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1497 - accuracy: 0.9395 - val_loss: 0.4260 - val_accuracy: 0.8710\n",
      "Epoch 706/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1541 - accuracy: 0.9435 - val_loss: 0.3833 - val_accuracy: 0.8827\n",
      "Epoch 707/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1612 - accuracy: 0.9362 - val_loss: 0.8781 - val_accuracy: 0.7933\n",
      "Epoch 708/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1689 - accuracy: 0.9391 - val_loss: 0.4851 - val_accuracy: 0.8534\n",
      "Epoch 709/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2197 - accuracy: 0.9135 - val_loss: 0.6322 - val_accuracy: 0.8270\n",
      "Epoch 710/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1942 - accuracy: 0.9245 - val_loss: 0.4490 - val_accuracy: 0.8592\n",
      "Epoch 711/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1820 - accuracy: 0.9329 - val_loss: 0.4584 - val_accuracy: 0.8622\n",
      "Epoch 712/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1811 - accuracy: 0.9337 - val_loss: 0.6197 - val_accuracy: 0.8314\n",
      "Epoch 713/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1718 - accuracy: 0.9344 - val_loss: 0.4300 - val_accuracy: 0.8695\n",
      "Epoch 714/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1577 - accuracy: 0.9344 - val_loss: 0.4250 - val_accuracy: 0.8607\n",
      "Epoch 715/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9359 - val_loss: 0.4798 - val_accuracy: 0.8563\n",
      "Epoch 716/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1637 - accuracy: 0.9348 - val_loss: 0.4156 - val_accuracy: 0.8812\n",
      "Epoch 717/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1778 - accuracy: 0.9318 - val_loss: 0.9670 - val_accuracy: 0.7625\n",
      "Epoch 718/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1874 - accuracy: 0.9285 - val_loss: 0.4222 - val_accuracy: 0.8666\n",
      "Epoch 719/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1470 - accuracy: 0.9443 - val_loss: 0.4242 - val_accuracy: 0.8680\n",
      "Epoch 720/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1711 - accuracy: 0.9340 - val_loss: 0.5018 - val_accuracy: 0.8431\n",
      "Epoch 721/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1617 - accuracy: 0.9344 - val_loss: 0.4055 - val_accuracy: 0.8680\n",
      "Epoch 722/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1776 - accuracy: 0.9340 - val_loss: 0.4259 - val_accuracy: 0.8622\n",
      "Epoch 723/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1498 - accuracy: 0.9402 - val_loss: 0.4027 - val_accuracy: 0.8812\n",
      "Epoch 724/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1559 - accuracy: 0.9377 - val_loss: 0.4222 - val_accuracy: 0.8578\n",
      "Epoch 725/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1609 - accuracy: 0.9366 - val_loss: 0.4314 - val_accuracy: 0.8710\n",
      "Epoch 726/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1562 - accuracy: 0.9388 - val_loss: 0.4001 - val_accuracy: 0.8754\n",
      "Epoch 727/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1642 - accuracy: 0.9340 - val_loss: 0.4311 - val_accuracy: 0.8651\n",
      "Epoch 728/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1733 - accuracy: 0.9311 - val_loss: 0.4217 - val_accuracy: 0.8666\n",
      "Epoch 729/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1519 - accuracy: 0.9428 - val_loss: 0.4247 - val_accuracy: 0.8695\n",
      "Epoch 730/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1451 - accuracy: 0.9428 - val_loss: 0.4311 - val_accuracy: 0.8710\n",
      "Epoch 731/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1655 - accuracy: 0.9300 - val_loss: 0.4353 - val_accuracy: 0.8607\n",
      "Epoch 732/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1489 - accuracy: 0.9428 - val_loss: 0.3901 - val_accuracy: 0.8739\n",
      "Epoch 733/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1615 - accuracy: 0.9355 - val_loss: 0.8295 - val_accuracy: 0.7889\n",
      "Epoch 734/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1405 - accuracy: 0.9432 - val_loss: 0.4328 - val_accuracy: 0.8680\n",
      "Epoch 735/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1422 - accuracy: 0.9417 - val_loss: 0.5964 - val_accuracy: 0.8270\n",
      "Epoch 736/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1510 - accuracy: 0.9388 - val_loss: 0.4440 - val_accuracy: 0.8534\n",
      "Epoch 737/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1595 - accuracy: 0.9395 - val_loss: 0.4228 - val_accuracy: 0.8724\n",
      "Epoch 738/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1347 - accuracy: 0.9465 - val_loss: 0.5456 - val_accuracy: 0.8460\n",
      "Epoch 739/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1638 - accuracy: 0.9344 - val_loss: 0.4993 - val_accuracy: 0.8534\n",
      "Epoch 740/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1636 - accuracy: 0.9366 - val_loss: 0.4458 - val_accuracy: 0.8519\n",
      "Epoch 741/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1641 - accuracy: 0.9362 - val_loss: 0.4172 - val_accuracy: 0.8783\n",
      "Epoch 742/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1595 - accuracy: 0.9337 - val_loss: 0.7419 - val_accuracy: 0.7947\n",
      "Epoch 743/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1605 - accuracy: 0.9337 - val_loss: 0.4103 - val_accuracy: 0.8636\n",
      "Epoch 744/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1533 - accuracy: 0.9410 - val_loss: 0.4575 - val_accuracy: 0.8578\n",
      "Epoch 745/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1539 - accuracy: 0.9402 - val_loss: 0.5436 - val_accuracy: 0.8416\n",
      "Epoch 746/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1531 - accuracy: 0.9384 - val_loss: 0.4242 - val_accuracy: 0.8724\n",
      "Epoch 747/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1372 - accuracy: 0.9417 - val_loss: 0.4745 - val_accuracy: 0.8548\n",
      "Epoch 748/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1518 - accuracy: 0.9391 - val_loss: 0.6913 - val_accuracy: 0.8270\n",
      "Epoch 749/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9443 - val_loss: 0.4168 - val_accuracy: 0.8651\n",
      "Epoch 750/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1364 - accuracy: 0.9406 - val_loss: 0.4725 - val_accuracy: 0.8651\n",
      "Epoch 751/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1489 - accuracy: 0.9424 - val_loss: 0.4961 - val_accuracy: 0.8475\n",
      "Epoch 752/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1575 - accuracy: 0.9370 - val_loss: 0.4316 - val_accuracy: 0.8724\n",
      "Epoch 753/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1465 - accuracy: 0.9388 - val_loss: 0.4857 - val_accuracy: 0.8475\n",
      "Epoch 754/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1596 - accuracy: 0.9355 - val_loss: 0.4818 - val_accuracy: 0.8578\n",
      "Epoch 755/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1547 - accuracy: 0.9410 - val_loss: 0.4064 - val_accuracy: 0.8607\n",
      "Epoch 756/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1504 - accuracy: 0.9370 - val_loss: 0.4310 - val_accuracy: 0.8548\n",
      "Epoch 757/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1512 - accuracy: 0.9391 - val_loss: 0.3957 - val_accuracy: 0.8812\n",
      "Epoch 758/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1532 - accuracy: 0.9366 - val_loss: 0.4128 - val_accuracy: 0.8798\n",
      "Epoch 759/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1503 - accuracy: 0.9424 - val_loss: 0.4671 - val_accuracy: 0.8578\n",
      "Epoch 760/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1564 - accuracy: 0.9380 - val_loss: 0.4437 - val_accuracy: 0.8578\n",
      "Epoch 761/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1471 - accuracy: 0.9446 - val_loss: 0.4663 - val_accuracy: 0.8651\n",
      "Epoch 762/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1487 - accuracy: 0.9421 - val_loss: 0.4505 - val_accuracy: 0.8798\n",
      "Epoch 763/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1518 - accuracy: 0.9410 - val_loss: 0.4188 - val_accuracy: 0.8768\n",
      "Epoch 764/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1676 - accuracy: 0.9348 - val_loss: 0.4214 - val_accuracy: 0.8666\n",
      "Epoch 765/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1487 - accuracy: 0.9428 - val_loss: 0.4271 - val_accuracy: 0.8695\n",
      "Epoch 766/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1457 - accuracy: 0.9446 - val_loss: 0.4411 - val_accuracy: 0.8607\n",
      "Epoch 767/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1518 - accuracy: 0.9410 - val_loss: 0.4292 - val_accuracy: 0.8592\n",
      "Epoch 768/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1519 - accuracy: 0.9424 - val_loss: 0.5672 - val_accuracy: 0.8460\n",
      "Epoch 769/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1391 - accuracy: 0.9476 - val_loss: 0.3925 - val_accuracy: 0.8754\n",
      "Epoch 770/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1776 - accuracy: 0.9322 - val_loss: 0.3795 - val_accuracy: 0.8754\n",
      "Epoch 771/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1499 - accuracy: 0.9366 - val_loss: 0.3764 - val_accuracy: 0.8724\n",
      "Epoch 772/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1552 - accuracy: 0.9333 - val_loss: 0.4153 - val_accuracy: 0.8651\n",
      "Epoch 773/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1457 - accuracy: 0.9417 - val_loss: 0.9099 - val_accuracy: 0.7639\n",
      "Epoch 774/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1540 - accuracy: 0.9391 - val_loss: 0.4638 - val_accuracy: 0.8563\n",
      "Epoch 775/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1489 - accuracy: 0.9421 - val_loss: 0.3915 - val_accuracy: 0.8680\n",
      "Epoch 776/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1422 - accuracy: 0.9465 - val_loss: 0.4232 - val_accuracy: 0.8607\n",
      "Epoch 777/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9377 - val_loss: 0.5378 - val_accuracy: 0.8343\n",
      "Epoch 778/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1412 - accuracy: 0.9468 - val_loss: 0.4402 - val_accuracy: 0.8636\n",
      "Epoch 779/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1496 - accuracy: 0.9402 - val_loss: 0.4597 - val_accuracy: 0.8548\n",
      "Epoch 780/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1447 - accuracy: 0.9380 - val_loss: 0.3915 - val_accuracy: 0.8842\n",
      "Epoch 781/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1468 - accuracy: 0.9362 - val_loss: 0.4743 - val_accuracy: 0.8710\n",
      "Epoch 782/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1494 - accuracy: 0.9450 - val_loss: 0.4220 - val_accuracy: 0.8680\n",
      "Epoch 783/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1348 - accuracy: 0.9479 - val_loss: 0.4593 - val_accuracy: 0.8504\n",
      "Epoch 784/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1211 - accuracy: 0.9589 - val_loss: 0.4086 - val_accuracy: 0.8798\n",
      "Epoch 785/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1349 - accuracy: 0.9461 - val_loss: 0.4903 - val_accuracy: 0.8548\n",
      "Epoch 786/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1507 - accuracy: 0.9428 - val_loss: 0.4498 - val_accuracy: 0.8519\n",
      "Epoch 787/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1365 - accuracy: 0.9443 - val_loss: 0.7232 - val_accuracy: 0.8006\n",
      "Epoch 788/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1449 - accuracy: 0.9457 - val_loss: 0.4324 - val_accuracy: 0.8651\n",
      "Epoch 789/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1441 - accuracy: 0.9421 - val_loss: 0.4295 - val_accuracy: 0.8578\n",
      "Epoch 790/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1622 - accuracy: 0.9399 - val_loss: 0.5589 - val_accuracy: 0.8475\n",
      "Epoch 791/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1297 - accuracy: 0.9505 - val_loss: 0.3843 - val_accuracy: 0.8651\n",
      "Epoch 792/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1534 - accuracy: 0.9380 - val_loss: 0.4496 - val_accuracy: 0.8622\n",
      "Epoch 793/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1551 - accuracy: 0.9380 - val_loss: 0.4771 - val_accuracy: 0.8475\n",
      "Epoch 794/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1505 - accuracy: 0.9370 - val_loss: 0.4995 - val_accuracy: 0.8475\n",
      "Epoch 795/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1586 - accuracy: 0.9359 - val_loss: 0.4097 - val_accuracy: 0.8636\n",
      "Epoch 796/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1455 - accuracy: 0.9432 - val_loss: 0.4245 - val_accuracy: 0.8636\n",
      "Epoch 797/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1417 - accuracy: 0.9417 - val_loss: 0.4115 - val_accuracy: 0.8695\n",
      "Epoch 798/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1465 - accuracy: 0.9450 - val_loss: 0.3873 - val_accuracy: 0.8710\n",
      "Epoch 799/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9527 - val_loss: 0.4882 - val_accuracy: 0.8475\n",
      "Epoch 800/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1400 - accuracy: 0.9479 - val_loss: 0.3941 - val_accuracy: 0.8739\n",
      "Epoch 801/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1402 - accuracy: 0.9413 - val_loss: 0.5175 - val_accuracy: 0.8548\n",
      "Epoch 802/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1446 - accuracy: 0.9402 - val_loss: 0.5572 - val_accuracy: 0.8431\n",
      "Epoch 803/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1470 - accuracy: 0.9424 - val_loss: 0.4808 - val_accuracy: 0.8548\n",
      "Epoch 804/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1478 - accuracy: 0.9432 - val_loss: 1.6226 - val_accuracy: 0.6877\n",
      "Epoch 805/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1551 - accuracy: 0.9399 - val_loss: 0.4300 - val_accuracy: 0.8607\n",
      "Epoch 806/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1521 - accuracy: 0.9384 - val_loss: 0.4610 - val_accuracy: 0.8607\n",
      "Epoch 807/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1615 - accuracy: 0.9406 - val_loss: 0.4264 - val_accuracy: 0.8607\n",
      "Epoch 808/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1457 - accuracy: 0.9465 - val_loss: 0.4303 - val_accuracy: 0.8651\n",
      "Epoch 809/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1521 - accuracy: 0.9399 - val_loss: 0.4204 - val_accuracy: 0.8607\n",
      "Epoch 810/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1562 - accuracy: 0.9384 - val_loss: 0.4421 - val_accuracy: 0.8563\n",
      "Epoch 811/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1500 - accuracy: 0.9424 - val_loss: 0.8306 - val_accuracy: 0.7947\n",
      "Epoch 812/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9384 - val_loss: 0.3828 - val_accuracy: 0.8783\n",
      "Epoch 813/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1454 - accuracy: 0.9395 - val_loss: 0.4044 - val_accuracy: 0.8739\n",
      "Epoch 814/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1563 - accuracy: 0.9402 - val_loss: 0.3938 - val_accuracy: 0.8724\n",
      "Epoch 815/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1453 - accuracy: 0.9461 - val_loss: 0.4245 - val_accuracy: 0.8666\n",
      "Epoch 816/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1605 - accuracy: 0.9322 - val_loss: 0.4097 - val_accuracy: 0.8724\n",
      "Epoch 817/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1430 - accuracy: 0.9487 - val_loss: 0.5476 - val_accuracy: 0.8519\n",
      "Epoch 818/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1315 - accuracy: 0.9498 - val_loss: 0.4144 - val_accuracy: 0.8622\n",
      "Epoch 819/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1572 - accuracy: 0.9388 - val_loss: 0.7980 - val_accuracy: 0.7801\n",
      "Epoch 820/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9406 - val_loss: 0.3858 - val_accuracy: 0.8783\n",
      "Epoch 821/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9483 - val_loss: 0.9247 - val_accuracy: 0.7933\n",
      "Epoch 822/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9432 - val_loss: 0.4192 - val_accuracy: 0.8768\n",
      "Epoch 823/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1411 - accuracy: 0.9450 - val_loss: 0.5498 - val_accuracy: 0.8328\n",
      "Epoch 824/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1621 - accuracy: 0.9380 - val_loss: 0.4292 - val_accuracy: 0.8592\n",
      "Epoch 825/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1464 - accuracy: 0.9421 - val_loss: 0.3930 - val_accuracy: 0.8754\n",
      "Epoch 826/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1464 - accuracy: 0.9435 - val_loss: 0.4522 - val_accuracy: 0.8622\n",
      "Epoch 827/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1372 - accuracy: 0.9428 - val_loss: 0.5104 - val_accuracy: 0.8534\n",
      "Epoch 828/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1390 - accuracy: 0.9399 - val_loss: 0.4015 - val_accuracy: 0.8710\n",
      "Epoch 829/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1561 - accuracy: 0.9370 - val_loss: 0.3918 - val_accuracy: 0.8636\n",
      "Epoch 830/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1397 - accuracy: 0.9435 - val_loss: 0.3712 - val_accuracy: 0.8724\n",
      "Epoch 831/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9388 - val_loss: 0.3887 - val_accuracy: 0.8710\n",
      "Epoch 832/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1242 - accuracy: 0.9527 - val_loss: 0.3970 - val_accuracy: 0.8710\n",
      "Epoch 833/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1440 - accuracy: 0.9432 - val_loss: 0.7012 - val_accuracy: 0.7903\n",
      "Epoch 834/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1439 - accuracy: 0.9446 - val_loss: 0.4109 - val_accuracy: 0.8724\n",
      "Epoch 835/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1366 - accuracy: 0.9457 - val_loss: 0.4319 - val_accuracy: 0.8578\n",
      "Epoch 836/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1383 - accuracy: 0.9428 - val_loss: 0.4147 - val_accuracy: 0.8666\n",
      "Epoch 837/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1442 - accuracy: 0.9406 - val_loss: 0.9504 - val_accuracy: 0.7977\n",
      "Epoch 838/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1446 - accuracy: 0.9428 - val_loss: 0.4151 - val_accuracy: 0.8695\n",
      "Epoch 839/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1338 - accuracy: 0.9479 - val_loss: 0.3976 - val_accuracy: 0.8754\n",
      "Epoch 840/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1334 - accuracy: 0.9479 - val_loss: 0.3885 - val_accuracy: 0.8695\n",
      "Epoch 841/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1404 - accuracy: 0.9476 - val_loss: 0.5963 - val_accuracy: 0.8270\n",
      "Epoch 842/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1512 - accuracy: 0.9399 - val_loss: 0.4100 - val_accuracy: 0.8695\n",
      "Epoch 843/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.9498 - val_loss: 0.4470 - val_accuracy: 0.8636\n",
      "Epoch 844/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1508 - accuracy: 0.9435 - val_loss: 0.4487 - val_accuracy: 0.8607\n",
      "Epoch 845/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1417 - accuracy: 0.9443 - val_loss: 0.4167 - val_accuracy: 0.8636\n",
      "Epoch 846/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1366 - accuracy: 0.9479 - val_loss: 0.4575 - val_accuracy: 0.8607\n",
      "Epoch 847/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1518 - accuracy: 0.9399 - val_loss: 0.4787 - val_accuracy: 0.8504\n",
      "Epoch 848/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1601 - accuracy: 0.9359 - val_loss: 0.4677 - val_accuracy: 0.8578\n",
      "Epoch 849/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1277 - accuracy: 0.9483 - val_loss: 0.4212 - val_accuracy: 0.8695\n",
      "Epoch 850/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1549 - accuracy: 0.9395 - val_loss: 0.4566 - val_accuracy: 0.8622\n",
      "Epoch 851/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1486 - accuracy: 0.9388 - val_loss: 0.4487 - val_accuracy: 0.8695\n",
      "Epoch 852/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1344 - accuracy: 0.9443 - val_loss: 0.6187 - val_accuracy: 0.8358\n",
      "Epoch 853/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1634 - accuracy: 0.9362 - val_loss: 0.4477 - val_accuracy: 0.8695\n",
      "Epoch 854/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1326 - accuracy: 0.9450 - val_loss: 0.4310 - val_accuracy: 0.8592\n",
      "Epoch 855/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1613 - accuracy: 0.9373 - val_loss: 0.4097 - val_accuracy: 0.8666\n",
      "Epoch 856/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1571 - accuracy: 0.9391 - val_loss: 0.4480 - val_accuracy: 0.8548\n",
      "Epoch 857/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9406 - val_loss: 0.5538 - val_accuracy: 0.8343\n",
      "Epoch 858/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1606 - accuracy: 0.9402 - val_loss: 0.5893 - val_accuracy: 0.8226\n",
      "Epoch 859/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1447 - accuracy: 0.9421 - val_loss: 0.5268 - val_accuracy: 0.8490\n",
      "Epoch 860/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1513 - accuracy: 0.9406 - val_loss: 0.6709 - val_accuracy: 0.8050\n",
      "Epoch 861/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1472 - accuracy: 0.9450 - val_loss: 0.4911 - val_accuracy: 0.8636\n",
      "Epoch 862/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1536 - accuracy: 0.9406 - val_loss: 0.3934 - val_accuracy: 0.8812\n",
      "Epoch 863/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1407 - accuracy: 0.9402 - val_loss: 0.4406 - val_accuracy: 0.8504\n",
      "Epoch 864/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1538 - accuracy: 0.9366 - val_loss: 0.4466 - val_accuracy: 0.8622\n",
      "Epoch 865/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1499 - accuracy: 0.9450 - val_loss: 0.4482 - val_accuracy: 0.8680\n",
      "Epoch 866/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1381 - accuracy: 0.9454 - val_loss: 0.4348 - val_accuracy: 0.8710\n",
      "Epoch 867/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1420 - accuracy: 0.9454 - val_loss: 0.4174 - val_accuracy: 0.8783\n",
      "Epoch 868/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1273 - accuracy: 0.9516 - val_loss: 0.4356 - val_accuracy: 0.8666\n",
      "Epoch 869/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1514 - accuracy: 0.9406 - val_loss: 0.4203 - val_accuracy: 0.8724\n",
      "Epoch 870/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9461 - val_loss: 0.4635 - val_accuracy: 0.8563\n",
      "Epoch 871/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1308 - accuracy: 0.9545 - val_loss: 0.4454 - val_accuracy: 0.8680\n",
      "Epoch 872/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1376 - accuracy: 0.9457 - val_loss: 0.4495 - val_accuracy: 0.8651\n",
      "Epoch 873/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1398 - accuracy: 0.9509 - val_loss: 0.4500 - val_accuracy: 0.8607\n",
      "Epoch 874/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1372 - accuracy: 0.9454 - val_loss: 0.4469 - val_accuracy: 0.8651\n",
      "Epoch 875/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1375 - accuracy: 0.9476 - val_loss: 0.4388 - val_accuracy: 0.8651\n",
      "Epoch 876/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1371 - accuracy: 0.9468 - val_loss: 0.4262 - val_accuracy: 0.8798\n",
      "Epoch 877/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9424 - val_loss: 0.4171 - val_accuracy: 0.8724\n",
      "Epoch 878/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1361 - accuracy: 0.9468 - val_loss: 0.4412 - val_accuracy: 0.8592\n",
      "Epoch 879/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1247 - accuracy: 0.9545 - val_loss: 0.4641 - val_accuracy: 0.8504\n",
      "Epoch 880/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1446 - accuracy: 0.9479 - val_loss: 0.4010 - val_accuracy: 0.8812\n",
      "Epoch 881/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1311 - accuracy: 0.9450 - val_loss: 0.4073 - val_accuracy: 0.8695\n",
      "Epoch 882/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1477 - accuracy: 0.9465 - val_loss: 0.4161 - val_accuracy: 0.8812\n",
      "Epoch 883/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1433 - accuracy: 0.9402 - val_loss: 0.4257 - val_accuracy: 0.8592\n",
      "Epoch 884/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1420 - accuracy: 0.9395 - val_loss: 0.4068 - val_accuracy: 0.8739\n",
      "Epoch 885/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1479 - accuracy: 0.9421 - val_loss: 0.4933 - val_accuracy: 0.8504\n",
      "Epoch 886/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1383 - accuracy: 0.9424 - val_loss: 0.5183 - val_accuracy: 0.8402\n",
      "Epoch 887/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1242 - accuracy: 0.9527 - val_loss: 0.3978 - val_accuracy: 0.8695\n",
      "Epoch 888/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1449 - accuracy: 0.9391 - val_loss: 0.4342 - val_accuracy: 0.8548\n",
      "Epoch 889/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1435 - accuracy: 0.9406 - val_loss: 0.4034 - val_accuracy: 0.8710\n",
      "Epoch 890/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9446 - val_loss: 0.3908 - val_accuracy: 0.8754\n",
      "Epoch 891/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1436 - accuracy: 0.9399 - val_loss: 0.4054 - val_accuracy: 0.8578\n",
      "Epoch 892/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1335 - accuracy: 0.9454 - val_loss: 0.4493 - val_accuracy: 0.8710\n",
      "Epoch 893/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1414 - accuracy: 0.9476 - val_loss: 0.4112 - val_accuracy: 0.8724\n",
      "Epoch 894/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1376 - accuracy: 0.9454 - val_loss: 0.4840 - val_accuracy: 0.8563\n",
      "Epoch 895/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1463 - accuracy: 0.9428 - val_loss: 1.2533 - val_accuracy: 0.7449\n",
      "Epoch 896/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1432 - accuracy: 0.9446 - val_loss: 0.4155 - val_accuracy: 0.8651\n",
      "Epoch 897/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1409 - accuracy: 0.9450 - val_loss: 0.4303 - val_accuracy: 0.8754\n",
      "Epoch 898/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1474 - accuracy: 0.9461 - val_loss: 0.4179 - val_accuracy: 0.8695\n",
      "Epoch 899/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9439 - val_loss: 0.4060 - val_accuracy: 0.8739\n",
      "Epoch 900/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1481 - accuracy: 0.9410 - val_loss: 0.7171 - val_accuracy: 0.7991\n",
      "Epoch 901/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1535 - accuracy: 0.9402 - val_loss: 0.7964 - val_accuracy: 0.8006\n",
      "Epoch 902/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1369 - accuracy: 0.9435 - val_loss: 0.4205 - val_accuracy: 0.8724\n",
      "Epoch 903/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1286 - accuracy: 0.9476 - val_loss: 0.4049 - val_accuracy: 0.8666\n",
      "Epoch 904/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1289 - accuracy: 0.9512 - val_loss: 0.4333 - val_accuracy: 0.8636\n",
      "Epoch 905/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1287 - accuracy: 0.9498 - val_loss: 0.9377 - val_accuracy: 0.7801\n",
      "Epoch 906/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1464 - accuracy: 0.9395 - val_loss: 0.4085 - val_accuracy: 0.8680\n",
      "Epoch 907/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1414 - accuracy: 0.9461 - val_loss: 0.6969 - val_accuracy: 0.8226\n",
      "Epoch 908/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1381 - accuracy: 0.9454 - val_loss: 0.4583 - val_accuracy: 0.8636\n",
      "Epoch 909/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1354 - accuracy: 0.9457 - val_loss: 0.4278 - val_accuracy: 0.8666\n",
      "Epoch 910/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1511 - accuracy: 0.9377 - val_loss: 0.5052 - val_accuracy: 0.8548\n",
      "Epoch 911/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1294 - accuracy: 0.9512 - val_loss: 0.4018 - val_accuracy: 0.8754\n",
      "Epoch 912/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1508 - accuracy: 0.9391 - val_loss: 0.4013 - val_accuracy: 0.8754\n",
      "Epoch 913/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1259 - accuracy: 0.9509 - val_loss: 0.4215 - val_accuracy: 0.8739\n",
      "Epoch 914/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1564 - accuracy: 0.9344 - val_loss: 0.4050 - val_accuracy: 0.8710\n",
      "Epoch 915/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1605 - accuracy: 0.9428 - val_loss: 0.6287 - val_accuracy: 0.8226\n",
      "Epoch 916/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1561 - accuracy: 0.9391 - val_loss: 0.4477 - val_accuracy: 0.8622\n",
      "Epoch 917/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1392 - accuracy: 0.9406 - val_loss: 0.4203 - val_accuracy: 0.8724\n",
      "Epoch 918/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1597 - accuracy: 0.9380 - val_loss: 0.4394 - val_accuracy: 0.8680\n",
      "Epoch 919/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1495 - accuracy: 0.9454 - val_loss: 0.4038 - val_accuracy: 0.8754\n",
      "Epoch 920/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1306 - accuracy: 0.9435 - val_loss: 0.4594 - val_accuracy: 0.8651\n",
      "Epoch 921/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1343 - accuracy: 0.9450 - val_loss: 0.4542 - val_accuracy: 0.8695\n",
      "Epoch 922/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1404 - accuracy: 0.9402 - val_loss: 0.4935 - val_accuracy: 0.8475\n",
      "Epoch 923/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1476 - accuracy: 0.9377 - val_loss: 0.4140 - val_accuracy: 0.8680\n",
      "Epoch 924/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1291 - accuracy: 0.9457 - val_loss: 0.4313 - val_accuracy: 0.8636\n",
      "Epoch 925/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1418 - accuracy: 0.9388 - val_loss: 1.2503 - val_accuracy: 0.7141\n",
      "Epoch 926/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1468 - accuracy: 0.9432 - val_loss: 0.4260 - val_accuracy: 0.8783\n",
      "Epoch 927/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1351 - accuracy: 0.9483 - val_loss: 0.4497 - val_accuracy: 0.8607\n",
      "Epoch 928/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1592 - accuracy: 0.9337 - val_loss: 1.8324 - val_accuracy: 0.6584\n",
      "Epoch 929/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1427 - accuracy: 0.9421 - val_loss: 0.4418 - val_accuracy: 0.8651\n",
      "Epoch 930/7000\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1430 - accuracy: 0.9417 - val_loss: 0.4437 - val_accuracy: 0.8607\n",
      "Epoch 931/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1340 - accuracy: 0.9461 - val_loss: 0.4777 - val_accuracy: 0.8504\n",
      "Epoch 932/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1330 - accuracy: 0.9457 - val_loss: 1.6136 - val_accuracy: 0.6891\n",
      "Epoch 933/7000\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.1361 - accuracy: 0.9461 - val_loss: 0.4356 - val_accuracy: 0.8534\n",
      "Epoch 934/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1541 - accuracy: 0.9377 - val_loss: 0.3970 - val_accuracy: 0.8754\n",
      "Epoch 935/7000\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1491 - accuracy: 0.9384 - val_loss: 0.4155 - val_accuracy: 0.8651\n",
      "Epoch 936/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1360 - accuracy: 0.9432 - val_loss: 0.3979 - val_accuracy: 0.8607\n",
      "Epoch 937/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1354 - accuracy: 0.9483 - val_loss: 0.4461 - val_accuracy: 0.8695\n",
      "Epoch 938/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1411 - accuracy: 0.9443 - val_loss: 0.6190 - val_accuracy: 0.8314\n",
      "Epoch 939/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1258 - accuracy: 0.9476 - val_loss: 0.4319 - val_accuracy: 0.8651\n",
      "Epoch 940/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9439 - val_loss: 0.4812 - val_accuracy: 0.8460\n",
      "Epoch 941/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1318 - accuracy: 0.9505 - val_loss: 0.4231 - val_accuracy: 0.8739\n",
      "Epoch 942/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1393 - accuracy: 0.9399 - val_loss: 0.3986 - val_accuracy: 0.8695\n",
      "Epoch 943/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1397 - accuracy: 0.9443 - val_loss: 0.4028 - val_accuracy: 0.8695\n",
      "Epoch 944/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1326 - accuracy: 0.9457 - val_loss: 0.6427 - val_accuracy: 0.8211\n",
      "Epoch 945/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1376 - accuracy: 0.9450 - val_loss: 0.5128 - val_accuracy: 0.8534\n",
      "Epoch 946/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1378 - accuracy: 0.9443 - val_loss: 0.4159 - val_accuracy: 0.8739\n",
      "Epoch 947/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1375 - accuracy: 0.9479 - val_loss: 0.5561 - val_accuracy: 0.8402\n",
      "Epoch 948/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1389 - accuracy: 0.9428 - val_loss: 0.4917 - val_accuracy: 0.8519\n",
      "Epoch 949/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1576 - accuracy: 0.9359 - val_loss: 0.4171 - val_accuracy: 0.8680\n",
      "Epoch 950/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1459 - accuracy: 0.9413 - val_loss: 0.4823 - val_accuracy: 0.8607\n",
      "Epoch 951/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9413 - val_loss: 0.4418 - val_accuracy: 0.8666\n",
      "Epoch 952/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1292 - accuracy: 0.9512 - val_loss: 0.4866 - val_accuracy: 0.8607\n",
      "Epoch 953/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1074 - accuracy: 0.9575 - val_loss: 0.3978 - val_accuracy: 0.8710\n",
      "Epoch 954/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9457 - val_loss: 0.4042 - val_accuracy: 0.8754\n",
      "Epoch 955/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1420 - accuracy: 0.9443 - val_loss: 0.4789 - val_accuracy: 0.8666\n",
      "Epoch 956/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1432 - accuracy: 0.9509 - val_loss: 0.7344 - val_accuracy: 0.8035\n",
      "Epoch 957/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1322 - accuracy: 0.9465 - val_loss: 0.3946 - val_accuracy: 0.8710\n",
      "Epoch 958/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1347 - accuracy: 0.9498 - val_loss: 0.4154 - val_accuracy: 0.8695\n",
      "Epoch 959/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1358 - accuracy: 0.9450 - val_loss: 0.4294 - val_accuracy: 0.8548\n",
      "Epoch 960/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1309 - accuracy: 0.9490 - val_loss: 0.7109 - val_accuracy: 0.8182\n",
      "Epoch 961/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1297 - accuracy: 0.9531 - val_loss: 0.4002 - val_accuracy: 0.8607\n",
      "Epoch 962/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1239 - accuracy: 0.9483 - val_loss: 0.4052 - val_accuracy: 0.8783\n",
      "Epoch 963/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1516 - accuracy: 0.9318 - val_loss: 0.5546 - val_accuracy: 0.8387\n",
      "Epoch 964/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1277 - accuracy: 0.9476 - val_loss: 0.4934 - val_accuracy: 0.8490\n",
      "Epoch 965/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1340 - accuracy: 0.9479 - val_loss: 0.9293 - val_accuracy: 0.7742\n",
      "Epoch 966/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1442 - accuracy: 0.9498 - val_loss: 0.4332 - val_accuracy: 0.8607\n",
      "Epoch 967/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1299 - accuracy: 0.9520 - val_loss: 0.5296 - val_accuracy: 0.8416\n",
      "Epoch 968/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1340 - accuracy: 0.9468 - val_loss: 0.4379 - val_accuracy: 0.8636\n",
      "Epoch 969/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1349 - accuracy: 0.9483 - val_loss: 0.5452 - val_accuracy: 0.8372\n",
      "Epoch 970/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9472 - val_loss: 0.4325 - val_accuracy: 0.8710\n",
      "Epoch 971/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1375 - accuracy: 0.9443 - val_loss: 0.4290 - val_accuracy: 0.8578\n",
      "Epoch 972/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1322 - accuracy: 0.9512 - val_loss: 0.7048 - val_accuracy: 0.8138\n",
      "Epoch 973/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1235 - accuracy: 0.9501 - val_loss: 0.6450 - val_accuracy: 0.8196\n",
      "Epoch 974/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1311 - accuracy: 0.9490 - val_loss: 0.4648 - val_accuracy: 0.8490\n",
      "Epoch 975/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1338 - accuracy: 0.9490 - val_loss: 0.7467 - val_accuracy: 0.8138\n",
      "Epoch 976/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1501 - accuracy: 0.9457 - val_loss: 0.3756 - val_accuracy: 0.8666\n",
      "Epoch 977/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1348 - accuracy: 0.9457 - val_loss: 0.4822 - val_accuracy: 0.8372\n",
      "Epoch 978/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1296 - accuracy: 0.9450 - val_loss: 0.5953 - val_accuracy: 0.8343\n",
      "Epoch 979/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1366 - accuracy: 0.9494 - val_loss: 0.4388 - val_accuracy: 0.8622\n",
      "Epoch 980/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1480 - accuracy: 0.9391 - val_loss: 0.7169 - val_accuracy: 0.8138\n",
      "Epoch 981/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1476 - accuracy: 0.9406 - val_loss: 0.6304 - val_accuracy: 0.8035\n",
      "Epoch 982/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9450 - val_loss: 1.8735 - val_accuracy: 0.6598\n",
      "Epoch 983/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1323 - accuracy: 0.9509 - val_loss: 0.3894 - val_accuracy: 0.8768\n",
      "Epoch 984/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1535 - accuracy: 0.9410 - val_loss: 0.4495 - val_accuracy: 0.8768\n",
      "Epoch 985/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1420 - accuracy: 0.9454 - val_loss: 0.4302 - val_accuracy: 0.8607\n",
      "Epoch 986/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1543 - accuracy: 0.9410 - val_loss: 0.4555 - val_accuracy: 0.8548\n",
      "Epoch 987/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1380 - accuracy: 0.9472 - val_loss: 0.4330 - val_accuracy: 0.8607\n",
      "Epoch 988/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1384 - accuracy: 0.9406 - val_loss: 0.4319 - val_accuracy: 0.8680\n",
      "Epoch 989/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1535 - accuracy: 0.9395 - val_loss: 0.4193 - val_accuracy: 0.8636\n",
      "Epoch 990/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1603 - accuracy: 0.9359 - val_loss: 0.4710 - val_accuracy: 0.8563\n",
      "Epoch 991/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1422 - accuracy: 0.9461 - val_loss: 0.4180 - val_accuracy: 0.8783\n",
      "Epoch 992/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1580 - accuracy: 0.9421 - val_loss: 0.3964 - val_accuracy: 0.8739\n",
      "Epoch 993/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1366 - accuracy: 0.9468 - val_loss: 0.4471 - val_accuracy: 0.8636\n",
      "Epoch 994/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1327 - accuracy: 0.9494 - val_loss: 0.7600 - val_accuracy: 0.8079\n",
      "Epoch 995/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1342 - accuracy: 0.9443 - val_loss: 0.6170 - val_accuracy: 0.8240\n",
      "Epoch 996/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1274 - accuracy: 0.9472 - val_loss: 0.4114 - val_accuracy: 0.8680\n",
      "Epoch 997/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1219 - accuracy: 0.9468 - val_loss: 0.4278 - val_accuracy: 0.8680\n",
      "Epoch 998/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1545 - accuracy: 0.9435 - val_loss: 0.4822 - val_accuracy: 0.8504\n",
      "Epoch 999/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1482 - accuracy: 0.9498 - val_loss: 0.4468 - val_accuracy: 0.8504\n",
      "Epoch 1000/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1302 - accuracy: 0.9512 - val_loss: 0.4573 - val_accuracy: 0.8622\n",
      "Epoch 1001/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1570 - accuracy: 0.9377 - val_loss: 0.4179 - val_accuracy: 0.8754\n",
      "Epoch 1002/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1311 - accuracy: 0.9476 - val_loss: 0.4306 - val_accuracy: 0.8695\n",
      "Epoch 1003/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1579 - accuracy: 0.9366 - val_loss: 1.2261 - val_accuracy: 0.7390\n",
      "Epoch 1004/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1496 - accuracy: 0.9395 - val_loss: 0.4399 - val_accuracy: 0.8563\n",
      "Epoch 1005/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1409 - accuracy: 0.9432 - val_loss: 0.4426 - val_accuracy: 0.8636\n",
      "Epoch 1006/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1341 - accuracy: 0.9479 - val_loss: 0.4089 - val_accuracy: 0.8754\n",
      "Epoch 1007/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1328 - accuracy: 0.9498 - val_loss: 0.4418 - val_accuracy: 0.8666\n",
      "Epoch 1008/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1258 - accuracy: 0.9457 - val_loss: 0.4549 - val_accuracy: 0.8592\n",
      "Epoch 1009/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1322 - accuracy: 0.9443 - val_loss: 0.4479 - val_accuracy: 0.8666\n",
      "Epoch 1010/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1403 - accuracy: 0.9421 - val_loss: 0.5365 - val_accuracy: 0.8622\n",
      "Epoch 1011/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1290 - accuracy: 0.9498 - val_loss: 0.4768 - val_accuracy: 0.8519\n",
      "Epoch 1012/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1269 - accuracy: 0.9476 - val_loss: 0.4068 - val_accuracy: 0.8798\n",
      "Epoch 1013/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1252 - accuracy: 0.9465 - val_loss: 0.6528 - val_accuracy: 0.8402\n",
      "Epoch 1014/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1229 - accuracy: 0.9487 - val_loss: 0.5738 - val_accuracy: 0.8431\n",
      "Epoch 1015/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1475 - accuracy: 0.9457 - val_loss: 0.4180 - val_accuracy: 0.8607\n",
      "Epoch 1016/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1154 - accuracy: 0.9527 - val_loss: 0.5554 - val_accuracy: 0.8299\n",
      "Epoch 1017/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1480 - accuracy: 0.9391 - val_loss: 0.4630 - val_accuracy: 0.8666\n",
      "Epoch 1018/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1535 - accuracy: 0.9417 - val_loss: 0.4078 - val_accuracy: 0.8666\n",
      "Epoch 1019/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1451 - accuracy: 0.9494 - val_loss: 0.4476 - val_accuracy: 0.8666\n",
      "Epoch 1020/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1532 - accuracy: 0.9439 - val_loss: 0.4520 - val_accuracy: 0.8534\n",
      "Epoch 1021/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1453 - accuracy: 0.9366 - val_loss: 0.5431 - val_accuracy: 0.8563\n",
      "Epoch 1022/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1389 - accuracy: 0.9454 - val_loss: 0.5075 - val_accuracy: 0.8504\n",
      "Epoch 1023/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1362 - accuracy: 0.9494 - val_loss: 0.4130 - val_accuracy: 0.8739\n",
      "Epoch 1024/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1381 - accuracy: 0.9450 - val_loss: 0.3785 - val_accuracy: 0.8900\n",
      "Epoch 1025/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1422 - accuracy: 0.9424 - val_loss: 0.4153 - val_accuracy: 0.8724\n",
      "Epoch 1026/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1318 - accuracy: 0.9476 - val_loss: 0.4240 - val_accuracy: 0.8651\n",
      "Epoch 1027/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1387 - accuracy: 0.9457 - val_loss: 0.3988 - val_accuracy: 0.8798\n",
      "Epoch 1028/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9531 - val_loss: 0.5566 - val_accuracy: 0.8343\n",
      "Epoch 1029/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9446 - val_loss: 0.3780 - val_accuracy: 0.8754\n",
      "Epoch 1030/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.9439 - val_loss: 0.4437 - val_accuracy: 0.8651\n",
      "Epoch 1031/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1251 - accuracy: 0.9494 - val_loss: 0.3878 - val_accuracy: 0.8768\n",
      "Epoch 1032/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1492 - accuracy: 0.9413 - val_loss: 0.3950 - val_accuracy: 0.8768\n",
      "Epoch 1033/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1490 - accuracy: 0.9359 - val_loss: 0.4067 - val_accuracy: 0.8754\n",
      "Epoch 1034/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1324 - accuracy: 0.9498 - val_loss: 0.3909 - val_accuracy: 0.8798\n",
      "Epoch 1035/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1349 - accuracy: 0.9454 - val_loss: 0.8273 - val_accuracy: 0.7977\n",
      "Epoch 1036/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1370 - accuracy: 0.9421 - val_loss: 0.4222 - val_accuracy: 0.8680\n",
      "Epoch 1037/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1205 - accuracy: 0.9490 - val_loss: 0.4497 - val_accuracy: 0.8578\n",
      "Epoch 1038/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1285 - accuracy: 0.9490 - val_loss: 0.4057 - val_accuracy: 0.8695\n",
      "Epoch 1039/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1452 - accuracy: 0.9439 - val_loss: 0.4407 - val_accuracy: 0.8607\n",
      "Epoch 1040/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9472 - val_loss: 0.4158 - val_accuracy: 0.8739\n",
      "Epoch 1041/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1361 - accuracy: 0.9432 - val_loss: 0.4696 - val_accuracy: 0.8622\n",
      "Epoch 1042/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9428 - val_loss: 0.4316 - val_accuracy: 0.8768\n",
      "Epoch 1043/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1428 - accuracy: 0.9454 - val_loss: 0.4368 - val_accuracy: 0.8666\n",
      "Epoch 1044/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1446 - accuracy: 0.9410 - val_loss: 0.4659 - val_accuracy: 0.8607\n",
      "Epoch 1045/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1275 - accuracy: 0.9479 - val_loss: 0.4392 - val_accuracy: 0.8680\n",
      "Epoch 1046/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1366 - accuracy: 0.9461 - val_loss: 0.8228 - val_accuracy: 0.7859\n",
      "Epoch 1047/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1294 - accuracy: 0.9498 - val_loss: 0.4673 - val_accuracy: 0.8592\n",
      "Epoch 1048/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1313 - accuracy: 0.9446 - val_loss: 0.4592 - val_accuracy: 0.8636\n",
      "Epoch 1049/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1255 - accuracy: 0.9465 - val_loss: 0.4420 - val_accuracy: 0.8622\n",
      "Epoch 1050/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1368 - accuracy: 0.9450 - val_loss: 0.4955 - val_accuracy: 0.8475\n",
      "Epoch 1051/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1305 - accuracy: 0.9476 - val_loss: 0.4610 - val_accuracy: 0.8563\n",
      "Epoch 1052/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1392 - accuracy: 0.9468 - val_loss: 0.6176 - val_accuracy: 0.8416\n",
      "Epoch 1053/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1249 - accuracy: 0.9523 - val_loss: 0.4403 - val_accuracy: 0.8651\n",
      "Epoch 1054/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1637 - accuracy: 0.9377 - val_loss: 0.4388 - val_accuracy: 0.8724\n",
      "Epoch 1055/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1424 - accuracy: 0.9439 - val_loss: 0.4168 - val_accuracy: 0.8739\n",
      "Epoch 1056/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1473 - accuracy: 0.9413 - val_loss: 0.4247 - val_accuracy: 0.8710\n",
      "Epoch 1057/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1357 - accuracy: 0.9483 - val_loss: 0.3979 - val_accuracy: 0.8754\n",
      "Epoch 1058/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1548 - accuracy: 0.9439 - val_loss: 0.4516 - val_accuracy: 0.8666\n",
      "Epoch 1059/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1977 - accuracy: 0.9245 - val_loss: 0.5137 - val_accuracy: 0.8534\n",
      "Epoch 1060/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1624 - accuracy: 0.9384 - val_loss: 0.5832 - val_accuracy: 0.8358\n",
      "Epoch 1061/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1553 - accuracy: 0.9446 - val_loss: 0.4023 - val_accuracy: 0.8651\n",
      "Epoch 1062/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1589 - accuracy: 0.9410 - val_loss: 0.5390 - val_accuracy: 0.8372\n",
      "Epoch 1063/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1427 - accuracy: 0.9468 - val_loss: 0.4148 - val_accuracy: 0.8739\n",
      "Epoch 1064/7000\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1275 - accuracy: 0.9465 - val_loss: 0.9244 - val_accuracy: 0.7771\n",
      "Epoch 1065/7000\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1495 - accuracy: 0.9450 - val_loss: 0.5445 - val_accuracy: 0.8402\n",
      "Epoch 1066/7000\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1443 - accuracy: 0.9435 - val_loss: 0.5766 - val_accuracy: 0.8343\n",
      "Epoch 1067/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1455 - accuracy: 0.9417 - val_loss: 0.3739 - val_accuracy: 0.8827\n",
      "Epoch 1068/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1582 - accuracy: 0.9413 - val_loss: 0.4505 - val_accuracy: 0.8534\n",
      "Epoch 1069/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1449 - accuracy: 0.9410 - val_loss: 0.4016 - val_accuracy: 0.8607\n",
      "Epoch 1070/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1496 - accuracy: 0.9384 - val_loss: 0.5389 - val_accuracy: 0.8387\n",
      "Epoch 1071/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1316 - accuracy: 0.9490 - val_loss: 0.4110 - val_accuracy: 0.8666\n",
      "Epoch 1072/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1313 - accuracy: 0.9483 - val_loss: 0.4018 - val_accuracy: 0.8856\n",
      "Epoch 1073/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1357 - accuracy: 0.9432 - val_loss: 0.4128 - val_accuracy: 0.8651\n",
      "Epoch 1074/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1378 - accuracy: 0.9476 - val_loss: 0.4141 - val_accuracy: 0.8680\n",
      "Epoch 1075/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1331 - accuracy: 0.9483 - val_loss: 0.4057 - val_accuracy: 0.8724\n",
      "Epoch 1076/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1274 - accuracy: 0.9468 - val_loss: 0.4869 - val_accuracy: 0.8578\n",
      "Epoch 1077/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1352 - accuracy: 0.9461 - val_loss: 0.6190 - val_accuracy: 0.8372\n",
      "Epoch 1078/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1307 - accuracy: 0.9487 - val_loss: 0.3794 - val_accuracy: 0.8768\n",
      "Epoch 1079/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1317 - accuracy: 0.9531 - val_loss: 0.4274 - val_accuracy: 0.8636\n",
      "Epoch 1080/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1400 - accuracy: 0.9432 - val_loss: 0.4658 - val_accuracy: 0.8578\n",
      "Epoch 1081/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1278 - accuracy: 0.9494 - val_loss: 0.3783 - val_accuracy: 0.8812\n",
      "Epoch 1082/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1393 - accuracy: 0.9446 - val_loss: 0.5213 - val_accuracy: 0.8416\n",
      "Epoch 1083/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1233 - accuracy: 0.9476 - val_loss: 0.4639 - val_accuracy: 0.8666\n",
      "Epoch 1084/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1337 - accuracy: 0.9490 - val_loss: 0.4314 - val_accuracy: 0.8768\n",
      "Epoch 1085/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1341 - accuracy: 0.9424 - val_loss: 0.4266 - val_accuracy: 0.8680\n",
      "Epoch 1086/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9465 - val_loss: 0.3999 - val_accuracy: 0.8710\n",
      "Epoch 1087/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1446 - accuracy: 0.9446 - val_loss: 0.4034 - val_accuracy: 0.8651\n",
      "Epoch 1088/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1234 - accuracy: 0.9505 - val_loss: 0.4852 - val_accuracy: 0.8578\n",
      "Epoch 1089/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1476 - accuracy: 0.9384 - val_loss: 0.5495 - val_accuracy: 0.8328\n",
      "Epoch 1090/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1363 - accuracy: 0.9472 - val_loss: 0.3992 - val_accuracy: 0.8651\n",
      "Epoch 1091/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.9465 - val_loss: 1.1652 - val_accuracy: 0.7493\n",
      "Epoch 1092/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9490 - val_loss: 0.3879 - val_accuracy: 0.8739\n",
      "Epoch 1093/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1455 - accuracy: 0.9457 - val_loss: 0.4163 - val_accuracy: 0.8842\n",
      "Epoch 1094/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1318 - accuracy: 0.9483 - val_loss: 0.4807 - val_accuracy: 0.8651\n",
      "Epoch 1095/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1300 - accuracy: 0.9479 - val_loss: 0.4430 - val_accuracy: 0.8651\n",
      "Epoch 1096/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1329 - accuracy: 0.9461 - val_loss: 0.4758 - val_accuracy: 0.8534\n",
      "Epoch 1097/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1441 - accuracy: 0.9421 - val_loss: 0.4212 - val_accuracy: 0.8768\n",
      "Epoch 1098/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1422 - accuracy: 0.9461 - val_loss: 0.4533 - val_accuracy: 0.8754\n",
      "Epoch 1099/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1300 - accuracy: 0.9501 - val_loss: 0.4512 - val_accuracy: 0.8680\n",
      "Epoch 1100/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1231 - accuracy: 0.9549 - val_loss: 0.5318 - val_accuracy: 0.8490\n",
      "Epoch 1101/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1347 - accuracy: 0.9432 - val_loss: 0.4904 - val_accuracy: 0.8504\n",
      "Epoch 1102/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1288 - accuracy: 0.9428 - val_loss: 0.6674 - val_accuracy: 0.8284\n",
      "Epoch 1103/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1314 - accuracy: 0.9479 - val_loss: 0.4157 - val_accuracy: 0.8680\n",
      "Epoch 1104/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1360 - accuracy: 0.9523 - val_loss: 0.4030 - val_accuracy: 0.8739\n",
      "Epoch 1105/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9465 - val_loss: 0.4021 - val_accuracy: 0.8768\n",
      "Epoch 1106/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1461 - accuracy: 0.9443 - val_loss: 0.3960 - val_accuracy: 0.8739\n",
      "Epoch 1107/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1270 - accuracy: 0.9479 - val_loss: 0.4235 - val_accuracy: 0.8666\n",
      "Epoch 1108/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1334 - accuracy: 0.9476 - val_loss: 0.3949 - val_accuracy: 0.8768\n",
      "Epoch 1109/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1311 - accuracy: 0.9483 - val_loss: 0.3961 - val_accuracy: 0.8754\n",
      "Epoch 1110/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1377 - accuracy: 0.9479 - val_loss: 0.4287 - val_accuracy: 0.8666\n",
      "Epoch 1111/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1180 - accuracy: 0.9520 - val_loss: 1.0098 - val_accuracy: 0.7903\n",
      "Epoch 1112/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1306 - accuracy: 0.9494 - val_loss: 0.5764 - val_accuracy: 0.8431\n",
      "Epoch 1113/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1350 - accuracy: 0.9483 - val_loss: 0.4072 - val_accuracy: 0.8783\n",
      "Epoch 1114/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1285 - accuracy: 0.9487 - val_loss: 0.3860 - val_accuracy: 0.8856\n",
      "Epoch 1115/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1362 - accuracy: 0.9457 - val_loss: 0.4890 - val_accuracy: 0.8475\n",
      "Epoch 1116/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1241 - accuracy: 0.9538 - val_loss: 0.4159 - val_accuracy: 0.8768\n",
      "Epoch 1117/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1426 - accuracy: 0.9413 - val_loss: 0.4120 - val_accuracy: 0.8724\n",
      "Epoch 1118/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1266 - accuracy: 0.9505 - val_loss: 0.3897 - val_accuracy: 0.8710\n",
      "Epoch 1119/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1349 - accuracy: 0.9450 - val_loss: 0.3977 - val_accuracy: 0.8739\n",
      "Epoch 1120/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1246 - accuracy: 0.9501 - val_loss: 0.5050 - val_accuracy: 0.8446\n",
      "Epoch 1121/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1366 - accuracy: 0.9461 - val_loss: 0.4077 - val_accuracy: 0.8827\n",
      "Epoch 1122/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1222 - accuracy: 0.9516 - val_loss: 0.5960 - val_accuracy: 0.8475\n",
      "Epoch 1123/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1243 - accuracy: 0.9498 - val_loss: 0.4070 - val_accuracy: 0.8768\n",
      "Epoch 1124/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1350 - accuracy: 0.9498 - val_loss: 0.6512 - val_accuracy: 0.8240\n",
      "Epoch 1125/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1272 - accuracy: 0.9509 - val_loss: 0.6187 - val_accuracy: 0.8446\n",
      "Epoch 1126/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1471 - accuracy: 0.9417 - val_loss: 0.4137 - val_accuracy: 0.8695\n",
      "Epoch 1127/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1285 - accuracy: 0.9454 - val_loss: 0.4570 - val_accuracy: 0.8592\n",
      "Epoch 1128/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1325 - accuracy: 0.9487 - val_loss: 1.3260 - val_accuracy: 0.7493\n",
      "Epoch 1129/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.4218 - val_accuracy: 0.8739\n",
      "Epoch 1130/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1241 - accuracy: 0.9487 - val_loss: 0.4867 - val_accuracy: 0.8504\n",
      "Epoch 1131/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1331 - accuracy: 0.9472 - val_loss: 0.4221 - val_accuracy: 0.8695\n",
      "Epoch 1132/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1220 - accuracy: 0.9523 - val_loss: 2.2165 - val_accuracy: 0.6188\n",
      "Epoch 1133/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1387 - accuracy: 0.9432 - val_loss: 0.5924 - val_accuracy: 0.8182\n",
      "Epoch 1134/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1261 - accuracy: 0.9501 - val_loss: 0.4122 - val_accuracy: 0.8724\n",
      "Epoch 1135/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1308 - accuracy: 0.9443 - val_loss: 0.4392 - val_accuracy: 0.8827\n",
      "Epoch 1136/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1282 - accuracy: 0.9501 - val_loss: 0.4999 - val_accuracy: 0.8563\n",
      "Epoch 1137/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1369 - accuracy: 0.9454 - val_loss: 0.4202 - val_accuracy: 0.8724\n",
      "Epoch 1138/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1173 - accuracy: 0.9523 - val_loss: 0.4116 - val_accuracy: 0.8578\n",
      "Epoch 1139/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1247 - accuracy: 0.9501 - val_loss: 0.4356 - val_accuracy: 0.8666\n",
      "Epoch 1140/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1240 - accuracy: 0.9549 - val_loss: 0.4029 - val_accuracy: 0.8798\n",
      "Epoch 1141/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1305 - accuracy: 0.9494 - val_loss: 0.6096 - val_accuracy: 0.8270\n",
      "Epoch 1142/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1245 - accuracy: 0.9476 - val_loss: 0.4162 - val_accuracy: 0.8783\n",
      "Epoch 1143/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1241 - accuracy: 0.9487 - val_loss: 0.4360 - val_accuracy: 0.8695\n",
      "Epoch 1144/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1276 - accuracy: 0.9531 - val_loss: 0.4540 - val_accuracy: 0.8636\n",
      "Epoch 1145/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1177 - accuracy: 0.9494 - val_loss: 0.7151 - val_accuracy: 0.8050\n",
      "Epoch 1146/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1268 - accuracy: 0.9487 - val_loss: 0.4206 - val_accuracy: 0.8754\n",
      "Epoch 1147/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9446 - val_loss: 0.4346 - val_accuracy: 0.8592\n",
      "Epoch 1148/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1348 - accuracy: 0.9483 - val_loss: 0.7128 - val_accuracy: 0.8226\n",
      "Epoch 1149/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1341 - accuracy: 0.9465 - val_loss: 0.3929 - val_accuracy: 0.8856\n",
      "Epoch 1150/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1212 - accuracy: 0.9538 - val_loss: 0.9240 - val_accuracy: 0.7801\n",
      "Epoch 1151/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1142 - accuracy: 0.9542 - val_loss: 0.4906 - val_accuracy: 0.8446\n",
      "Epoch 1152/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1236 - accuracy: 0.9501 - val_loss: 0.4259 - val_accuracy: 0.8680\n",
      "Epoch 1153/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1298 - accuracy: 0.9472 - val_loss: 0.6110 - val_accuracy: 0.8299\n",
      "Epoch 1154/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9454 - val_loss: 0.4072 - val_accuracy: 0.8739\n",
      "Epoch 1155/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1277 - accuracy: 0.9450 - val_loss: 0.4245 - val_accuracy: 0.8724\n",
      "Epoch 1156/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1277 - accuracy: 0.9505 - val_loss: 0.3836 - val_accuracy: 0.8842\n",
      "Epoch 1157/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1163 - accuracy: 0.9578 - val_loss: 0.4039 - val_accuracy: 0.8695\n",
      "Epoch 1158/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1255 - accuracy: 0.9501 - val_loss: 0.4416 - val_accuracy: 0.8563\n",
      "Epoch 1159/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1331 - accuracy: 0.9457 - val_loss: 0.4848 - val_accuracy: 0.8519\n",
      "Epoch 1160/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1279 - accuracy: 0.9472 - val_loss: 0.4727 - val_accuracy: 0.8460\n",
      "Epoch 1161/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1163 - accuracy: 0.9523 - val_loss: 0.3984 - val_accuracy: 0.8783\n",
      "Epoch 1162/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1104 - accuracy: 0.9564 - val_loss: 0.3955 - val_accuracy: 0.8739\n",
      "Epoch 1163/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1306 - accuracy: 0.9509 - val_loss: 0.4172 - val_accuracy: 0.8710\n",
      "Epoch 1164/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1253 - accuracy: 0.9483 - val_loss: 0.5304 - val_accuracy: 0.8328\n",
      "Epoch 1165/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1178 - accuracy: 0.9545 - val_loss: 0.4283 - val_accuracy: 0.8666\n",
      "Epoch 1166/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1230 - accuracy: 0.9549 - val_loss: 0.4152 - val_accuracy: 0.8666\n",
      "Epoch 1167/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1202 - accuracy: 0.9520 - val_loss: 0.3820 - val_accuracy: 0.8739\n",
      "Epoch 1168/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1431 - accuracy: 0.9450 - val_loss: 0.3771 - val_accuracy: 0.8651\n",
      "Epoch 1169/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1239 - accuracy: 0.9523 - val_loss: 0.3902 - val_accuracy: 0.8680\n",
      "Epoch 1170/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1103 - accuracy: 0.9571 - val_loss: 0.3905 - val_accuracy: 0.8724\n",
      "Epoch 1171/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1278 - accuracy: 0.9479 - val_loss: 0.4064 - val_accuracy: 0.8607\n",
      "Epoch 1172/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1194 - accuracy: 0.9512 - val_loss: 0.4755 - val_accuracy: 0.8504\n",
      "Epoch 1173/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1229 - accuracy: 0.9487 - val_loss: 0.3811 - val_accuracy: 0.8812\n",
      "Epoch 1174/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1104 - accuracy: 0.9538 - val_loss: 0.4267 - val_accuracy: 0.8680\n",
      "Epoch 1175/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1213 - accuracy: 0.9549 - val_loss: 0.5969 - val_accuracy: 0.8270\n",
      "Epoch 1176/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9501 - val_loss: 0.3864 - val_accuracy: 0.8798\n",
      "Epoch 1177/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1183 - accuracy: 0.9520 - val_loss: 0.4105 - val_accuracy: 0.8695\n",
      "Epoch 1178/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1206 - accuracy: 0.9523 - val_loss: 0.3783 - val_accuracy: 0.8739\n",
      "Epoch 1179/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1264 - accuracy: 0.9490 - val_loss: 0.4090 - val_accuracy: 0.8739\n",
      "Epoch 1180/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1437 - accuracy: 0.9450 - val_loss: 0.4362 - val_accuracy: 0.8607\n",
      "Epoch 1181/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1115 - accuracy: 0.9556 - val_loss: 0.4634 - val_accuracy: 0.8636\n",
      "Epoch 1182/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1210 - accuracy: 0.9516 - val_loss: 0.4223 - val_accuracy: 0.8651\n",
      "Epoch 1183/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9428 - val_loss: 0.4151 - val_accuracy: 0.8695\n",
      "Epoch 1184/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1195 - accuracy: 0.9538 - val_loss: 0.4211 - val_accuracy: 0.8739\n",
      "Epoch 1185/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1327 - accuracy: 0.9483 - val_loss: 0.5280 - val_accuracy: 0.8490\n",
      "Epoch 1186/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1135 - accuracy: 0.9571 - val_loss: 0.4429 - val_accuracy: 0.8666\n",
      "Epoch 1187/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1141 - accuracy: 0.9534 - val_loss: 0.5171 - val_accuracy: 0.8446\n",
      "Epoch 1188/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1138 - accuracy: 0.9553 - val_loss: 0.4064 - val_accuracy: 0.8754\n",
      "Epoch 1189/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1205 - accuracy: 0.9549 - val_loss: 0.5225 - val_accuracy: 0.8431\n",
      "Epoch 1190/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1177 - accuracy: 0.9531 - val_loss: 0.4089 - val_accuracy: 0.8827\n",
      "Epoch 1191/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9435 - val_loss: 0.4792 - val_accuracy: 0.8519\n",
      "Epoch 1192/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1179 - accuracy: 0.9553 - val_loss: 0.3970 - val_accuracy: 0.8798\n",
      "Epoch 1193/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1146 - accuracy: 0.9604 - val_loss: 0.3923 - val_accuracy: 0.8768\n",
      "Epoch 1194/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1242 - accuracy: 0.9534 - val_loss: 0.4182 - val_accuracy: 0.8680\n",
      "Epoch 1195/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1300 - accuracy: 0.9472 - val_loss: 0.4020 - val_accuracy: 0.8754\n",
      "Epoch 1196/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1450 - accuracy: 0.9457 - val_loss: 0.4580 - val_accuracy: 0.8563\n",
      "Epoch 1197/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1320 - accuracy: 0.9450 - val_loss: 0.4104 - val_accuracy: 0.8768\n",
      "Epoch 1198/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1187 - accuracy: 0.9531 - val_loss: 0.6467 - val_accuracy: 0.8240\n",
      "Epoch 1199/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1263 - accuracy: 0.9516 - val_loss: 0.4331 - val_accuracy: 0.8798\n",
      "Epoch 1200/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1171 - accuracy: 0.9527 - val_loss: 0.5336 - val_accuracy: 0.8534\n",
      "Epoch 1201/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1256 - accuracy: 0.9501 - val_loss: 0.4508 - val_accuracy: 0.8636\n",
      "Epoch 1202/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1226 - accuracy: 0.9549 - val_loss: 0.4536 - val_accuracy: 0.8578\n",
      "Epoch 1203/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1288 - accuracy: 0.9483 - val_loss: 0.3975 - val_accuracy: 0.8754\n",
      "Epoch 1204/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1238 - accuracy: 0.9490 - val_loss: 0.4767 - val_accuracy: 0.8416\n",
      "Epoch 1205/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1326 - accuracy: 0.9454 - val_loss: 0.4395 - val_accuracy: 0.8622\n",
      "Epoch 1206/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1405 - accuracy: 0.9457 - val_loss: 0.5149 - val_accuracy: 0.8490\n",
      "Epoch 1207/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1249 - accuracy: 0.9490 - val_loss: 0.4661 - val_accuracy: 0.8592\n",
      "Epoch 1208/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1439 - accuracy: 0.9421 - val_loss: 0.4170 - val_accuracy: 0.8871\n",
      "Epoch 1209/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1157 - accuracy: 0.9545 - val_loss: 0.4433 - val_accuracy: 0.8724\n",
      "Epoch 1210/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1234 - accuracy: 0.9534 - val_loss: 0.5506 - val_accuracy: 0.8416\n",
      "Epoch 1211/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1368 - accuracy: 0.9505 - val_loss: 0.3986 - val_accuracy: 0.8710\n",
      "Epoch 1212/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1201 - accuracy: 0.9538 - val_loss: 0.5069 - val_accuracy: 0.8460\n",
      "Epoch 1213/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1201 - accuracy: 0.9531 - val_loss: 0.4406 - val_accuracy: 0.8636\n",
      "Epoch 1214/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1302 - accuracy: 0.9465 - val_loss: 0.3928 - val_accuracy: 0.8798\n",
      "Epoch 1215/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1343 - accuracy: 0.9476 - val_loss: 0.4209 - val_accuracy: 0.8622\n",
      "Epoch 1216/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1189 - accuracy: 0.9578 - val_loss: 0.4001 - val_accuracy: 0.8695\n",
      "Epoch 1217/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1255 - accuracy: 0.9501 - val_loss: 0.4455 - val_accuracy: 0.8651\n",
      "Epoch 1218/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1236 - accuracy: 0.9542 - val_loss: 0.4160 - val_accuracy: 0.8739\n",
      "Epoch 1219/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1245 - accuracy: 0.9479 - val_loss: 0.4080 - val_accuracy: 0.8754\n",
      "Epoch 1220/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1289 - accuracy: 0.9505 - val_loss: 0.4825 - val_accuracy: 0.8666\n",
      "Epoch 1221/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1012 - accuracy: 0.9615 - val_loss: 0.4232 - val_accuracy: 0.8710\n",
      "Epoch 1222/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2197 - accuracy: 0.9293 - val_loss: 1.5582 - val_accuracy: 0.6730\n",
      "Epoch 1223/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2177 - accuracy: 0.9223 - val_loss: 0.9372 - val_accuracy: 0.7654\n",
      "Epoch 1224/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1745 - accuracy: 0.9344 - val_loss: 0.4980 - val_accuracy: 0.8666\n",
      "Epoch 1225/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1669 - accuracy: 0.9359 - val_loss: 0.4394 - val_accuracy: 0.8651\n",
      "Epoch 1226/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1429 - accuracy: 0.9399 - val_loss: 0.4054 - val_accuracy: 0.8651\n",
      "Epoch 1227/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1685 - accuracy: 0.9373 - val_loss: 0.4467 - val_accuracy: 0.8519\n",
      "Epoch 1228/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1594 - accuracy: 0.9373 - val_loss: 0.4319 - val_accuracy: 0.8724\n",
      "Epoch 1229/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1462 - accuracy: 0.9402 - val_loss: 0.3829 - val_accuracy: 0.8724\n",
      "Epoch 1230/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1276 - accuracy: 0.9494 - val_loss: 0.3654 - val_accuracy: 0.8842\n",
      "Epoch 1231/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1368 - accuracy: 0.9461 - val_loss: 0.3870 - val_accuracy: 0.8783\n",
      "Epoch 1232/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1392 - accuracy: 0.9483 - val_loss: 0.3748 - val_accuracy: 0.8783\n",
      "Epoch 1233/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1500 - accuracy: 0.9457 - val_loss: 0.3900 - val_accuracy: 0.8754\n",
      "Epoch 1234/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1245 - accuracy: 0.9479 - val_loss: 0.3844 - val_accuracy: 0.8871\n",
      "Epoch 1235/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1427 - accuracy: 0.9384 - val_loss: 0.4202 - val_accuracy: 0.8695\n",
      "Epoch 1236/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1318 - accuracy: 0.9487 - val_loss: 0.4294 - val_accuracy: 0.8636\n",
      "Epoch 1237/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1300 - accuracy: 0.9443 - val_loss: 0.3875 - val_accuracy: 0.8739\n",
      "Epoch 1238/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1480 - accuracy: 0.9406 - val_loss: 0.3895 - val_accuracy: 0.8798\n",
      "Epoch 1239/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1398 - accuracy: 0.9432 - val_loss: 0.4272 - val_accuracy: 0.8710\n",
      "Epoch 1240/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1323 - accuracy: 0.9505 - val_loss: 0.4546 - val_accuracy: 0.8563\n",
      "Epoch 1241/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1324 - accuracy: 0.9509 - val_loss: 0.4165 - val_accuracy: 0.8636\n",
      "Epoch 1242/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1369 - accuracy: 0.9450 - val_loss: 0.4165 - val_accuracy: 0.8768\n",
      "Epoch 1243/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1442 - accuracy: 0.9435 - val_loss: 0.4427 - val_accuracy: 0.8548\n",
      "Epoch 1244/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9501 - val_loss: 0.4294 - val_accuracy: 0.8636\n",
      "Epoch 1245/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1423 - accuracy: 0.9461 - val_loss: 0.4318 - val_accuracy: 0.8578\n",
      "Epoch 1246/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1253 - accuracy: 0.9443 - val_loss: 0.3997 - val_accuracy: 0.8724\n",
      "Epoch 1247/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1238 - accuracy: 0.9505 - val_loss: 0.3881 - val_accuracy: 0.8724\n",
      "Epoch 1248/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1298 - accuracy: 0.9468 - val_loss: 0.6573 - val_accuracy: 0.8299\n",
      "Epoch 1249/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1372 - accuracy: 0.9494 - val_loss: 0.3905 - val_accuracy: 0.8710\n",
      "Epoch 1250/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1232 - accuracy: 0.9545 - val_loss: 0.4136 - val_accuracy: 0.8724\n",
      "Epoch 1251/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1250 - accuracy: 0.9512 - val_loss: 0.4259 - val_accuracy: 0.8739\n",
      "Epoch 1252/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1245 - accuracy: 0.9494 - val_loss: 0.3877 - val_accuracy: 0.8798\n",
      "Epoch 1253/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1261 - accuracy: 0.9494 - val_loss: 0.3895 - val_accuracy: 0.8783\n",
      "Epoch 1254/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1192 - accuracy: 0.9498 - val_loss: 0.4167 - val_accuracy: 0.8636\n",
      "Epoch 1255/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1290 - accuracy: 0.9446 - val_loss: 0.4044 - val_accuracy: 0.8768\n",
      "Epoch 1256/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1231 - accuracy: 0.9545 - val_loss: 0.4212 - val_accuracy: 0.8563\n",
      "Epoch 1257/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1256 - accuracy: 0.9553 - val_loss: 0.4500 - val_accuracy: 0.8651\n",
      "Epoch 1258/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1439 - accuracy: 0.9410 - val_loss: 0.7379 - val_accuracy: 0.8050\n",
      "Epoch 1259/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1394 - accuracy: 0.9468 - val_loss: 0.4163 - val_accuracy: 0.8724\n",
      "Epoch 1260/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1257 - accuracy: 0.9501 - val_loss: 0.4220 - val_accuracy: 0.8812\n",
      "Epoch 1261/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1433 - accuracy: 0.9487 - val_loss: 0.3854 - val_accuracy: 0.8798\n",
      "Epoch 1262/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1336 - accuracy: 0.9487 - val_loss: 0.3900 - val_accuracy: 0.8768\n",
      "Epoch 1263/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1274 - accuracy: 0.9494 - val_loss: 0.4385 - val_accuracy: 0.8695\n",
      "Epoch 1264/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1301 - accuracy: 0.9472 - val_loss: 0.4062 - val_accuracy: 0.8812\n",
      "Epoch 1265/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1092 - accuracy: 0.9593 - val_loss: 0.4143 - val_accuracy: 0.8798\n",
      "Epoch 1266/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1477 - accuracy: 0.9443 - val_loss: 0.4448 - val_accuracy: 0.8592\n",
      "Epoch 1267/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1143 - accuracy: 0.9567 - val_loss: 0.4384 - val_accuracy: 0.8680\n",
      "Epoch 1268/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1396 - accuracy: 0.9417 - val_loss: 0.5835 - val_accuracy: 0.8314\n",
      "Epoch 1269/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1350 - accuracy: 0.9443 - val_loss: 0.4287 - val_accuracy: 0.8768\n",
      "Epoch 1270/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1262 - accuracy: 0.9567 - val_loss: 0.4002 - val_accuracy: 0.8871\n",
      "Epoch 1271/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1096 - accuracy: 0.9549 - val_loss: 0.3879 - val_accuracy: 0.8754\n",
      "Epoch 1272/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1173 - accuracy: 0.9549 - val_loss: 0.3936 - val_accuracy: 0.8695\n",
      "Epoch 1273/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1251 - accuracy: 0.9479 - val_loss: 0.3953 - val_accuracy: 0.8768\n",
      "Epoch 1274/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1293 - accuracy: 0.9505 - val_loss: 0.3885 - val_accuracy: 0.8636\n",
      "Epoch 1275/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1259 - accuracy: 0.9487 - val_loss: 0.4493 - val_accuracy: 0.8724\n",
      "Epoch 1276/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1167 - accuracy: 0.9534 - val_loss: 0.3951 - val_accuracy: 0.8768\n",
      "Epoch 1277/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1212 - accuracy: 0.9512 - val_loss: 0.4379 - val_accuracy: 0.8695\n",
      "Epoch 1278/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1299 - accuracy: 0.9509 - val_loss: 0.4174 - val_accuracy: 0.8798\n",
      "Epoch 1279/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1153 - accuracy: 0.9567 - val_loss: 0.3933 - val_accuracy: 0.8710\n",
      "Epoch 1280/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1148 - accuracy: 0.9549 - val_loss: 0.3995 - val_accuracy: 0.8754\n",
      "Epoch 1281/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1317 - accuracy: 0.9494 - val_loss: 0.4050 - val_accuracy: 0.8754\n",
      "Epoch 1282/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1280 - accuracy: 0.9487 - val_loss: 0.4416 - val_accuracy: 0.8622\n",
      "Epoch 1283/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1245 - accuracy: 0.9509 - val_loss: 0.4336 - val_accuracy: 0.8607\n",
      "Epoch 1284/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1358 - accuracy: 0.9476 - val_loss: 0.3912 - val_accuracy: 0.8768\n",
      "Epoch 1285/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1398 - accuracy: 0.9454 - val_loss: 0.4264 - val_accuracy: 0.8710\n",
      "Epoch 1286/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1357 - accuracy: 0.9494 - val_loss: 0.5967 - val_accuracy: 0.8358\n",
      "Epoch 1287/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1163 - accuracy: 0.9545 - val_loss: 0.4040 - val_accuracy: 0.8754\n",
      "Epoch 1288/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1240 - accuracy: 0.9494 - val_loss: 0.5749 - val_accuracy: 0.8416\n",
      "Epoch 1289/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1296 - accuracy: 0.9527 - val_loss: 0.5840 - val_accuracy: 0.8402\n",
      "Epoch 1290/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1325 - accuracy: 0.9501 - val_loss: 0.4006 - val_accuracy: 0.8812\n",
      "Epoch 1291/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1244 - accuracy: 0.9472 - val_loss: 0.4345 - val_accuracy: 0.8666\n",
      "Epoch 1292/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1312 - accuracy: 0.9472 - val_loss: 0.4134 - val_accuracy: 0.8680\n",
      "Epoch 1293/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1276 - accuracy: 0.9490 - val_loss: 0.4319 - val_accuracy: 0.8739\n",
      "Epoch 1294/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1229 - accuracy: 0.9487 - val_loss: 0.4067 - val_accuracy: 0.8768\n",
      "Epoch 1295/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1069 - accuracy: 0.9575 - val_loss: 0.4091 - val_accuracy: 0.8812\n",
      "Epoch 1296/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1121 - accuracy: 0.9575 - val_loss: 0.3905 - val_accuracy: 0.8798\n",
      "Epoch 1297/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1083 - accuracy: 0.9611 - val_loss: 0.4197 - val_accuracy: 0.8754\n",
      "Epoch 1298/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1338 - accuracy: 0.9465 - val_loss: 0.4335 - val_accuracy: 0.8622\n",
      "Epoch 1299/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1331 - accuracy: 0.9461 - val_loss: 0.4636 - val_accuracy: 0.8607\n",
      "Epoch 1300/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1266 - accuracy: 0.9538 - val_loss: 0.3950 - val_accuracy: 0.8724\n",
      "Epoch 1301/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1312 - accuracy: 0.9454 - val_loss: 0.4527 - val_accuracy: 0.8651\n",
      "Epoch 1302/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1284 - accuracy: 0.9472 - val_loss: 0.4019 - val_accuracy: 0.8783\n",
      "Epoch 1303/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1294 - accuracy: 0.9479 - val_loss: 0.7872 - val_accuracy: 0.8035\n",
      "Epoch 1304/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1221 - accuracy: 0.9531 - val_loss: 0.4221 - val_accuracy: 0.8783\n",
      "Epoch 1305/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1246 - accuracy: 0.9564 - val_loss: 0.4182 - val_accuracy: 0.8710\n",
      "Epoch 1306/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1115 - accuracy: 0.9553 - val_loss: 0.4158 - val_accuracy: 0.8768\n",
      "Epoch 1307/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1184 - accuracy: 0.9545 - val_loss: 0.4380 - val_accuracy: 0.8768\n",
      "Epoch 1308/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1159 - accuracy: 0.9564 - val_loss: 0.4874 - val_accuracy: 0.8636\n",
      "Epoch 1309/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1262 - accuracy: 0.9501 - val_loss: 0.5228 - val_accuracy: 0.8666\n",
      "Epoch 1310/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1127 - accuracy: 0.9527 - val_loss: 0.7303 - val_accuracy: 0.8035\n",
      "Epoch 1311/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1278 - accuracy: 0.9523 - val_loss: 0.3998 - val_accuracy: 0.8827\n",
      "Epoch 1312/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1296 - accuracy: 0.9516 - val_loss: 0.4360 - val_accuracy: 0.8666\n",
      "Epoch 1313/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1130 - accuracy: 0.9527 - val_loss: 0.4150 - val_accuracy: 0.8768\n",
      "Epoch 1314/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1201 - accuracy: 0.9472 - val_loss: 0.5174 - val_accuracy: 0.8534\n",
      "Epoch 1315/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1241 - accuracy: 0.9520 - val_loss: 0.4729 - val_accuracy: 0.8724\n",
      "Epoch 1316/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1377 - accuracy: 0.9498 - val_loss: 0.4325 - val_accuracy: 0.8739\n",
      "Epoch 1317/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1178 - accuracy: 0.9494 - val_loss: 0.4720 - val_accuracy: 0.8563\n",
      "Epoch 1318/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1146 - accuracy: 0.9534 - val_loss: 0.4111 - val_accuracy: 0.8724\n",
      "Epoch 1319/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1201 - accuracy: 0.9505 - val_loss: 0.4189 - val_accuracy: 0.8710\n",
      "Epoch 1320/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1091 - accuracy: 0.9582 - val_loss: 0.4216 - val_accuracy: 0.8680\n",
      "Epoch 1321/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1302 - accuracy: 0.9494 - val_loss: 0.4312 - val_accuracy: 0.8724\n",
      "Epoch 1322/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1142 - accuracy: 0.9527 - val_loss: 0.4402 - val_accuracy: 0.8695\n",
      "Epoch 1323/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1108 - accuracy: 0.9586 - val_loss: 0.4368 - val_accuracy: 0.8680\n",
      "Epoch 1324/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1209 - accuracy: 0.9468 - val_loss: 0.5580 - val_accuracy: 0.8534\n",
      "Epoch 1325/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1200 - accuracy: 0.9534 - val_loss: 0.5241 - val_accuracy: 0.8534\n",
      "Epoch 1326/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1169 - accuracy: 0.9538 - val_loss: 0.4381 - val_accuracy: 0.8695\n",
      "Epoch 1327/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1162 - accuracy: 0.9553 - val_loss: 0.4222 - val_accuracy: 0.8827\n",
      "Epoch 1328/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1152 - accuracy: 0.9593 - val_loss: 0.4208 - val_accuracy: 0.8812\n",
      "Epoch 1329/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1195 - accuracy: 0.9538 - val_loss: 0.4229 - val_accuracy: 0.8636\n",
      "Epoch 1330/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1061 - accuracy: 0.9553 - val_loss: 0.4473 - val_accuracy: 0.8651\n",
      "Epoch 1331/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1088 - accuracy: 0.9531 - val_loss: 0.4355 - val_accuracy: 0.8724\n",
      "Epoch 1332/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1138 - accuracy: 0.9560 - val_loss: 0.5527 - val_accuracy: 0.8475\n",
      "Epoch 1333/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1232 - accuracy: 0.9498 - val_loss: 0.4561 - val_accuracy: 0.8651\n",
      "Epoch 1334/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1264 - accuracy: 0.9490 - val_loss: 0.4681 - val_accuracy: 0.8666\n",
      "Epoch 1335/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1140 - accuracy: 0.9560 - val_loss: 0.5064 - val_accuracy: 0.8592\n",
      "Epoch 1336/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1125 - accuracy: 0.9560 - val_loss: 0.4388 - val_accuracy: 0.8724\n",
      "Epoch 1337/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1250 - accuracy: 0.9476 - val_loss: 0.4804 - val_accuracy: 0.8710\n",
      "Epoch 1338/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1333 - accuracy: 0.9523 - val_loss: 0.5021 - val_accuracy: 0.8563\n",
      "Epoch 1339/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1196 - accuracy: 0.9501 - val_loss: 0.5301 - val_accuracy: 0.8460\n",
      "Epoch 1340/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1157 - accuracy: 0.9549 - val_loss: 0.4806 - val_accuracy: 0.8636\n",
      "Epoch 1341/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1172 - accuracy: 0.9556 - val_loss: 0.4348 - val_accuracy: 0.8724\n",
      "Epoch 1342/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1245 - accuracy: 0.9490 - val_loss: 0.4249 - val_accuracy: 0.8636\n",
      "Epoch 1343/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1188 - accuracy: 0.9542 - val_loss: 0.5358 - val_accuracy: 0.8534\n",
      "Epoch 1344/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.4948 - val_accuracy: 0.8504\n",
      "Epoch 1345/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1175 - accuracy: 0.9509 - val_loss: 0.4342 - val_accuracy: 0.8783\n",
      "Epoch 1346/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1195 - accuracy: 0.9545 - val_loss: 0.5165 - val_accuracy: 0.8534\n",
      "Epoch 1347/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1178 - accuracy: 0.9531 - val_loss: 0.4429 - val_accuracy: 0.8724\n",
      "Epoch 1348/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1216 - accuracy: 0.9520 - val_loss: 0.4706 - val_accuracy: 0.8651\n",
      "Epoch 1349/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1057 - accuracy: 0.9630 - val_loss: 0.4223 - val_accuracy: 0.8768\n",
      "Epoch 1350/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.0990 - accuracy: 0.9571 - val_loss: 0.4249 - val_accuracy: 0.8783\n",
      "Epoch 1351/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1250 - accuracy: 0.9520 - val_loss: 0.4268 - val_accuracy: 0.8783\n",
      "Epoch 1352/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1147 - accuracy: 0.9527 - val_loss: 0.4422 - val_accuracy: 0.8827\n",
      "Epoch 1353/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1202 - accuracy: 0.9575 - val_loss: 0.4118 - val_accuracy: 0.8842\n",
      "Epoch 1354/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1221 - accuracy: 0.9560 - val_loss: 0.4267 - val_accuracy: 0.8724\n",
      "Epoch 1355/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1146 - accuracy: 0.9549 - val_loss: 0.5882 - val_accuracy: 0.8358\n",
      "Epoch 1356/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1262 - accuracy: 0.9505 - val_loss: 0.4442 - val_accuracy: 0.8724\n",
      "Epoch 1357/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1182 - accuracy: 0.9545 - val_loss: 0.4099 - val_accuracy: 0.8915\n",
      "Epoch 1358/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1191 - accuracy: 0.9586 - val_loss: 0.4370 - val_accuracy: 0.8680\n",
      "Epoch 1359/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1230 - accuracy: 0.9549 - val_loss: 0.4887 - val_accuracy: 0.8636\n",
      "Epoch 1360/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1246 - accuracy: 0.9479 - val_loss: 0.4933 - val_accuracy: 0.8475\n",
      "Epoch 1361/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1066 - accuracy: 0.9582 - val_loss: 0.4360 - val_accuracy: 0.8724\n",
      "Epoch 1362/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1082 - accuracy: 0.9542 - val_loss: 0.6892 - val_accuracy: 0.8270\n",
      "Epoch 1363/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1197 - accuracy: 0.9527 - val_loss: 0.4482 - val_accuracy: 0.8651\n",
      "Epoch 1364/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1187 - accuracy: 0.9549 - val_loss: 0.4421 - val_accuracy: 0.8651\n",
      "Epoch 1365/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1115 - accuracy: 0.9527 - val_loss: 0.9496 - val_accuracy: 0.7859\n",
      "Epoch 1366/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1287 - accuracy: 0.9472 - val_loss: 0.4825 - val_accuracy: 0.8607\n",
      "Epoch 1367/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1135 - accuracy: 0.9516 - val_loss: 0.5341 - val_accuracy: 0.8519\n",
      "Epoch 1368/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1097 - accuracy: 0.9597 - val_loss: 0.5297 - val_accuracy: 0.8548\n",
      "Epoch 1369/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1098 - accuracy: 0.9567 - val_loss: 0.4520 - val_accuracy: 0.8739\n",
      "Epoch 1370/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1401 - accuracy: 0.9479 - val_loss: 2.8304 - val_accuracy: 0.5968\n",
      "Epoch 1371/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1356 - accuracy: 0.9454 - val_loss: 0.4999 - val_accuracy: 0.8666\n",
      "Epoch 1372/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1174 - accuracy: 0.9505 - val_loss: 0.5017 - val_accuracy: 0.8622\n",
      "Epoch 1373/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1322 - accuracy: 0.9501 - val_loss: 0.5565 - val_accuracy: 0.8446\n",
      "Epoch 1374/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1231 - accuracy: 0.9509 - val_loss: 0.4456 - val_accuracy: 0.8695\n",
      "Epoch 1375/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1126 - accuracy: 0.9501 - val_loss: 0.4496 - val_accuracy: 0.8651\n",
      "Epoch 1376/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1128 - accuracy: 0.9571 - val_loss: 0.4621 - val_accuracy: 0.8563\n",
      "Epoch 1377/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1186 - accuracy: 0.9538 - val_loss: 0.4522 - val_accuracy: 0.8783\n",
      "Epoch 1378/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1242 - accuracy: 0.9516 - val_loss: 0.4605 - val_accuracy: 0.8680\n",
      "Epoch 1379/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1164 - accuracy: 0.9520 - val_loss: 0.4362 - val_accuracy: 0.8651\n",
      "Epoch 1380/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1158 - accuracy: 0.9509 - val_loss: 0.4512 - val_accuracy: 0.8563\n",
      "Epoch 1381/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1224 - accuracy: 0.9505 - val_loss: 0.4180 - val_accuracy: 0.8754\n",
      "Epoch 1382/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1299 - accuracy: 0.9483 - val_loss: 0.4801 - val_accuracy: 0.8636\n",
      "Epoch 1383/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9531 - val_loss: 0.4489 - val_accuracy: 0.8607\n",
      "Epoch 1384/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1228 - accuracy: 0.9494 - val_loss: 0.4687 - val_accuracy: 0.8695\n",
      "Epoch 1385/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1318 - accuracy: 0.9490 - val_loss: 0.7471 - val_accuracy: 0.8065\n",
      "Epoch 1386/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9450 - val_loss: 0.4568 - val_accuracy: 0.8666\n",
      "Epoch 1387/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1292 - accuracy: 0.9487 - val_loss: 0.4668 - val_accuracy: 0.8724\n",
      "Epoch 1388/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1262 - accuracy: 0.9483 - val_loss: 0.6456 - val_accuracy: 0.8343\n",
      "Epoch 1389/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1362 - accuracy: 0.9490 - val_loss: 0.4307 - val_accuracy: 0.8680\n",
      "Epoch 1390/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1307 - accuracy: 0.9483 - val_loss: 0.4590 - val_accuracy: 0.8724\n",
      "Epoch 1391/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1260 - accuracy: 0.9494 - val_loss: 0.4687 - val_accuracy: 0.8607\n",
      "Epoch 1392/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1239 - accuracy: 0.9509 - val_loss: 0.5046 - val_accuracy: 0.8534\n",
      "Epoch 1393/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1314 - accuracy: 0.9479 - val_loss: 0.4911 - val_accuracy: 0.8622\n",
      "Epoch 1394/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1361 - accuracy: 0.9476 - val_loss: 0.4608 - val_accuracy: 0.8768\n",
      "Epoch 1395/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1223 - accuracy: 0.9479 - val_loss: 0.4609 - val_accuracy: 0.8783\n",
      "Epoch 1396/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1315 - accuracy: 0.9476 - val_loss: 0.4495 - val_accuracy: 0.8680\n",
      "Epoch 1397/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1136 - accuracy: 0.9534 - val_loss: 0.4857 - val_accuracy: 0.8622\n",
      "Epoch 1398/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1191 - accuracy: 0.9490 - val_loss: 0.4550 - val_accuracy: 0.8651\n",
      "Epoch 1399/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1275 - accuracy: 0.9509 - val_loss: 1.1528 - val_accuracy: 0.7434\n",
      "Epoch 1400/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1287 - accuracy: 0.9512 - val_loss: 0.4386 - val_accuracy: 0.8739\n",
      "Epoch 1401/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1191 - accuracy: 0.9531 - val_loss: 0.4866 - val_accuracy: 0.8490\n",
      "Epoch 1402/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1273 - accuracy: 0.9461 - val_loss: 0.5460 - val_accuracy: 0.8548\n",
      "Epoch 1403/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1245 - accuracy: 0.9476 - val_loss: 0.4073 - val_accuracy: 0.8798\n",
      "Epoch 1404/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1265 - accuracy: 0.9534 - val_loss: 0.4271 - val_accuracy: 0.8710\n",
      "Epoch 1405/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1156 - accuracy: 0.9567 - val_loss: 0.5937 - val_accuracy: 0.8343\n",
      "Epoch 1406/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1212 - accuracy: 0.9498 - val_loss: 0.4826 - val_accuracy: 0.8695\n",
      "Epoch 1407/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1357 - accuracy: 0.9465 - val_loss: 0.4546 - val_accuracy: 0.8695\n",
      "Epoch 1408/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1279 - accuracy: 0.9545 - val_loss: 0.4119 - val_accuracy: 0.8827\n",
      "Epoch 1409/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1158 - accuracy: 0.9531 - val_loss: 0.4347 - val_accuracy: 0.8739\n",
      "Epoch 1410/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1118 - accuracy: 0.9571 - val_loss: 0.4406 - val_accuracy: 0.8710\n",
      "Epoch 1411/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1240 - accuracy: 0.9564 - val_loss: 0.4157 - val_accuracy: 0.8754\n",
      "Epoch 1412/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1024 - accuracy: 0.9582 - val_loss: 0.4499 - val_accuracy: 0.8622\n",
      "Epoch 1413/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1180 - accuracy: 0.9494 - val_loss: 0.4383 - val_accuracy: 0.8724\n",
      "Epoch 1414/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1124 - accuracy: 0.9586 - val_loss: 0.4295 - val_accuracy: 0.8768\n",
      "Epoch 1415/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9520 - val_loss: 0.4169 - val_accuracy: 0.8754\n",
      "Epoch 1416/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1084 - accuracy: 0.9556 - val_loss: 0.5097 - val_accuracy: 0.8519\n",
      "Epoch 1417/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1113 - accuracy: 0.9567 - val_loss: 0.4295 - val_accuracy: 0.8900\n",
      "Epoch 1418/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1275 - accuracy: 0.9509 - val_loss: 0.5681 - val_accuracy: 0.8519\n",
      "Epoch 1419/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1150 - accuracy: 0.9527 - val_loss: 0.5386 - val_accuracy: 0.8622\n",
      "Epoch 1420/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1271 - accuracy: 0.9487 - val_loss: 0.4495 - val_accuracy: 0.8798\n",
      "Epoch 1421/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1168 - accuracy: 0.9505 - val_loss: 0.4291 - val_accuracy: 0.8783\n",
      "Epoch 1422/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0990 - accuracy: 0.9608 - val_loss: 0.4460 - val_accuracy: 0.8680\n",
      "Epoch 1423/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1360 - accuracy: 0.9498 - val_loss: 0.4961 - val_accuracy: 0.8666\n",
      "Epoch 1424/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1153 - accuracy: 0.9512 - val_loss: 0.4336 - val_accuracy: 0.8710\n",
      "Epoch 1425/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1130 - accuracy: 0.9553 - val_loss: 0.5539 - val_accuracy: 0.8431\n",
      "Epoch 1426/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1141 - accuracy: 0.9553 - val_loss: 0.4756 - val_accuracy: 0.8651\n",
      "Epoch 1427/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1174 - accuracy: 0.9549 - val_loss: 0.4386 - val_accuracy: 0.8798\n",
      "Epoch 1428/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1276 - accuracy: 0.9509 - val_loss: 0.4221 - val_accuracy: 0.8695\n",
      "Epoch 1429/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1167 - accuracy: 0.9534 - val_loss: 0.4395 - val_accuracy: 0.8768\n",
      "Epoch 1430/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1240 - accuracy: 0.9520 - val_loss: 0.6464 - val_accuracy: 0.8372\n",
      "Epoch 1431/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1254 - accuracy: 0.9490 - val_loss: 0.4294 - val_accuracy: 0.8695\n",
      "Epoch 1432/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1144 - accuracy: 0.9560 - val_loss: 0.4798 - val_accuracy: 0.8636\n",
      "Epoch 1433/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1247 - accuracy: 0.9516 - val_loss: 0.4365 - val_accuracy: 0.8651\n",
      "Epoch 1434/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1126 - accuracy: 0.9531 - val_loss: 0.4799 - val_accuracy: 0.8666\n",
      "Epoch 1435/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1281 - accuracy: 0.9487 - val_loss: 0.7987 - val_accuracy: 0.8211\n",
      "Epoch 1436/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1090 - accuracy: 0.9549 - val_loss: 0.4043 - val_accuracy: 0.8798\n",
      "Epoch 1437/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1119 - accuracy: 0.9538 - val_loss: 0.4533 - val_accuracy: 0.8768\n",
      "Epoch 1438/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1236 - accuracy: 0.9538 - val_loss: 0.5382 - val_accuracy: 0.8592\n",
      "Epoch 1439/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1169 - accuracy: 0.9527 - val_loss: 0.4860 - val_accuracy: 0.8592\n",
      "Epoch 1440/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1120 - accuracy: 0.9556 - val_loss: 0.4643 - val_accuracy: 0.8651\n",
      "Epoch 1441/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1189 - accuracy: 0.9505 - val_loss: 0.4482 - val_accuracy: 0.8651\n",
      "Epoch 1442/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1125 - accuracy: 0.9553 - val_loss: 0.4274 - val_accuracy: 0.8754\n",
      "Epoch 1443/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.0966 - accuracy: 0.9571 - val_loss: 0.4264 - val_accuracy: 0.8754\n",
      "Epoch 1444/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1301 - accuracy: 0.9538 - val_loss: 0.5847 - val_accuracy: 0.8343\n",
      "Epoch 1445/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9505 - val_loss: 0.5376 - val_accuracy: 0.8592\n",
      "Epoch 1446/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1195 - accuracy: 0.9534 - val_loss: 0.4494 - val_accuracy: 0.8798\n",
      "Epoch 1447/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1252 - accuracy: 0.9527 - val_loss: 0.4463 - val_accuracy: 0.8724\n",
      "Epoch 1448/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1215 - accuracy: 0.9516 - val_loss: 0.4200 - val_accuracy: 0.8812\n",
      "Epoch 1449/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1167 - accuracy: 0.9512 - val_loss: 0.4362 - val_accuracy: 0.8724\n",
      "Epoch 1450/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1022 - accuracy: 0.9560 - val_loss: 0.4131 - val_accuracy: 0.8724\n",
      "Epoch 1451/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1102 - accuracy: 0.9538 - val_loss: 0.4379 - val_accuracy: 0.8724\n",
      "Epoch 1452/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1246 - accuracy: 0.9527 - val_loss: 0.4459 - val_accuracy: 0.8710\n",
      "Epoch 1453/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1148 - accuracy: 0.9593 - val_loss: 0.4434 - val_accuracy: 0.8710\n",
      "Epoch 1454/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1193 - accuracy: 0.9534 - val_loss: 0.4884 - val_accuracy: 0.8622\n",
      "Epoch 1455/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1339 - accuracy: 0.9472 - val_loss: 0.4249 - val_accuracy: 0.8768\n",
      "Epoch 1456/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1280 - accuracy: 0.9523 - val_loss: 0.4367 - val_accuracy: 0.8695\n",
      "Epoch 1457/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1359 - accuracy: 0.9461 - val_loss: 1.9232 - val_accuracy: 0.6496\n",
      "Epoch 1458/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1325 - accuracy: 0.9457 - val_loss: 0.4701 - val_accuracy: 0.8592\n",
      "Epoch 1459/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1246 - accuracy: 0.9534 - val_loss: 0.4628 - val_accuracy: 0.8651\n",
      "Epoch 1460/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1270 - accuracy: 0.9534 - val_loss: 0.4839 - val_accuracy: 0.8651\n",
      "Epoch 1461/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1202 - accuracy: 0.9523 - val_loss: 0.3966 - val_accuracy: 0.8842\n",
      "Epoch 1462/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1322 - accuracy: 0.9501 - val_loss: 0.4635 - val_accuracy: 0.8695\n",
      "Epoch 1463/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1241 - accuracy: 0.9483 - val_loss: 0.4738 - val_accuracy: 0.8768\n",
      "Epoch 1464/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1136 - accuracy: 0.9534 - val_loss: 0.4359 - val_accuracy: 0.8680\n",
      "Epoch 1465/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1236 - accuracy: 0.9461 - val_loss: 0.5052 - val_accuracy: 0.8490\n",
      "Epoch 1466/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1356 - accuracy: 0.9476 - val_loss: 0.4777 - val_accuracy: 0.8460\n",
      "Epoch 1467/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1145 - accuracy: 0.9553 - val_loss: 0.5109 - val_accuracy: 0.8651\n",
      "Epoch 1468/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1206 - accuracy: 0.9520 - val_loss: 0.4504 - val_accuracy: 0.8812\n",
      "Epoch 1469/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1134 - accuracy: 0.9520 - val_loss: 0.4367 - val_accuracy: 0.8666\n",
      "Epoch 1470/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1226 - accuracy: 0.9494 - val_loss: 0.4638 - val_accuracy: 0.8592\n",
      "Epoch 1471/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1110 - accuracy: 0.9542 - val_loss: 0.4522 - val_accuracy: 0.8739\n",
      "Epoch 1472/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1164 - accuracy: 0.9571 - val_loss: 0.6534 - val_accuracy: 0.8358\n",
      "Epoch 1473/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1093 - accuracy: 0.9604 - val_loss: 0.4560 - val_accuracy: 0.8636\n",
      "Epoch 1474/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1233 - accuracy: 0.9490 - val_loss: 0.4400 - val_accuracy: 0.8710\n",
      "Epoch 1475/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1357 - accuracy: 0.9454 - val_loss: 0.4602 - val_accuracy: 0.8739\n",
      "Epoch 1476/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1139 - accuracy: 0.9564 - val_loss: 0.4857 - val_accuracy: 0.8548\n",
      "Epoch 1477/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1222 - accuracy: 0.9567 - val_loss: 0.5547 - val_accuracy: 0.8416\n",
      "Epoch 1478/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1372 - accuracy: 0.9465 - val_loss: 0.5149 - val_accuracy: 0.8592\n",
      "Epoch 1479/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1284 - accuracy: 0.9512 - val_loss: 0.4969 - val_accuracy: 0.8666\n",
      "Epoch 1480/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1136 - accuracy: 0.9575 - val_loss: 0.4598 - val_accuracy: 0.8724\n",
      "Epoch 1481/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1120 - accuracy: 0.9542 - val_loss: 0.4670 - val_accuracy: 0.8622\n",
      "Epoch 1482/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0981 - accuracy: 0.9641 - val_loss: 0.4561 - val_accuracy: 0.8563\n",
      "Epoch 1483/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1090 - accuracy: 0.9564 - val_loss: 0.5143 - val_accuracy: 0.8534\n",
      "Epoch 1484/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1178 - accuracy: 0.9509 - val_loss: 0.4599 - val_accuracy: 0.8724\n",
      "Epoch 1485/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1126 - accuracy: 0.9553 - val_loss: 0.5015 - val_accuracy: 0.8666\n",
      "Epoch 1486/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1212 - accuracy: 0.9479 - val_loss: 0.4570 - val_accuracy: 0.8680\n",
      "Epoch 1487/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1062 - accuracy: 0.9582 - val_loss: 0.4379 - val_accuracy: 0.8607\n",
      "Epoch 1488/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0988 - accuracy: 0.9648 - val_loss: 0.4803 - val_accuracy: 0.8680\n",
      "Epoch 1489/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1073 - accuracy: 0.9531 - val_loss: 0.4725 - val_accuracy: 0.8680\n",
      "Epoch 1490/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1097 - accuracy: 0.9542 - val_loss: 0.4789 - val_accuracy: 0.8680\n",
      "Epoch 1491/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.0961 - accuracy: 0.9615 - val_loss: 0.4844 - val_accuracy: 0.8695\n",
      "Epoch 1492/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1250 - accuracy: 0.9523 - val_loss: 0.5207 - val_accuracy: 0.8607\n",
      "Epoch 1493/7000\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1129 - accuracy: 0.9578 - val_loss: 0.4811 - val_accuracy: 0.8680\n",
      "Epoch 1494/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.0995 - accuracy: 0.9586 - val_loss: 0.4700 - val_accuracy: 0.8695\n",
      "Epoch 1495/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1242 - accuracy: 0.9520 - val_loss: 0.4560 - val_accuracy: 0.8578\n",
      "Epoch 1496/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1114 - accuracy: 0.9560 - val_loss: 0.8991 - val_accuracy: 0.7859\n",
      "Epoch 1497/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1272 - accuracy: 0.9501 - val_loss: 0.4498 - val_accuracy: 0.8651\n",
      "Epoch 1498/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1104 - accuracy: 0.9545 - val_loss: 0.4522 - val_accuracy: 0.8724\n",
      "Epoch 1499/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1074 - accuracy: 0.9589 - val_loss: 0.4771 - val_accuracy: 0.8622\n",
      "Epoch 1500/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1242 - accuracy: 0.9553 - val_loss: 0.4525 - val_accuracy: 0.8666\n",
      "Epoch 1501/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1148 - accuracy: 0.9542 - val_loss: 0.4898 - val_accuracy: 0.8651\n",
      "Epoch 1502/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1067 - accuracy: 0.9564 - val_loss: 0.4820 - val_accuracy: 0.8563\n",
      "Epoch 1503/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1226 - accuracy: 0.9509 - val_loss: 0.5039 - val_accuracy: 0.8680\n",
      "Epoch 1504/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1210 - accuracy: 0.9512 - val_loss: 0.4850 - val_accuracy: 0.8548\n",
      "Epoch 1505/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1172 - accuracy: 0.9549 - val_loss: 2.9030 - val_accuracy: 0.5792\n",
      "Epoch 1506/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1436 - accuracy: 0.9490 - val_loss: 0.5196 - val_accuracy: 0.8475\n",
      "Epoch 1507/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1197 - accuracy: 0.9556 - val_loss: 0.4774 - val_accuracy: 0.8739\n",
      "Epoch 1508/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1243 - accuracy: 0.9479 - val_loss: 0.4383 - val_accuracy: 0.8710\n",
      "Epoch 1509/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1100 - accuracy: 0.9542 - val_loss: 0.4384 - val_accuracy: 0.8578\n",
      "Epoch 1510/7000\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1026 - accuracy: 0.9534 - val_loss: 0.4592 - val_accuracy: 0.8622\n",
      "Epoch 1511/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1165 - accuracy: 0.9512 - val_loss: 0.7674 - val_accuracy: 0.8094\n",
      "Epoch 1512/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1189 - accuracy: 0.9523 - val_loss: 0.4591 - val_accuracy: 0.8680\n",
      "Epoch 1513/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1178 - accuracy: 0.9523 - val_loss: 0.5461 - val_accuracy: 0.8475\n",
      "Epoch 1514/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1164 - accuracy: 0.9542 - val_loss: 0.4492 - val_accuracy: 0.8695\n",
      "Epoch 1515/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1181 - accuracy: 0.9531 - val_loss: 0.4704 - val_accuracy: 0.8592\n",
      "Epoch 1516/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1262 - accuracy: 0.9542 - val_loss: 0.4234 - val_accuracy: 0.8724\n",
      "Epoch 1517/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1163 - accuracy: 0.9542 - val_loss: 0.4692 - val_accuracy: 0.8768\n",
      "Epoch 1518/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1136 - accuracy: 0.9531 - val_loss: 0.4369 - val_accuracy: 0.8695\n",
      "Epoch 1519/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1004 - accuracy: 0.9571 - val_loss: 0.4697 - val_accuracy: 0.8695\n",
      "Epoch 1520/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1201 - accuracy: 0.9534 - val_loss: 0.5313 - val_accuracy: 0.8460\n",
      "Epoch 1521/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1187 - accuracy: 0.9531 - val_loss: 0.4963 - val_accuracy: 0.8534\n",
      "Epoch 1522/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1199 - accuracy: 0.9589 - val_loss: 0.4119 - val_accuracy: 0.8636\n",
      "Epoch 1523/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1134 - accuracy: 0.9600 - val_loss: 0.7450 - val_accuracy: 0.8211\n",
      "Epoch 1524/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1220 - accuracy: 0.9505 - val_loss: 0.8454 - val_accuracy: 0.8065\n",
      "Epoch 1525/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1305 - accuracy: 0.9509 - val_loss: 0.6853 - val_accuracy: 0.8358\n",
      "Epoch 1526/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1156 - accuracy: 0.9534 - val_loss: 0.4579 - val_accuracy: 0.8695\n",
      "Epoch 1527/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1164 - accuracy: 0.9505 - val_loss: 0.8534 - val_accuracy: 0.8211\n",
      "Epoch 1528/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1283 - accuracy: 0.9490 - val_loss: 0.7584 - val_accuracy: 0.8006\n",
      "Epoch 1529/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1116 - accuracy: 0.9545 - val_loss: 0.4871 - val_accuracy: 0.8710\n",
      "Epoch 1530/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1079 - accuracy: 0.9531 - val_loss: 0.5159 - val_accuracy: 0.8651\n",
      "Epoch 1531/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1113 - accuracy: 0.9549 - val_loss: 0.4431 - val_accuracy: 0.8680\n",
      "Epoch 1532/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1221 - accuracy: 0.9534 - val_loss: 0.4998 - val_accuracy: 0.8563\n",
      "Epoch 1533/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1136 - accuracy: 0.9538 - val_loss: 0.4347 - val_accuracy: 0.8783\n",
      "Epoch 1534/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1152 - accuracy: 0.9531 - val_loss: 0.4456 - val_accuracy: 0.8768\n",
      "Epoch 1535/7000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1105 - accuracy: 0.9512 - val_loss: 0.4708 - val_accuracy: 0.8710\n",
      "Epoch 1536/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1141 - accuracy: 0.9538 - val_loss: 0.4370 - val_accuracy: 0.8739\n",
      "Epoch 1537/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1181 - accuracy: 0.9549 - val_loss: 0.4507 - val_accuracy: 0.8739\n",
      "Epoch 1538/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1143 - accuracy: 0.9523 - val_loss: 0.5363 - val_accuracy: 0.8490\n",
      "Epoch 1539/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1239 - accuracy: 0.9505 - val_loss: 0.5014 - val_accuracy: 0.8504\n",
      "Epoch 1540/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1158 - accuracy: 0.9560 - val_loss: 0.4685 - val_accuracy: 0.8636\n",
      "Epoch 1541/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1073 - accuracy: 0.9553 - val_loss: 0.4397 - val_accuracy: 0.8798\n",
      "Epoch 1542/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1302 - accuracy: 0.9490 - val_loss: 0.4491 - val_accuracy: 0.8724\n",
      "Epoch 1543/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1058 - accuracy: 0.9622 - val_loss: 0.4282 - val_accuracy: 0.8622\n",
      "Epoch 1544/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1133 - accuracy: 0.9545 - val_loss: 0.4437 - val_accuracy: 0.8754\n",
      "Epoch 1545/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1131 - accuracy: 0.9531 - val_loss: 0.4566 - val_accuracy: 0.8622\n",
      "Epoch 1546/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1232 - accuracy: 0.9516 - val_loss: 0.4685 - val_accuracy: 0.8651\n",
      "Epoch 1547/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1100 - accuracy: 0.9567 - val_loss: 0.4305 - val_accuracy: 0.8695\n",
      "Epoch 1548/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1306 - accuracy: 0.9479 - val_loss: 0.4404 - val_accuracy: 0.8651\n",
      "Epoch 1549/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1140 - accuracy: 0.9564 - val_loss: 0.4183 - val_accuracy: 0.8754\n",
      "Epoch 1550/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1244 - accuracy: 0.9542 - val_loss: 0.7113 - val_accuracy: 0.8196\n",
      "Epoch 1551/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1113 - accuracy: 0.9582 - val_loss: 0.4574 - val_accuracy: 0.8578\n",
      "Epoch 1552/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1262 - accuracy: 0.9490 - val_loss: 0.4134 - val_accuracy: 0.8666\n",
      "Epoch 1553/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1194 - accuracy: 0.9542 - val_loss: 0.4316 - val_accuracy: 0.8651\n",
      "Epoch 1554/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1081 - accuracy: 0.9538 - val_loss: 0.4206 - val_accuracy: 0.8798\n",
      "Epoch 1555/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1274 - accuracy: 0.9472 - val_loss: 0.4793 - val_accuracy: 0.8548\n",
      "Epoch 1556/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0978 - accuracy: 0.9608 - val_loss: 0.4315 - val_accuracy: 0.8783\n",
      "Epoch 1557/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1084 - accuracy: 0.9600 - val_loss: 0.4187 - val_accuracy: 0.8827\n",
      "Epoch 1558/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1035 - accuracy: 0.9586 - val_loss: 0.5058 - val_accuracy: 0.8519\n",
      "Epoch 1559/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1144 - accuracy: 0.9578 - val_loss: 0.5680 - val_accuracy: 0.8519\n",
      "Epoch 1560/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1044 - accuracy: 0.9597 - val_loss: 0.4375 - val_accuracy: 0.8783\n",
      "Epoch 1561/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1155 - accuracy: 0.9549 - val_loss: 0.4342 - val_accuracy: 0.8710\n",
      "Epoch 1562/7000\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1071 - accuracy: 0.9553 - val_loss: 0.5142 - val_accuracy: 0.8651\n",
      "Epoch 1563/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.0978 - accuracy: 0.9622 - val_loss: 0.4819 - val_accuracy: 0.8622\n",
      "Epoch 1564/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1140 - accuracy: 0.9560 - val_loss: 0.4347 - val_accuracy: 0.8710\n",
      "Epoch 1565/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1054 - accuracy: 0.9597 - val_loss: 1.3690 - val_accuracy: 0.7126\n",
      "Epoch 1566/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1068 - accuracy: 0.9586 - val_loss: 0.4370 - val_accuracy: 0.8812\n",
      "Epoch 1567/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1140 - accuracy: 0.9542 - val_loss: 0.4849 - val_accuracy: 0.8680\n",
      "Epoch 1568/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1102 - accuracy: 0.9545 - val_loss: 0.4975 - val_accuracy: 0.8607\n",
      "Epoch 1569/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1162 - accuracy: 0.9509 - val_loss: 0.4900 - val_accuracy: 0.8622\n",
      "Epoch 1570/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1314 - accuracy: 0.9457 - val_loss: 0.4804 - val_accuracy: 0.8680\n",
      "Epoch 1571/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0980 - accuracy: 0.9600 - val_loss: 0.4366 - val_accuracy: 0.8768\n",
      "Epoch 1572/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1108 - accuracy: 0.9556 - val_loss: 0.4266 - val_accuracy: 0.8680\n",
      "Epoch 1573/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1142 - accuracy: 0.9615 - val_loss: 0.4441 - val_accuracy: 0.8710\n",
      "Epoch 1574/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0959 - accuracy: 0.9604 - val_loss: 0.4225 - val_accuracy: 0.8856\n",
      "Epoch 1575/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1131 - accuracy: 0.9571 - val_loss: 0.4426 - val_accuracy: 0.8636\n",
      "Epoch 1576/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1103 - accuracy: 0.9571 - val_loss: 0.4632 - val_accuracy: 0.8592\n",
      "Epoch 1577/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1067 - accuracy: 0.9534 - val_loss: 0.4488 - val_accuracy: 0.8636\n",
      "Epoch 1578/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1254 - accuracy: 0.9494 - val_loss: 0.4810 - val_accuracy: 0.8666\n",
      "Epoch 1579/7000\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1251 - accuracy: 0.9534 - val_loss: 0.6945 - val_accuracy: 0.8152\n",
      "Epoch 1580/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1161 - accuracy: 0.9556 - val_loss: 0.4584 - val_accuracy: 0.8724\n",
      "Epoch 1581/7000\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1191 - accuracy: 0.9505 - val_loss: 0.4375 - val_accuracy: 0.8856\n",
      "Epoch 1582/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1183 - accuracy: 0.9505 - val_loss: 0.4633 - val_accuracy: 0.8534\n",
      "Epoch 1583/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1122 - accuracy: 0.9545 - val_loss: 0.4436 - val_accuracy: 0.8739\n",
      "Epoch 1584/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1014 - accuracy: 0.9589 - val_loss: 0.4413 - val_accuracy: 0.8768\n",
      "Epoch 1585/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1066 - accuracy: 0.9597 - val_loss: 0.4441 - val_accuracy: 0.8680\n",
      "Epoch 1586/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1140 - accuracy: 0.9516 - val_loss: 0.4650 - val_accuracy: 0.8651\n",
      "Epoch 1587/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1091 - accuracy: 0.9578 - val_loss: 0.4512 - val_accuracy: 0.8783\n",
      "Epoch 1588/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1115 - accuracy: 0.9531 - val_loss: 0.4984 - val_accuracy: 0.8724\n",
      "Epoch 1589/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1237 - accuracy: 0.9520 - val_loss: 0.4322 - val_accuracy: 0.8666\n",
      "Epoch 1590/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1061 - accuracy: 0.9578 - val_loss: 0.4438 - val_accuracy: 0.8680\n",
      "Epoch 1591/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1197 - accuracy: 0.9571 - val_loss: 0.4826 - val_accuracy: 0.8578\n",
      "Epoch 1592/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1073 - accuracy: 0.9567 - val_loss: 0.4777 - val_accuracy: 0.8666\n",
      "Epoch 1593/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1095 - accuracy: 0.9571 - val_loss: 0.4745 - val_accuracy: 0.8592\n",
      "Epoch 1594/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1233 - accuracy: 0.9483 - val_loss: 0.7515 - val_accuracy: 0.8299\n",
      "Epoch 1595/7000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1100 - accuracy: 0.9589 - val_loss: 0.6160 - val_accuracy: 0.8416\n",
      "Epoch 1596/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1163 - accuracy: 0.9538 - val_loss: 0.4421 - val_accuracy: 0.8739\n",
      "Epoch 1597/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.0994 - accuracy: 0.9611 - val_loss: 0.4466 - val_accuracy: 0.8666\n",
      "Epoch 1598/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1074 - accuracy: 0.9586 - val_loss: 0.4696 - val_accuracy: 0.8636\n",
      "Epoch 1599/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1169 - accuracy: 0.9560 - val_loss: 0.4502 - val_accuracy: 0.8592\n",
      "Epoch 1600/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.0911 - accuracy: 0.9630 - val_loss: 0.4328 - val_accuracy: 0.8607\n",
      "Epoch 1601/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1045 - accuracy: 0.9611 - val_loss: 0.4849 - val_accuracy: 0.8578\n",
      "Epoch 1602/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1028 - accuracy: 0.9622 - val_loss: 0.4625 - val_accuracy: 0.8636\n",
      "Epoch 1603/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1040 - accuracy: 0.9604 - val_loss: 0.4556 - val_accuracy: 0.8739\n",
      "Epoch 1604/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1105 - accuracy: 0.9538 - val_loss: 0.4623 - val_accuracy: 0.8695\n",
      "Epoch 1605/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1059 - accuracy: 0.9619 - val_loss: 0.5065 - val_accuracy: 0.8548\n",
      "Epoch 1606/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1097 - accuracy: 0.9553 - val_loss: 0.5391 - val_accuracy: 0.8490\n",
      "Epoch 1607/7000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.1064 - accuracy: 0.9604 - val_loss: 0.5053 - val_accuracy: 0.8607\n",
      "Epoch 1608/7000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.1173 - accuracy: 0.9527 - val_loss: 0.4984 - val_accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe0dcb5ed0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import glob\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the folder name where the images are located\n",
    "folder_name = \"img\"\n",
    "\n",
    "# Construct the folder path\n",
    "folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# Specify the CSV file path containing image labels\n",
    "csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary where keys are filenames and values are labels\n",
    "labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "def load_images_from_folder(folder, labels_dict):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "        img = Image.open(file_path)\n",
    "        if img is not None:\n",
    "            img = img.convert('L')  # Convert image to grayscale\n",
    "            img = img.resize((28, 28))  # Resize the image\n",
    "            np_img = np.array(img)\n",
    "            images.append(np_img)\n",
    "            filename = os.path.basename(file_path)\n",
    "            label = labels_dict[filename]  # Get the label from the filename\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "images = np.array(images)  # Convert list of arrays to a single array\n",
    "images = images / 255.0  # Normalize pixel values\n",
    "images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Adjusted Dropout\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))  # Adjusted Dropout\n",
    "\n",
    "num_classes = len(set(numerical_labels))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Changed optimizer to SGD\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1000)\n",
    "\n",
    "\n",
    "# Model Checkpoint\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "          epochs=7000,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# 86/86 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9721\n",
    "# Train Loss: 0.06979891657829285\n",
    "# Train Accuracy: 0.9721407890319824\n",
    "    \n",
    "# 22/22 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8695\n",
    "# Test Loss: 0.3703301250934601\n",
    "# Test Accuracy: 0.8695014715194702\n",
    "# 22/22 [==============================] - 0s 3ms/step    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9813\n",
      "Train Loss: 0.043908171355724335\n",
      "Train Accuracy: 0.9813050031661987\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Epoch7000\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Epoch7000\\assets\n"
     ]
    }
   ],
   "source": [
    "#Save Model For Furture Use\n",
    "model.save('Epoch7000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9608\n",
      "Train Loss: 0.09689047932624817\n",
      "Train Accuracy: 0.9607771039009094\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8636\n",
      "Test Loss: 0.49838370084762573\n",
      "Test Accuracy: 0.8636363744735718\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47        14\n",
      "           1       1.00      0.55      0.71        11\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.95      1.00      0.98        20\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      0.94      0.97        16\n",
      "           6       1.00      1.00      1.00         9\n",
      "           7       1.00      0.87      0.93        15\n",
      "           8       0.86      1.00      0.92        12\n",
      "           9       0.92      1.00      0.96        11\n",
      "          10       0.94      1.00      0.97        16\n",
      "          11       0.89      0.89      0.89         9\n",
      "          12       0.83      0.56      0.67         9\n",
      "          13       0.83      1.00      0.91        10\n",
      "          14       1.00      1.00      1.00        15\n",
      "          15       1.00      0.93      0.96        14\n",
      "          16       1.00      1.00      1.00        10\n",
      "          17       1.00      1.00      1.00        11\n",
      "          18       0.65      0.94      0.77        16\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       0.78      0.58      0.67        12\n",
      "          21       1.00      0.89      0.94         9\n",
      "          22       1.00      1.00      1.00         9\n",
      "          23       1.00      0.86      0.92         7\n",
      "          24       0.43      0.33      0.38         9\n",
      "          25       0.75      0.75      0.75         8\n",
      "          26       0.81      1.00      0.90        13\n",
      "          27       1.00      1.00      1.00         8\n",
      "          28       0.83      0.50      0.62        10\n",
      "          29       0.92      1.00      0.96        11\n",
      "          30       0.83      0.91      0.87        11\n",
      "          31       0.83      0.91      0.87        11\n",
      "          32       0.75      0.75      0.75        12\n",
      "          33       0.79      1.00      0.88        11\n",
      "          34       0.70      0.70      0.70        10\n",
      "          35       0.91      0.91      0.91        11\n",
      "          36       1.00      0.85      0.92        13\n",
      "          37       1.00      1.00      1.00         6\n",
      "          38       0.56      0.83      0.67         6\n",
      "          39       0.88      1.00      0.93         7\n",
      "          40       1.00      1.00      1.00        12\n",
      "          41       1.00      0.88      0.93         8\n",
      "          42       0.79      1.00      0.88        11\n",
      "          43       0.90      1.00      0.95         9\n",
      "          44       1.00      0.92      0.96        13\n",
      "          45       1.00      1.00      1.00         7\n",
      "          46       0.64      0.90      0.75        10\n",
      "          47       0.82      0.82      0.82        11\n",
      "          48       0.85      1.00      0.92        11\n",
      "          49       0.91      0.83      0.87        12\n",
      "          50       0.64      0.54      0.58        13\n",
      "          51       0.75      0.86      0.80         7\n",
      "          52       1.00      0.73      0.84        11\n",
      "          53       0.88      0.78      0.82         9\n",
      "          54       0.68      0.72      0.70        18\n",
      "          55       1.00      1.00      1.00        12\n",
      "          56       0.91      0.83      0.87        12\n",
      "          57       0.86      0.75      0.80         8\n",
      "          58       0.73      0.73      0.73        11\n",
      "          59       1.00      0.75      0.86        16\n",
      "          60       0.78      0.70      0.74        10\n",
      "          61       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86       682\n",
      "   macro avg       0.87      0.86      0.86       682\n",
      "weighted avg       0.87      0.86      0.86       682\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 10 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 12  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8416\n",
      "Test Loss: 0.4875432252883911\n",
      "Test Accuracy: 0.8416422009468079\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.79      0.63        14\n",
      "           1       0.70      0.64      0.67        11\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       1.00      0.90      0.95        20\n",
      "           4       1.00      0.93      0.96        14\n",
      "           5       1.00      0.88      0.93        16\n",
      "           6       1.00      1.00      1.00         9\n",
      "           7       1.00      0.93      0.97        15\n",
      "           8       0.92      0.92      0.92        12\n",
      "           9       1.00      0.73      0.84        11\n",
      "          10       0.94      1.00      0.97        16\n",
      "          11       0.89      0.89      0.89         9\n",
      "          12       0.83      0.56      0.67         9\n",
      "          13       0.91      1.00      0.95        10\n",
      "          14       1.00      1.00      1.00        15\n",
      "          15       1.00      0.93      0.96        14\n",
      "          16       1.00      1.00      1.00        10\n",
      "          17       1.00      0.91      0.95        11\n",
      "          18       0.68      0.81      0.74        16\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       0.88      0.58      0.70        12\n",
      "          21       1.00      0.89      0.94         9\n",
      "          22       1.00      1.00      1.00         9\n",
      "          23       1.00      0.86      0.92         7\n",
      "          24       0.33      0.11      0.17         9\n",
      "          25       0.78      0.88      0.82         8\n",
      "          26       0.80      0.92      0.86        13\n",
      "          27       1.00      1.00      1.00         8\n",
      "          28       0.73      0.80      0.76        10\n",
      "          29       0.92      1.00      0.96        11\n",
      "          30       1.00      0.73      0.84        11\n",
      "          31       0.70      0.64      0.67        11\n",
      "          32       0.86      0.50      0.63        12\n",
      "          33       1.00      0.36      0.53        11\n",
      "          34       0.90      0.90      0.90        10\n",
      "          35       0.90      0.82      0.86        11\n",
      "          36       0.81      1.00      0.90        13\n",
      "          37       0.75      1.00      0.86         6\n",
      "          38       0.50      0.83      0.62         6\n",
      "          39       1.00      1.00      1.00         7\n",
      "          40       1.00      1.00      1.00        12\n",
      "          41       1.00      0.62      0.77         8\n",
      "          42       0.52      1.00      0.69        11\n",
      "          43       0.89      0.89      0.89         9\n",
      "          44       0.92      0.92      0.92        13\n",
      "          45       1.00      1.00      1.00         7\n",
      "          46       0.62      0.80      0.70        10\n",
      "          47       1.00      0.73      0.84        11\n",
      "          48       1.00      1.00      1.00        11\n",
      "          49       1.00      0.75      0.86        12\n",
      "          50       0.69      0.69      0.69        13\n",
      "          51       0.83      0.71      0.77         7\n",
      "          52       0.78      0.64      0.70        11\n",
      "          53       0.90      1.00      0.95         9\n",
      "          54       0.79      0.83      0.81        18\n",
      "          55       1.00      1.00      1.00        12\n",
      "          56       0.83      0.83      0.83        12\n",
      "          57       0.60      0.75      0.67         8\n",
      "          58       0.53      0.91      0.67        11\n",
      "          59       0.65      0.81      0.72        16\n",
      "          60       0.88      0.70      0.78        10\n",
      "          61       0.69      0.90      0.78        10\n",
      "\n",
      "    accuracy                           0.84       682\n",
      "   macro avg       0.86      0.84      0.84       682\n",
      "weighted avg       0.86      0.84      0.84       682\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  0  0 ...  0  0  0]\n",
      " [ 0  7  0 ...  0  0  0]\n",
      " [ 0  0 10 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 13  0  1]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 3ms/step - loss: 3.6321 - accuracy: 0.0876\n",
      "Train Loss: 3.6320950984954834\n",
      "Train Accuracy: 0.08760996907949448\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0927 - accuracy: 0.7170\n",
      "Test Loss: 2.092695951461792\n",
      "Test Accuracy: 0.7170087695121765\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43        14\n",
      "           1       0.38      0.45      0.42        11\n",
      "           2       0.80      0.80      0.80        10\n",
      "           3       0.67      0.60      0.63        20\n",
      "           4       0.93      0.93      0.93        14\n",
      "           5       0.63      0.75      0.69        16\n",
      "           6       0.88      0.78      0.82         9\n",
      "           7       0.86      0.80      0.83        15\n",
      "           8       0.62      0.67      0.64        12\n",
      "           9       0.67      0.73      0.70        11\n",
      "          10       0.88      0.94      0.91        16\n",
      "          11       0.78      0.78      0.78         9\n",
      "          12       0.56      0.56      0.56         9\n",
      "          13       0.77      1.00      0.87        10\n",
      "          14       0.93      0.93      0.93        15\n",
      "          15       1.00      0.93      0.96        14\n",
      "          16       0.73      0.80      0.76        10\n",
      "          17       0.73      0.73      0.73        11\n",
      "          18       0.50      0.38      0.43        16\n",
      "          19       0.40      0.80      0.53         5\n",
      "          20       0.83      0.42      0.56        12\n",
      "          21       0.69      1.00      0.82         9\n",
      "          22       0.80      0.89      0.84         9\n",
      "          23       0.83      0.71      0.77         7\n",
      "          24       0.50      0.56      0.53         9\n",
      "          25       0.89      1.00      0.94         8\n",
      "          26       0.92      0.85      0.88        13\n",
      "          27       0.89      1.00      0.94         8\n",
      "          28       0.70      0.70      0.70        10\n",
      "          29       1.00      1.00      1.00        11\n",
      "          30       0.80      0.73      0.76        11\n",
      "          31       0.67      0.73      0.70        11\n",
      "          32       0.75      0.75      0.75        12\n",
      "          33       0.67      0.73      0.70        11\n",
      "          34       0.86      0.60      0.71        10\n",
      "          35       0.82      0.82      0.82        11\n",
      "          36       0.83      0.77      0.80        13\n",
      "          37       0.86      1.00      0.92         6\n",
      "          38       0.30      0.50      0.37         6\n",
      "          39       0.88      1.00      0.93         7\n",
      "          40       0.80      0.67      0.73        12\n",
      "          41       0.50      0.38      0.43         8\n",
      "          42       0.70      0.64      0.67        11\n",
      "          43       0.75      0.67      0.71         9\n",
      "          44       0.83      0.38      0.53        13\n",
      "          45       1.00      0.57      0.73         7\n",
      "          46       0.53      0.80      0.64        10\n",
      "          47       0.43      0.82      0.56        11\n",
      "          48       1.00      0.73      0.84        11\n",
      "          49       0.82      0.75      0.78        12\n",
      "          50       0.77      0.77      0.77        13\n",
      "          51       1.00      0.71      0.83         7\n",
      "          52       0.78      0.64      0.70        11\n",
      "          53       0.64      0.78      0.70         9\n",
      "          54       0.70      0.39      0.50        18\n",
      "          55       1.00      0.83      0.91        12\n",
      "          56       0.90      0.75      0.82        12\n",
      "          57       0.57      0.50      0.53         8\n",
      "          58       0.50      0.73      0.59        11\n",
      "          59       0.56      0.56      0.56        16\n",
      "          60       0.64      0.70      0.67        10\n",
      "          61       0.54      0.70      0.61        10\n",
      "\n",
      "    accuracy                           0.72       682\n",
      "   macro avg       0.73      0.73      0.72       682\n",
      "weighted avg       0.74      0.72      0.72       682\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6 0 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 1]\n",
      " [0 0 8 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 9 0 2]\n",
      " [0 0 0 ... 0 7 0]\n",
      " [0 0 0 ... 1 0 7]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img001-001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img001-002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img001-003.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img001-004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img001-005.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>img062-051.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>img062-052.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>img062-053.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>img062-054.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>img062-055.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image label\n",
       "0     img001-001.png     0\n",
       "1     img001-002.png     0\n",
       "2     img001-003.png     0\n",
       "3     img001-004.png     0\n",
       "4     img001-005.png     0\n",
       "...              ...   ...\n",
       "3405  img062-051.png     z\n",
       "3406  img062-052.png     z\n",
       "3407  img062-053.png     z\n",
       "3408  img062-054.png     z\n",
       "3409  img062-055.png     z\n",
       "\n",
       "[3410 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3963 - accuracy: 0.5982\n",
      "Test Loss: 1.3962992429733276\n",
      "Test Accuracy: 0.5982404947280884\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.36      0.40        14\n",
      "           1       0.26      0.82      0.40        11\n",
      "           2       0.78      0.70      0.74        10\n",
      "           3       0.67      0.70      0.68        20\n",
      "           4       0.59      0.71      0.65        14\n",
      "           5       0.75      0.56      0.64        16\n",
      "           6       0.50      0.56      0.53         9\n",
      "           7       0.45      0.87      0.59        15\n",
      "           8       0.50      0.67      0.57        12\n",
      "           9       0.58      0.64      0.61        11\n",
      "          10       0.93      0.81      0.87        16\n",
      "          11       1.00      0.44      0.62         9\n",
      "          12       0.58      0.78      0.67         9\n",
      "          13       0.90      0.90      0.90        10\n",
      "          14       0.86      0.80      0.83        15\n",
      "          15       0.81      0.93      0.87        14\n",
      "          16       0.62      1.00      0.77        10\n",
      "          17       0.67      0.36      0.47        11\n",
      "          18       0.50      0.06      0.11        16\n",
      "          19       0.25      0.20      0.22         5\n",
      "          20       0.53      0.67      0.59        12\n",
      "          21       0.62      0.56      0.59         9\n",
      "          22       0.73      0.89      0.80         9\n",
      "          23       0.71      0.71      0.71         7\n",
      "          24       0.38      0.33      0.35         9\n",
      "          25       0.86      0.75      0.80         8\n",
      "          26       1.00      0.31      0.47        13\n",
      "          27       0.80      0.50      0.62         8\n",
      "          28       0.62      0.50      0.56        10\n",
      "          29       0.75      0.82      0.78        11\n",
      "          30       0.73      0.73      0.73        11\n",
      "          31       0.80      0.73      0.76        11\n",
      "          32       0.64      0.75      0.69        12\n",
      "          33       0.78      0.64      0.70        11\n",
      "          34       0.67      0.60      0.63        10\n",
      "          35       0.69      0.82      0.75        11\n",
      "          36       0.50      0.69      0.58        13\n",
      "          37       0.71      0.83      0.77         6\n",
      "          38       0.33      0.83      0.48         6\n",
      "          39       1.00      0.71      0.83         7\n",
      "          40       0.88      0.58      0.70        12\n",
      "          41       0.56      0.62      0.59         8\n",
      "          42       0.60      0.27      0.37        11\n",
      "          43       0.62      0.56      0.59         9\n",
      "          44       0.36      0.62      0.46        13\n",
      "          45       0.43      0.86      0.57         7\n",
      "          46       1.00      0.00      0.00        10\n",
      "          47       1.00      0.18      0.31        11\n",
      "          48       0.80      0.73      0.76        11\n",
      "          49       0.89      0.67      0.76        12\n",
      "          50       0.59      0.77      0.67        13\n",
      "          51       1.00      0.29      0.44         7\n",
      "          52       0.56      0.45      0.50        11\n",
      "          53       0.38      0.67      0.48         9\n",
      "          54       0.64      0.39      0.48        18\n",
      "          55       0.50      0.25      0.33        12\n",
      "          56       1.00      0.58      0.74        12\n",
      "          57       0.29      0.25      0.27         8\n",
      "          58       0.50      0.45      0.48        11\n",
      "          59       0.57      0.50      0.53        16\n",
      "          60       0.38      0.50      0.43        10\n",
      "          61       0.39      0.70      0.50        10\n",
      "\n",
      "    accuracy                           0.60       682\n",
      "   macro avg       0.65      0.60      0.59       682\n",
      "weighted avg       0.66      0.60      0.59       682\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 0 0 ... 0 0 0]\n",
      " [0 9 0 ... 0 0 0]\n",
      " [0 0 7 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 8 0 6]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 7]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image Description](Image/Twitter1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(text_list, tokenizer, stopwords_list, remove_words):\n",
    "    '''\n",
    "    Takes in a list of strings, a tokenizer, a list of stopwords, and a list of words to remove.\n",
    "    Returns a list of lowercased, tokenized, stopwords-removed, and lemmatized words.\n",
    "    '''\n",
    "    # lowercase\n",
    "    lower = [str(text).lower() for text in text_list]\n",
    "\n",
    "    # tokenize\n",
    "    tokenized = [tokenizer.tokenize(tweet) for tweet in lower]\n",
    "\n",
    "    # stopwords and special characters\n",
    "    no_stops = []\n",
    "    for item in tokenized:\n",
    "        temp = []\n",
    "        for token in item:\n",
    "            if token not in stopwords_list and token not in remove_words:\n",
    "                # Remove special characters\n",
    "                token = re.sub(r'\\W+', '', token)\n",
    "                temp.append(token)\n",
    "        no_stops.append(temp)\n",
    "\n",
    "    # preparation for lemmatization\n",
    "    tags = [pos_tag(tokens) for tokens in no_stops]\n",
    "\n",
    "    better_tags = []\n",
    "    for item in tags:\n",
    "        temp1 = []\n",
    "        for word in item:\n",
    "            temp1.append((word[0], get_wordnet_pos(word[1])))\n",
    "        better_tags.append(temp1)\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lem = []\n",
    "    for item in better_tags:\n",
    "        temp2 = []\n",
    "        for word in item:\n",
    "            temp2.append(lemmatizer.lemmatize(word[0], word[1]))\n",
    "        lem.append(temp2)\n",
    "\n",
    "    preprocessed = [' '.join(i) for i in lem]\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "\n",
    "# Remove tweets with unknown sentiment\n",
    "df = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\"]\n",
    "\n",
    "# Remove 'No emotion toward brand or product' category\n",
    "df = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != 'No emotion toward brand or product']\n",
    "\n",
    "# Load and preprocess the data\n",
    "X = df['tweet_text']\n",
    "y = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenizer and stopwords list\n",
    "tokenizer = TweetTokenizer()\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "# Define the words to remove\n",
    "remove_words = ['rt', 'mention', '2', 'iphone', 'sxswi', '2åê', '522', 522, '32', '0134']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline for logistic regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', FunctionTransformer(clean_text, kw_args={'tokenizer': tokenizer, 'stopwords_list': stopwords_list, 'remove_words': remove_words})),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Create the pipeline for the dummy model\n",
    "dummy_pipeline = Pipeline([\n",
    "    ('preprocessor', FunctionTransformer(clean_text, kw_args={'tokenizer': tokenizer, 'stopwords_list': stopwords_list, 'remove_words': remove_words})),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune for logistic regression\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "    'classifier__C': [0.1, 1.0, 10.0]  # inverse of regularization strength\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter tuning using GridSearchCV for logistic regression\n",
    "grid_search_lr = GridSearchCV(lr_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model from GridSearchCV for logistic regression\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "best_model_lr = grid_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model with the best hyperparameters\n",
    "best_model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Train the dummy model\n",
    "dummy_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the logistic regression model\n",
    "y_pred_lr = best_model_lr.predict(X_test)\n",
    "\n",
    "# Make predictions using the dummy model\n",
    "y_pred_dummy = dummy_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the logistic regression model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='weighted', zero_division=1.0)\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='weighted', zero_division=1.0)\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted', zero_division=1.0)\n",
    "\n",
    "# Calculate evaluation metrics for the dummy model\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "precision_dummy = precision_score(y_test, y_pred_dummy, average='weighted', zero_division=1.0)\n",
    "recall_dummy = recall_score(y_test, y_pred_dummy, average='weighted', zero_division=1.0)\n",
    "f1_dummy = f1_score(y_test, y_pred_dummy, average='weighted', zero_division=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "print('Best Hyperparameters:')\n",
    "for param, value in best_params_lr.items():\n",
    "    print(f'{param}: {value}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the evaluation metrics for the logistic regression model\n",
    "print('Logistic Regression Model:')\n",
    "print(f'Accuracy: {accuracy_lr}')\n",
    "print(f'Precision: {precision_lr}')\n",
    "print(f'Recall: {recall_lr}')\n",
    "print(f'F1-score: {f1_lr}')\n",
    "print('')\n",
    "\n",
    "# Print the evaluation metrics for the dummy model\n",
    "print('Dummy Classifier:')\n",
    "print(f'Accuracy: {accuracy_dummy}')\n",
    "print(f'Precision: {precision_dummy}')\n",
    "print(f'Recall: {recall_dummy}')\n",
    "print(f'F1-score: {f1_dummy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Print the class labels\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Class {i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Print the class labels\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Class {i}: {label}\")\n",
    "\n",
    "# Perform feature analysis for logistic regression\n",
    "if 'tfidf' in best_model_lr.named_steps:\n",
    "    tfidf_vec = best_model_lr.named_steps['tfidf']\n",
    "    feature_names = tfidf_vec.get_feature_names_out()\n",
    "\n",
    "    # Get the coefficients for the positive class\n",
    "    coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "\n",
    "    # Sort the feature names and coefficients\n",
    "    sorted_indices = coefficients.argsort()\n",
    "    top_features = [feature_names[idx] for idx in sorted_indices[:10]]\n",
    "    bottom_features = [feature_names[idx] for idx in sorted_indices[-10:]]\n",
    "\n",
    "    # Print the top and bottom features\n",
    "    print('Negative emotion:')\n",
    "    print(top_features)\n",
    "    print('Positive emotion:')\n",
    "    print(bottom_features)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('Feature analysis is not available for the chosen model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Print the class labels\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Class {i}: {label}\")\n",
    "\n",
    "# Perform feature analysis for logistic regression\n",
    "if 'tfidf' in best_model_lr.named_steps:\n",
    "    tfidf_vec = best_model_lr.named_steps['tfidf']\n",
    "    feature_names = tfidf_vec.get_feature_names_out()\n",
    "\n",
    "    # Get the coefficients for the positive class\n",
    "    coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "\n",
    "    # Sort the feature names and coefficients\n",
    "    sorted_indices = coefficients.argsort()\n",
    "    top_features = [feature_names[idx] for idx in sorted_indices[:10]]\n",
    "    bottom_features = [feature_names[idx] for idx in sorted_indices[-10:]]\n",
    "\n",
    "    # Print the top and bottom features\n",
    "    print('Negative emotion:')\n",
    "    print(top_features)\n",
    "    print('Positive emotion:')\n",
    "    print(bottom_features)\n",
    "\n",
    "    # Plotting the feature analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(top_features)), coefficients[sorted_indices[:10]], align='center', color='#1DA1F2')\n",
    "    plt.yticks(range(len(top_features)), top_features)\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.ylabel('Top Features')\n",
    "    plt.title('Feature Analysis for Negative Emotion')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(bottom_features)), coefficients[sorted_indices[-10:]], align='center', color='#1DA1F2')\n",
    "    plt.yticks(range(len(bottom_features)), bottom_features)\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.ylabel('Positive emotion')\n",
    "    plt.title('Feature Analysis for Positive Emotion')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Feature analysis is not available for the chosen model.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extract the coefficients and feature names\n",
    "coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "feature_names = best_model_lr.named_steps['tfidf'].get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for positive emotion\n",
    "positive_df = pd.DataFrame({'Token': feature_names, 'Value Impact': coefficients})\n",
    "positive_df = positive_df.sort_values(by='Value Impact', ascending=False)\n",
    "\n",
    "# Create a DataFrame for negative emotion\n",
    "negative_df = pd.DataFrame({'Token': feature_names, 'Value Impact': -coefficients})\n",
    "negative_df = negative_df.sort_values(by='Value Impact', ascending=False)\n",
    "\n",
    "# Print the positive DataFrame\n",
    "print('Positive Emotion DataFrame:')\n",
    "print(positive_df.head(50))\n",
    "print()\n",
    "\n",
    "# Print the negative DataFrame\n",
    "print('Negative Emotion DataFrame:')\n",
    "print(negative_df.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the positive dataframe to CSV\n",
    "positive_df.to_csv('positive_emotion_dataframe.csv', index=True)\n",
    "\n",
    "# Save the negative dataframe to CSV\n",
    "negative_df.to_csv('negative_emotion_dataframe.csv', index=True)\n",
    "\n",
    "print('Dataframes saved to CSV files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Clean the text data\n",
    "X_cleaned = clean_text(X, tokenizer, stopwords_list, remove_words)\n",
    "\n",
    "# Tokenize the cleaned text\n",
    "tokens = [token for tweet_tokens in X_cleaned for token in tokenizer.tokenize(tweet_tokens)]\n",
    "\n",
    "# Remove the words specified for removal\n",
    "tokens_filtered = [token for token in tokens if token not in remove_words]\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_counts = Counter(tokens_filtered)\n",
    "\n",
    "# Get the top 10 most common words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "\n",
    "# Extract the words\n",
    "words = [word for word, _ in top_words]\n",
    "\n",
    "# Print the top 10 words\n",
    "print(\"Top 30 Words:\")\n",
    "for word in words:\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 10 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "words, frequencies = zip(*top_words)\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(words, frequencies, color='#1DA1F2')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 30 Words')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clean the text data\n",
    "X_cleaned = clean_text(X, tokenizer, stopwords_list, remove_words)\n",
    "\n",
    "# Tokenize the cleaned text\n",
    "tokens = [token for tweet_tokens in X_cleaned for token in tokenizer.tokenize(tweet_tokens)]\n",
    "\n",
    "# Remove the words specified for removal\n",
    "tokens_filtered = [token for token in tokens if token not in remove_words]\n",
    "\n",
    "# Create a frequency dictionary of the filtered words\n",
    "word_freq = {}\n",
    "for word in tokens_filtered:\n",
    "    word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "# Generate the word cloud based on the word frequency\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients for the positive class\n",
    "coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Get the top and bottom features\n",
    "sorted_indices = coefficients.argsort()\n",
    "top_features = [feature_names[idx] for idx in sorted_indices[:50]]\n",
    "bottom_features = [feature_names[idx] for idx in sorted_indices[-50:]]\n",
    "\n",
    "# Join the word lists for positive and negative emotions\n",
    "negative_text = ' '.join(top_features)\n",
    "positive_text = ' '.join(bottom_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate word cloud with custom color\n",
    "def generate_word_cloud_with_color(text_data, title):\n",
    "    # Define the color function\n",
    "    def blue_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        return \"hsl(200, 100%%, %d%%)\" % np.random.randint(30, 70)\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=blue_color_func).generate(text_data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Generate word cloud for positive emotion with shades of blue\n",
    "generate_word_cloud_with_color(positive_text, 'Word Cloud - Positive Emotion')\n",
    "generate_word_cloud_with_color(negative_text, 'Word Cloud - Negative Emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate word cloud with custom color\n",
    "def generate_word_cloud_with_color(text_data, title):\n",
    "    # Define the color function for blue\n",
    "    def blue_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        return \"hsl(200, 100%%, %d%%)\" % np.random.randint(30, 70)\n",
    "\n",
    "    # Define the color function for red\n",
    "    def red_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        return \"hsl(0, 100%%, %d%%)\" % np.random.randint(30, 70)\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white')\n",
    "\n",
    "    if \"Positive\" in title:\n",
    "        wordcloud.generate_from_text(text_data)\n",
    "        color_func = blue_color_func\n",
    "    elif \"Negative\" in title:\n",
    "        wordcloud.generate_from_text(text_data)\n",
    "        color_func = red_color_func\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud.recolor(color_func=color_func), interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Generate word cloud for positive emotion with shades of blue\n",
    "generate_word_cloud_with_color(positive_text, 'Word Cloud - Positive Emotion')\n",
    "# generate_word_cloud_with_color(negative_text, 'Word Cloud - Negative Emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud_with_color(negative_text, 'Word Cloud - Negative Emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the predicted labels for the test set\n",
    "y_pred = best_model_lr.predict(X_test)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Get the predicted probabilities for each class\n",
    "y_probs = best_model_lr.predict_proba(X_test)\n",
    "\n",
    "# Compute the false positive rate (fpr), true positive rate (tpr), and thresholds for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i, class_label in enumerate(best_model_lr.named_steps['classifier'].classes_):\n",
    "    fpr[class_label], tpr[class_label], _ = roc_curve(y_test, y_probs[:, i], pos_label=class_label)\n",
    "    roc_auc[class_label] = auc(fpr[class_label], tpr[class_label])\n",
    "\n",
    "# Plot the AUC-ROC curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "for class_label in best_model_lr.named_steps['classifier'].classes_:\n",
    "    plt.plot(fpr[class_label], tpr[class_label], label=f'{class_label} (AUC = {roc_auc[class_label]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image Description](Image/Twitter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
