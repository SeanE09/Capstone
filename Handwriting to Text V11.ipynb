{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conda activate TFgpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"DisplayIMG/Cartoon.png\" alt=\"Image Description\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = os.cpu_count()  # Get number of CPU cores\n",
    "num_cores_to_use = num_cores // 2  # Use half of the cores\n",
    "\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras_tuner import BayesianOptimization, HyperParameters\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras_tuner import HyperParameters\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras_tuner import BayesianOptimization, HyperParameters\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras_tuner import BayesianOptimization\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the folder name where the images are located\n",
    "folder_name = \"img\"\n",
    "\n",
    "# Construct the folder path\n",
    "folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# Specify the CSV file path containing image labels\n",
    "csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary where keys are filenames and values are labels\n",
    "labels_dict = df.set_index('image')['label'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images_from_folder(folder, labels_dict):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "        img = Image.open(file_path)\n",
    "        if img is not None:\n",
    "            img = img.convert('L')  # Convert image to grayscale\n",
    "            img = img.resize((64, 64))  # Resize the image                   3333\n",
    "            np_img = np.array(img)\n",
    "            images.append(np_img)\n",
    "            filename = os.path.basename(file_path)\n",
    "            label = labels_dict[filename]  # Get the label from the filename\n",
    "            labels.append(label)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "images = np.array(images)  # Convert list of arrays to a single array\n",
    "mean = np.mean(images)\n",
    "std = np.std(images)\n",
    "images = (images - mean) / std  # Normalize pixel values\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape array for CNN\n",
    "\n",
    "encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=35,  # Rotate images randomly by 20 degrees\n",
    "    width_shift_range=0.1,  # Shift images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,  # Shift images vertically by 10% of the height\n",
    "    shear_range=0.0,  # Apply shear transformation with a shear intensity of 0.2\n",
    "    zoom_range=0.1,  # Apply zoom transformation with a zoom range of 0.2\n",
    "    horizontal_flip=False,  # Flip images horizontally\n",
    "    vertical_flip=False  # Do not flip images vertically\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path to save the best hyperparameters\n",
    "hyperparameters_file_path = 'best_hyperparameters.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First block of convolutions\n",
    "    model.add(Conv2D(hp.Int('conv_1_units', min_value=32, max_value=128, step=32),\n",
    "                     (3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(64, 64, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Second block of convolutions\n",
    "    model.add(Conv2D(hp.Int('conv_2_units', min_value=64, max_value=256, step=64),\n",
    "                     (3, 3),\n",
    "                     activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Int('dense_1_units', min_value=128, max_value=512, step=128), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout_3', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = BayesianOptimization(\n",
    "    build_model,  # The function to construct the model\n",
    "    objective='val_accuracy',  # The metric to be optimized\n",
    "    max_trials=150,  # The maximum number of iterations for tuning\n",
    "    executions_per_trial=2,  # The number of models that should be built and fit for each trial for robustness purposes\n",
    "    directory=os.path.normpath('C:/keras_tuning'),  # The path to the directory where the search results are stored\n",
    "    project_name='keras_tuner_demo',  # The name of the project. This will be the name of the subdirectory under `directory` where the results are saved\n",
    "    overwrite=True  # Whether or not to overwrite the project if it already exists\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(\n",
    "    X_train,  # Training data\n",
    "    y_train,  # Training labels\n",
    "    epochs=200,  # The number of epochs for training\n",
    "    validation_data=(X_test, y_test),  # Validation data\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Callbacks to be used during training\n",
    ")\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "with open(hyperparameters_file_path, 'wb') as file:\n",
    "    pickle.dump(best_hyperparameters.values, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved hyperparameters\n",
    "with open(hyperparameters_file_path, 'rb') as file:\n",
    "    loaded_hyperparameters_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new HyperParameters object and set the loaded hyperparameters\n",
    "loaded_hyperparameters = HyperParameters()\n",
    "loaded_hyperparameters.values = loaded_hyperparameters_dict\n",
    "\n",
    "# Build and train the model with the loaded hyperparameters and augmented data\n",
    "best_model = build_model(loaded_hyperparameters)\n",
    "history = best_model.fit(datagen.flow(X_train, y_train),  # Use the augmented data generator for training data\n",
    "                         steps_per_epoch=len(X_train) // 32,  # Adjust the steps per epoch based on augmented data size\n",
    "                         epochs=500,\n",
    "                         validation_data=(X_test, y_test),\n",
    "                         callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=le.classes_, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((64, 64))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 64, 64, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# # Data augmentation for training data\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=35,  # Rotate images randomly by 20 degrees\n",
    "#     width_shift_range=0.1,  # Shift images horizontally by 10% of the width\n",
    "#     height_shift_range=0.1,  # Shift images vertically by 10% of the height\n",
    "#     shear_range=0.0,  # Apply shear transformation with a shear intensity of 0.2\n",
    "#     zoom_range=0.1,  # Apply zoom transformation with a zoom range of 0.2\n",
    "#     horizontal_flip=False,  # Flip images horizontally\n",
    "#     vertical_flip=False  # Do not flip images vertically\n",
    "# )\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # Specify the file path to the saved hyperparameters\n",
    "# hyperparameters_file_path = 'best_hyperparameters.pkl'\n",
    "\n",
    "# # Load the saved hyperparameters\n",
    "# with open(hyperparameters_file_path, 'rb') as file:\n",
    "#     loaded_hyperparameters_dict = pickle.load(file)\n",
    "\n",
    "# # Create a new HyperParameters object and set the loaded hyperparameters\n",
    "# loaded_hyperparameters = HyperParameters()\n",
    "# loaded_hyperparameters.values = loaded_hyperparameters_dict\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # First block of convolutions\n",
    "#     model.add(Conv2D(loaded_hyperparameters.get('conv_1_units'),\n",
    "#                      (3, 3),\n",
    "#                      activation='relu',\n",
    "#                      input_shape=(64, 64, 1)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(loaded_hyperparameters.get('dropout_1')))\n",
    "\n",
    "#     # Second block of convolutions\n",
    "#     model.add(Conv2D(loaded_hyperparameters.get('conv_2_units'),\n",
    "#                      (3, 3),\n",
    "#                      activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(loaded_hyperparameters.get('dropout_2')))\n",
    "\n",
    "#     # Fully connected layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(loaded_hyperparameters.get('dense_1_units'), activation='relu'))\n",
    "#     model.add(Dropout(loaded_hyperparameters.get('dropout_3')))\n",
    "#     model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "#     # Compile model\n",
    "#     model.compile(optimizer=Adam(loaded_hyperparameters.get('learning_rate')),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=1000)\n",
    "# model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# # Build and train the model with the loaded hyperparameters and augmented data\n",
    "# best_model = build_model(loaded_hyperparameters)\n",
    "# history = best_model.fit(datagen.flow(X_train, y_train),  # Use the augmented data generator for training data\n",
    "#                          steps_per_epoch=len(X_train) // 32,  # Adjust the steps per epoch based on augmented data size\n",
    "#                          epochs=500,\n",
    "#                          validation_data=(X_test, y_test),\n",
    "#                          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# # Plotting the accuracy and loss\n",
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# # Print a classification report\n",
    "# print(classification_report(y_true_classes, y_pred_classes, target_names=le.classes_, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=[12,8])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=[12,8])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = best_model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Save Model For Furture Use\n",
    "# model.save('EpochTenThousand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Assume you have a history object from model.fit\n",
    "# # history = model.fit(....)\n",
    "\n",
    "# # Save it under some name\n",
    "# with open('trainHistoryDict', 'wb') as file_pi:\n",
    "#     pickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trainHistoryDict', 'rb') as file_pi:\n",
    "#     loaded_history = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = best_model.evaluate(X_train, y_train)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Also convert the one-hot encoded labels back to label encoding\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Convert numerical labels back to original labels\n",
    "y_pred_labels = le.inverse_transform(y_pred_labels)\n",
    "y_true_labels = le.inverse_transform(y_true_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Create a list of unique labels\n",
    "labels = list(le.classes_)\n",
    "\n",
    "# Set the font scale (this will affect heatmap annotation size)\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Adjust size of labels, title using rcParams\n",
    "plt.rcParams['xtick.labelsize']=15\n",
    "plt.rcParams['ytick.labelsize']=15\n",
    "\n",
    "# Visualize confusion matrix using seaborn's heatmap\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label', fontsize=20)\n",
    "plt.ylabel('True Label', fontsize=20)\n",
    "plt.title('Confusion Matrix', fontsize=25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Maps (CAM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_4')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "\n",
    "# Choose an image from the test set\n",
    "test_image = X_test[4]\n",
    "\n",
    "# Reshape the image to match the input shape of the model\n",
    "test_image = np.reshape(test_image, (1, 64, 64, 1))\n",
    "\n",
    "# Generate the CAM for the chosen image\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_3')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_2')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Reshape the input image to match the expected input shape of the model\n",
    "    img = np.reshape(img, (1, 64, 64, 1))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Maps (CAM) of First Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_2')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Reshape the input image to match the expected input shape of the model\n",
    "    img = np.reshape(img, (-1, 64, 64, 1))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the image to match the expected input shape of the model\n",
    "test_image = np.reshape(test_image, (64, 64))\n",
    "test_image = np.expand_dims(test_image, axis=-1)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Maps (CAM) of 2nd Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def visualize_cam(model, img):\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('conv2d_3')\n",
    "    \n",
    "    # Define a new model that outputs the last conv layer and the model's predicted class probabilities\n",
    "    cam_model = tf.keras.Model(model.input, (last_conv_layer.output, model.output))\n",
    "    \n",
    "    # Calculate the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = cam_model(img)\n",
    "        predicted_class = tf.argmax(predictions[0])\n",
    "        gradient = tape.gradient(predictions[:, predicted_class], conv_outputs)\n",
    "    \n",
    "    # Compute the weights using global average pooling on the gradients\n",
    "    weights = tf.reduce_mean(gradient[0], axis=(0, 1))\n",
    "    \n",
    "    # Get the feature map values and resize them to match the input image size\n",
    "    feature_map = conv_outputs[0]\n",
    "    cam = np.dot(feature_map, weights)\n",
    "    cam = cv2.resize(cam, (img.shape[2], img.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    return cam\n",
    "\n",
    "\n",
    "# Choose an image from the test set\n",
    "test_image = X_test[3]\n",
    "\n",
    "# Reshape the image to match the input shape of the model\n",
    "test_image = np.reshape(test_image, (1, 64, 64, 1))\n",
    "\n",
    "# Generate the CAM for the chosen image\n",
    "cam = visualize_cam(best_model, test_image)\n",
    "\n",
    "# Plot the original image and the CAM\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "plt.title('Class Activation Map')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tf_explain.core.grad_cam import GradCAM\n",
    "\n",
    "# def image_to_uint_255(image):\n",
    "#     if isinstance(image, np.ndarray):\n",
    "#         if image.dtype == np.uint8:\n",
    "#             return image\n",
    "#         if image.min() < 0:\n",
    "#             image = (image + 1.0) / 2.0\n",
    "#         return (image * 255).astype(\"uint8\")\n",
    "#     elif isinstance(image, tf.Tensor):\n",
    "#         if tf.reduce_min(image) < 0:\n",
    "#             image = (image + 1.0) / 2.0\n",
    "#         return (image * 255).numpy().astype(\"uint8\")\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported image type. Expected NumPy array or TensorFlow tensor.\")\n",
    "\n",
    "\n",
    "\n",
    "# # Load the best model\n",
    "# best_model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# # Choose an image from the test set to generate Grad-CAM\n",
    "# image_index = 0\n",
    "# input_image = X_test[image_index]\n",
    "\n",
    "# # Preprocess the input image\n",
    "# preprocessed_image = tf.expand_dims(input_image, axis=0)\n",
    "\n",
    "# # Create a GradCAM instance\n",
    "# explainer = GradCAM()\n",
    "\n",
    "# # Generate Grad-CAM for the predicted class\n",
    "# class_index = np.argmax(best_model.predict(preprocessed_image), axis=1)[0]\n",
    "# grid = explainer.explain(validation_data=(preprocessed_image, None), model=best_model, layer_name=\"conv2d_3\", class_index=class_index)\n",
    "\n",
    "# # Rescale the grid for visualization\n",
    "# grid = cv2.resize(grid[0], (input_image.shape[1], input_image.shape[0]))\n",
    "\n",
    "# # Overlay the original image with the Grad-CAM grid\n",
    "# heatmap = cv2.applyColorMap(np.uint8(255 * grid), cv2.COLORMAP_JET)\n",
    "# output_image = cv2.addWeighted(cv2.cvtColor((input_image * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR), 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "# # Visualize the original image and Grad-CAM\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow((input_image * 255).astype(np.uint8), cmap='gray')\n",
    "# plt.title('Original Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(output_image[:, :, ::-1])\n",
    "# plt.title('Grad-CAM')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, img):\n",
    "    # Extract the intermediate feature maps\n",
    "    layer_outputs = [layer.output for layer in model.layers if 'conv2d' in layer.name]\n",
    "    activation_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    feature_maps = activation_model.predict(img)\n",
    "    \n",
    "    # Plot the feature maps\n",
    "    for layer, feature_map in zip(model.layers, feature_maps):\n",
    "        if 'conv2d' in layer.name:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.imshow(feature_map[0, :, :, 0], cmap='gray')\n",
    "            plt.title(layer.name + ' Feature Map')\n",
    "            plt.show()\n",
    "\n",
    "# Visualize the feature maps for the chosen image\n",
    "visualize_feature_maps(best_model, test_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_filters(model, layer_name):\n",
    "    layer = model.get_layer(layer_name)\n",
    "    filters, _ = layer.get_weights()\n",
    "\n",
    "    if filters.ndim == 4:\n",
    "        filters = np.moveaxis(filters, -1, 0)\n",
    "\n",
    "    num_filters = filters.shape[0]\n",
    "    num_rows = (num_filters + 7) // 8\n",
    "    plt.figure(figsize=(12, num_rows * 1.5))\n",
    "\n",
    "    for i, filter_ in enumerate(filters):\n",
    "        plt.subplot(num_rows, 8, i+1)\n",
    "        plt.imshow(filter_, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(layer_name + ' Filters')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Visualize the filters of the first convolutional layer\n",
    "visualize_filters(best_model, 'conv2d_2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_histograms(model, img):\n",
    "    activation_model = tf.keras.Model(inputs=model.input,\n",
    "                                      outputs=[layer.output for layer in model.layers if 'conv2d' in layer.name])\n",
    "    activations = activation_model.predict(img)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, activation in enumerate(activations):\n",
    "        if 'conv2d_2' in model.layers[i].name:\n",
    "            plt.subplot(2, 4, i+1)\n",
    "            plt.hist(activation.flatten(), bins=50)\n",
    "            plt.title(model.layers[i].name + ' Activation')\n",
    "            plt.xlabel('Activation Value')\n",
    "            plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the activation histograms for the chosen image\n",
    "plot_activation_histograms(best_model, test_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the results of hyperparameter optimization\n",
    "results = pd.read_csv('hyperparameter_results.csv')\n",
    "\n",
    "# Plot the accuracy and loss values for different hyperparameter settings\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results['learning_rate'], results['accuracy'], 'o-')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(results['learning_rate'], results['loss'], 'o-')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# ... (existing code)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the model architecture\n",
    "plot_model(best_model, to_file='model_architecture.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the embeddings from the model\n",
    "embedding_model = tf.keras.Model(inputs=best_model.input,\n",
    "                                 outputs=best_model.get_layer('conv2d_2').output)\n",
    "embeddings = embedding_model.predict(X_test)\n",
    "\n",
    "# Reshape the embeddings array to have two dimensions\n",
    "reshaped_embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "\n",
    "# Standardize the embeddings\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(reshaped_embeddings)\n",
    "\n",
    "# Reduce the dimensionality of the embeddings using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(scaled_embeddings)\n",
    "\n",
    "# Plot the embeddings\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], c=y_true_classes)\n",
    "plt.colorbar()\n",
    "plt.title('Embedding Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
