{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate TFgpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 4.1225 - accuracy: 0.0238 - val_loss: 4.0857 - val_accuracy: 0.0220\n",
      "Epoch 2/5\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.7175 - accuracy: 0.0869 - val_loss: 3.2641 - val_accuracy: 0.1745\n",
      "Epoch 3/5\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.7254 - accuracy: 0.2819 - val_loss: 2.5832 - val_accuracy: 0.3402\n",
      "Epoch 4/5\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 2.1166 - accuracy: 0.4249 - val_loss: 2.2214 - val_accuracy: 0.4223\n",
      "Epoch 5/5\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.7076 - accuracy: 0.5246 - val_loss: 1.8346 - val_accuracy: 0.5337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe5fe1ff10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "# import glob\n",
    "\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Specify the folder name where the images are located\n",
    "# folder_name = \"img\"\n",
    "\n",
    "# # Construct the folder path\n",
    "# folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# # Specify the CSV file path containing image labels\n",
    "# csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Create a dictionary where keys are filenames and values are labels\n",
    "# labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "# def load_images_from_folder(folder, labels_dict):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "#         img = Image.open(file_path)\n",
    "#         if img is not None:\n",
    "#             img = img.convert('L')  # Convert image to grayscale\n",
    "#             img = img.resize((28, 28))  # Resize the image\n",
    "#             np_img = np.array(img)\n",
    "#             images.append(np_img)\n",
    "#             filename = os.path.basename(file_path)\n",
    "#             label = labels_dict[filename]  # Get the label from the filename\n",
    "#             labels.append(label)\n",
    "#     return images, labels\n",
    "\n",
    "# images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "# images = np.array(images)  # Convert list of arrays to a single array\n",
    "# images = images / 255.0  # Normalize pixel values\n",
    "# images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "# encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# num_classes = len(set(numerical_labels))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 4.0487 - accuracy: 0.0286 - val_loss: 3.7491 - val_accuracy: 0.0865\n",
      "Epoch 2/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 3.1456 - accuracy: 0.1954 - val_loss: 2.7184 - val_accuracy: 0.2742\n",
      "Epoch 3/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 2.0651 - accuracy: 0.4395 - val_loss: 1.8162 - val_accuracy: 0.4985\n",
      "Epoch 4/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.3487 - accuracy: 0.6045 - val_loss: 1.4531 - val_accuracy: 0.5704\n",
      "Epoch 5/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.0118 - accuracy: 0.7023 - val_loss: 1.2266 - val_accuracy: 0.6598\n",
      "Epoch 6/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.7421 - accuracy: 0.7639 - val_loss: 1.1699 - val_accuracy: 0.6657\n",
      "Epoch 7/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.5630 - accuracy: 0.8098 - val_loss: 1.1438 - val_accuracy: 0.6642\n",
      "Epoch 8/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.4557 - accuracy: 0.8471 - val_loss: 1.1156 - val_accuracy: 0.6891\n",
      "Epoch 9/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.3542 - accuracy: 0.8809 - val_loss: 1.2289 - val_accuracy: 0.6716\n",
      "Epoch 10/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2931 - accuracy: 0.9095 - val_loss: 1.2226 - val_accuracy: 0.7009\n",
      "Epoch 11/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2523 - accuracy: 0.9135 - val_loss: 1.2302 - val_accuracy: 0.7273\n",
      "Epoch 12/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2076 - accuracy: 0.9300 - val_loss: 1.2205 - val_accuracy: 0.7155\n",
      "Epoch 13/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.1708 - accuracy: 0.9457 - val_loss: 1.2775 - val_accuracy: 0.7185\n",
      "Epoch 14/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1498 - accuracy: 0.9520 - val_loss: 1.4261 - val_accuracy: 0.7009\n",
      "Epoch 15/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1316 - accuracy: 0.9593 - val_loss: 1.2979 - val_accuracy: 0.7243\n",
      "Epoch 16/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1042 - accuracy: 0.9619 - val_loss: 1.5053 - val_accuracy: 0.6950\n",
      "Epoch 17/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1266 - accuracy: 0.9560 - val_loss: 1.4724 - val_accuracy: 0.7141\n",
      "Epoch 18/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1358 - accuracy: 0.9542 - val_loss: 1.5958 - val_accuracy: 0.7053\n",
      "Epoch 19/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0950 - accuracy: 0.9718 - val_loss: 1.6397 - val_accuracy: 0.7170\n",
      "Epoch 20/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1186 - accuracy: 0.9622 - val_loss: 1.4938 - val_accuracy: 0.6994\n",
      "Epoch 21/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0910 - accuracy: 0.9699 - val_loss: 1.5793 - val_accuracy: 0.7141\n",
      "Epoch 22/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9850 - val_loss: 1.6357 - val_accuracy: 0.7214\n",
      "Epoch 23/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9886 - val_loss: 1.7411 - val_accuracy: 0.7317\n",
      "Epoch 24/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 1.8063 - val_accuracy: 0.7067\n",
      "Epoch 25/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0944 - accuracy: 0.9670 - val_loss: 1.9085 - val_accuracy: 0.6862\n",
      "Epoch 26/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1552 - accuracy: 0.9509 - val_loss: 1.6398 - val_accuracy: 0.7126\n",
      "Epoch 27/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0711 - accuracy: 0.9765 - val_loss: 1.5142 - val_accuracy: 0.7199\n",
      "Epoch 28/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1338 - accuracy: 0.9604 - val_loss: 1.5007 - val_accuracy: 0.7067\n",
      "Epoch 29/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0739 - accuracy: 0.9791 - val_loss: 1.6710 - val_accuracy: 0.7097\n",
      "Epoch 30/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0664 - accuracy: 0.9791 - val_loss: 1.7855 - val_accuracy: 0.7170\n",
      "Epoch 31/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 1.7426 - val_accuracy: 0.7155\n",
      "Epoch 32/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 2.0017 - val_accuracy: 0.6950\n",
      "Epoch 33/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0543 - accuracy: 0.9824 - val_loss: 2.0807 - val_accuracy: 0.6906\n",
      "Epoch 34/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1379 - accuracy: 0.9542 - val_loss: 1.6631 - val_accuracy: 0.6965\n",
      "Epoch 35/40\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9600 - val_loss: 1.7034 - val_accuracy: 0.7199\n",
      "Epoch 36/40\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 1.8108 - val_accuracy: 0.7141\n",
      "Epoch 37/40\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 1.7129 - val_accuracy: 0.7243\n",
      "Epoch 38/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 1.6972 - val_accuracy: 0.7361\n",
      "Epoch 39/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 1.7399 - val_accuracy: 0.7419\n",
      "Epoch 40/40\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 1.7976 - val_accuracy: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe60969750>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "import glob\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the folder name where the images are located\n",
    "folder_name = \"img\"\n",
    "\n",
    "# Construct the folder path\n",
    "folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "# Specify the CSV file path containing image labels\n",
    "csv_file_path = os.path.join(current_directory, \"labels\", \"english-clean.csv\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary where keys are filenames and values are labels\n",
    "labels_dict = df.set_index('image')['label'].to_dict()\n",
    "\n",
    "def load_images_from_folder(folder, labels_dict):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file_path in glob.glob(os.path.join(folder, \"*.png\")):\n",
    "        img = Image.open(file_path)\n",
    "        if img is not None:\n",
    "            img = img.convert('L')  # Convert image to grayscale\n",
    "            img = img.resize((28, 28))  # Resize the image\n",
    "            np_img = np.array(img)\n",
    "            images.append(np_img)\n",
    "            filename = os.path.basename(file_path)\n",
    "            label = labels_dict[filename]  # Get the label from the filename\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_images_from_folder(folder_path, labels_dict)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "numerical_labels = le.fit_transform(labels)  # Convert labels to integers\n",
    "\n",
    "images = np.array(images)  # Convert list of arrays to a single array\n",
    "images = images / 255.0  # Normalize pixel values\n",
    "images = images.reshape(-1, 28, 28, 1)  # Reshape array for CNN\n",
    "\n",
    "encoded_labels = to_categorical(numerical_labels)  # One-hot encode labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "num_classes = len(set(numerical_labels))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Train Loss: 0.0026551405899226665\n",
      "Train Accuracy: 0.9992668628692627\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7976 - accuracy: 0.7375\n",
      "Test Loss: 1.797616720199585\n",
      "Test Accuracy: 0.7375366687774658\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        14\n",
      "           1       0.45      0.45      0.45        11\n",
      "           2       0.73      0.80      0.76        10\n",
      "           3       0.83      0.75      0.79        20\n",
      "           4       0.88      1.00      0.93        14\n",
      "           5       0.76      0.81      0.79        16\n",
      "           6       0.86      0.67      0.75         9\n",
      "           7       0.80      0.80      0.80        15\n",
      "           8       0.71      0.83      0.77        12\n",
      "           9       0.69      0.82      0.75        11\n",
      "          10       0.93      0.88      0.90        16\n",
      "          11       0.78      0.78      0.78         9\n",
      "          12       0.75      0.67      0.71         9\n",
      "          13       0.83      1.00      0.91        10\n",
      "          14       0.87      0.87      0.87        15\n",
      "          15       1.00      0.93      0.96        14\n",
      "          16       1.00      0.90      0.95        10\n",
      "          17       0.55      0.55      0.55        11\n",
      "          18       0.56      0.31      0.40        16\n",
      "          19       0.75      0.60      0.67         5\n",
      "          20       0.78      0.58      0.67        12\n",
      "          21       0.58      0.78      0.67         9\n",
      "          22       0.80      0.89      0.84         9\n",
      "          23       1.00      0.71      0.83         7\n",
      "          24       0.50      0.56      0.53         9\n",
      "          25       0.88      0.88      0.88         8\n",
      "          26       0.92      0.85      0.88        13\n",
      "          27       1.00      0.88      0.93         8\n",
      "          28       0.67      0.60      0.63        10\n",
      "          29       0.83      0.91      0.87        11\n",
      "          30       1.00      0.82      0.90        11\n",
      "          31       0.75      0.82      0.78        11\n",
      "          32       0.90      0.75      0.82        12\n",
      "          33       0.75      0.82      0.78        11\n",
      "          34       0.67      0.60      0.63        10\n",
      "          35       0.67      0.73      0.70        11\n",
      "          36       0.82      0.69      0.75        13\n",
      "          37       0.67      1.00      0.80         6\n",
      "          38       0.38      0.83      0.53         6\n",
      "          39       0.75      0.86      0.80         7\n",
      "          40       0.83      0.83      0.83        12\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       0.54      0.64      0.58        11\n",
      "          43       0.62      0.56      0.59         9\n",
      "          44       0.62      0.62      0.62        13\n",
      "          45       0.67      0.86      0.75         7\n",
      "          46       0.64      0.70      0.67        10\n",
      "          47       0.73      0.73      0.73        11\n",
      "          48       0.82      0.82      0.82        11\n",
      "          49       0.58      0.58      0.58        12\n",
      "          50       0.70      0.54      0.61        13\n",
      "          51       1.00      0.71      0.83         7\n",
      "          52       0.75      0.55      0.63        11\n",
      "          53       0.67      0.89      0.76         9\n",
      "          54       0.65      0.61      0.63        18\n",
      "          55       0.83      0.83      0.83        12\n",
      "          56       0.92      0.92      0.92        12\n",
      "          57       0.67      0.50      0.57         8\n",
      "          58       0.69      0.82      0.75        11\n",
      "          59       0.65      0.81      0.72        16\n",
      "          60       0.67      0.60      0.63        10\n",
      "          61       0.62      0.80      0.70        10\n",
      "\n",
      "    accuracy                           0.74       682\n",
      "   macro avg       0.74      0.74      0.73       682\n",
      "weighted avg       0.75      0.74      0.74       682\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  5  0 ...  0  0  0]\n",
      " [ 0  0  8 ...  0  0  1]\n",
      " ...\n",
      " [ 0  0  0 ... 13  0  1]\n",
      " [ 0  0  0 ...  0  6  0]\n",
      " [ 0  0  0 ...  1  0  8]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img001-001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img001-002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img001-003.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img001-004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img001-005.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>img062-051.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>img062-052.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>img062-053.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>img062-054.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>img062-055.png</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image label\n",
       "0     img001-001.png     0\n",
       "1     img001-002.png     0\n",
       "2     img001-003.png     0\n",
       "3     img001-004.png     0\n",
       "4     img001-005.png     0\n",
       "...              ...   ...\n",
       "3405  img062-051.png     z\n",
       "3406  img062-052.png     z\n",
       "3407  img062-053.png     z\n",
       "3408  img062-054.png     z\n",
       "3409  img062-055.png     z\n",
       "\n",
       "[3410 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3963 - accuracy: 0.5982\n",
      "Test Loss: 1.3962992429733276\n",
      "Test Accuracy: 0.5982404947280884\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.36      0.40        14\n",
      "           1       0.26      0.82      0.40        11\n",
      "           2       0.78      0.70      0.74        10\n",
      "           3       0.67      0.70      0.68        20\n",
      "           4       0.59      0.71      0.65        14\n",
      "           5       0.75      0.56      0.64        16\n",
      "           6       0.50      0.56      0.53         9\n",
      "           7       0.45      0.87      0.59        15\n",
      "           8       0.50      0.67      0.57        12\n",
      "           9       0.58      0.64      0.61        11\n",
      "          10       0.93      0.81      0.87        16\n",
      "          11       1.00      0.44      0.62         9\n",
      "          12       0.58      0.78      0.67         9\n",
      "          13       0.90      0.90      0.90        10\n",
      "          14       0.86      0.80      0.83        15\n",
      "          15       0.81      0.93      0.87        14\n",
      "          16       0.62      1.00      0.77        10\n",
      "          17       0.67      0.36      0.47        11\n",
      "          18       0.50      0.06      0.11        16\n",
      "          19       0.25      0.20      0.22         5\n",
      "          20       0.53      0.67      0.59        12\n",
      "          21       0.62      0.56      0.59         9\n",
      "          22       0.73      0.89      0.80         9\n",
      "          23       0.71      0.71      0.71         7\n",
      "          24       0.38      0.33      0.35         9\n",
      "          25       0.86      0.75      0.80         8\n",
      "          26       1.00      0.31      0.47        13\n",
      "          27       0.80      0.50      0.62         8\n",
      "          28       0.62      0.50      0.56        10\n",
      "          29       0.75      0.82      0.78        11\n",
      "          30       0.73      0.73      0.73        11\n",
      "          31       0.80      0.73      0.76        11\n",
      "          32       0.64      0.75      0.69        12\n",
      "          33       0.78      0.64      0.70        11\n",
      "          34       0.67      0.60      0.63        10\n",
      "          35       0.69      0.82      0.75        11\n",
      "          36       0.50      0.69      0.58        13\n",
      "          37       0.71      0.83      0.77         6\n",
      "          38       0.33      0.83      0.48         6\n",
      "          39       1.00      0.71      0.83         7\n",
      "          40       0.88      0.58      0.70        12\n",
      "          41       0.56      0.62      0.59         8\n",
      "          42       0.60      0.27      0.37        11\n",
      "          43       0.62      0.56      0.59         9\n",
      "          44       0.36      0.62      0.46        13\n",
      "          45       0.43      0.86      0.57         7\n",
      "          46       1.00      0.00      0.00        10\n",
      "          47       1.00      0.18      0.31        11\n",
      "          48       0.80      0.73      0.76        11\n",
      "          49       0.89      0.67      0.76        12\n",
      "          50       0.59      0.77      0.67        13\n",
      "          51       1.00      0.29      0.44         7\n",
      "          52       0.56      0.45      0.50        11\n",
      "          53       0.38      0.67      0.48         9\n",
      "          54       0.64      0.39      0.48        18\n",
      "          55       0.50      0.25      0.33        12\n",
      "          56       1.00      0.58      0.74        12\n",
      "          57       0.29      0.25      0.27         8\n",
      "          58       0.50      0.45      0.48        11\n",
      "          59       0.57      0.50      0.53        16\n",
      "          60       0.38      0.50      0.43        10\n",
      "          61       0.39      0.70      0.50        10\n",
      "\n",
      "    accuracy                           0.60       682\n",
      "   macro avg       0.65      0.60      0.59       682\n",
      "weighted avg       0.66      0.60      0.59       682\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 0 0 ... 0 0 0]\n",
      " [0 9 0 ... 0 0 0]\n",
      " [0 0 7 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 8 0 6]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 7]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image Description](Image/Twitter1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(text_list, tokenizer, stopwords_list, remove_words):\n",
    "    '''\n",
    "    Takes in a list of strings, a tokenizer, a list of stopwords, and a list of words to remove.\n",
    "    Returns a list of lowercased, tokenized, stopwords-removed, and lemmatized words.\n",
    "    '''\n",
    "    # lowercase\n",
    "    lower = [str(text).lower() for text in text_list]\n",
    "\n",
    "    # tokenize\n",
    "    tokenized = [tokenizer.tokenize(tweet) for tweet in lower]\n",
    "\n",
    "    # stopwords and special characters\n",
    "    no_stops = []\n",
    "    for item in tokenized:\n",
    "        temp = []\n",
    "        for token in item:\n",
    "            if token not in stopwords_list and token not in remove_words:\n",
    "                # Remove special characters\n",
    "                token = re.sub(r'\\W+', '', token)\n",
    "                temp.append(token)\n",
    "        no_stops.append(temp)\n",
    "\n",
    "    # preparation for lemmatization\n",
    "    tags = [pos_tag(tokens) for tokens in no_stops]\n",
    "\n",
    "    better_tags = []\n",
    "    for item in tags:\n",
    "        temp1 = []\n",
    "        for word in item:\n",
    "            temp1.append((word[0], get_wordnet_pos(word[1])))\n",
    "        better_tags.append(temp1)\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lem = []\n",
    "    for item in better_tags:\n",
    "        temp2 = []\n",
    "        for word in item:\n",
    "            temp2.append(lemmatizer.lemmatize(word[0], word[1]))\n",
    "        lem.append(temp2)\n",
    "\n",
    "    preprocessed = [' '.join(i) for i in lem]\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "\n",
    "# Remove tweets with unknown sentiment\n",
    "df = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\"]\n",
    "\n",
    "# Remove 'No emotion toward brand or product' category\n",
    "df = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != 'No emotion toward brand or product']\n",
    "\n",
    "# Load and preprocess the data\n",
    "X = df['tweet_text']\n",
    "y = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenizer and stopwords list\n",
    "tokenizer = TweetTokenizer()\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "# Define the words to remove\n",
    "remove_words = ['rt', 'mention', '2', 'iphone', 'sxswi', '2åê', '522', 522, '32', '0134']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline for logistic regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', FunctionTransformer(clean_text, kw_args={'tokenizer': tokenizer, 'stopwords_list': stopwords_list, 'remove_words': remove_words})),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Create the pipeline for the dummy model\n",
    "dummy_pipeline = Pipeline([\n",
    "    ('preprocessor', FunctionTransformer(clean_text, kw_args={'tokenizer': tokenizer, 'stopwords_list': stopwords_list, 'remove_words': remove_words})),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune for logistic regression\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "    'classifier__C': [0.1, 1.0, 10.0]  # inverse of regularization strength\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter tuning using GridSearchCV for logistic regression\n",
    "grid_search_lr = GridSearchCV(lr_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model from GridSearchCV for logistic regression\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "best_model_lr = grid_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model with the best hyperparameters\n",
    "best_model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Train the dummy model\n",
    "dummy_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the logistic regression model\n",
    "y_pred_lr = best_model_lr.predict(X_test)\n",
    "\n",
    "# Make predictions using the dummy model\n",
    "y_pred_dummy = dummy_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the logistic regression model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='weighted', zero_division=1.0)\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='weighted', zero_division=1.0)\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted', zero_division=1.0)\n",
    "\n",
    "# Calculate evaluation metrics for the dummy model\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "precision_dummy = precision_score(y_test, y_pred_dummy, average='weighted', zero_division=1.0)\n",
    "recall_dummy = recall_score(y_test, y_pred_dummy, average='weighted', zero_division=1.0)\n",
    "f1_dummy = f1_score(y_test, y_pred_dummy, average='weighted', zero_division=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "print('Best Hyperparameters:')\n",
    "for param, value in best_params_lr.items():\n",
    "    print(f'{param}: {value}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the evaluation metrics for the logistic regression model\n",
    "print('Logistic Regression Model:')\n",
    "print(f'Accuracy: {accuracy_lr}')\n",
    "print(f'Precision: {precision_lr}')\n",
    "print(f'Recall: {recall_lr}')\n",
    "print(f'F1-score: {f1_lr}')\n",
    "print('')\n",
    "\n",
    "# Print the evaluation metrics for the dummy model\n",
    "print('Dummy Classifier:')\n",
    "print(f'Accuracy: {accuracy_dummy}')\n",
    "print(f'Precision: {precision_dummy}')\n",
    "print(f'Recall: {recall_dummy}')\n",
    "print(f'F1-score: {f1_dummy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Print the class labels\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Class {i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Print the class labels\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Class {i}: {label}\")\n",
    "\n",
    "# Perform feature analysis for logistic regression\n",
    "if 'tfidf' in best_model_lr.named_steps:\n",
    "    tfidf_vec = best_model_lr.named_steps['tfidf']\n",
    "    feature_names = tfidf_vec.get_feature_names_out()\n",
    "\n",
    "    # Get the coefficients for the positive class\n",
    "    coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "\n",
    "    # Sort the feature names and coefficients\n",
    "    sorted_indices = coefficients.argsort()\n",
    "    top_features = [feature_names[idx] for idx in sorted_indices[:10]]\n",
    "    bottom_features = [feature_names[idx] for idx in sorted_indices[-10:]]\n",
    "\n",
    "    # Print the top and bottom features\n",
    "    print('Negative emotion:')\n",
    "    print(top_features)\n",
    "    print('Positive emotion:')\n",
    "    print(bottom_features)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('Feature analysis is not available for the chosen model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Print the class labels\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Class {i}: {label}\")\n",
    "\n",
    "# Perform feature analysis for logistic regression\n",
    "if 'tfidf' in best_model_lr.named_steps:\n",
    "    tfidf_vec = best_model_lr.named_steps['tfidf']\n",
    "    feature_names = tfidf_vec.get_feature_names_out()\n",
    "\n",
    "    # Get the coefficients for the positive class\n",
    "    coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "\n",
    "    # Sort the feature names and coefficients\n",
    "    sorted_indices = coefficients.argsort()\n",
    "    top_features = [feature_names[idx] for idx in sorted_indices[:10]]\n",
    "    bottom_features = [feature_names[idx] for idx in sorted_indices[-10:]]\n",
    "\n",
    "    # Print the top and bottom features\n",
    "    print('Negative emotion:')\n",
    "    print(top_features)\n",
    "    print('Positive emotion:')\n",
    "    print(bottom_features)\n",
    "\n",
    "    # Plotting the feature analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(top_features)), coefficients[sorted_indices[:10]], align='center', color='#1DA1F2')\n",
    "    plt.yticks(range(len(top_features)), top_features)\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.ylabel('Top Features')\n",
    "    plt.title('Feature Analysis for Negative Emotion')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(bottom_features)), coefficients[sorted_indices[-10:]], align='center', color='#1DA1F2')\n",
    "    plt.yticks(range(len(bottom_features)), bottom_features)\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.ylabel('Positive emotion')\n",
    "    plt.title('Feature Analysis for Positive Emotion')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Feature analysis is not available for the chosen model.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extract the coefficients and feature names\n",
    "coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "feature_names = best_model_lr.named_steps['tfidf'].get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for positive emotion\n",
    "positive_df = pd.DataFrame({'Token': feature_names, 'Value Impact': coefficients})\n",
    "positive_df = positive_df.sort_values(by='Value Impact', ascending=False)\n",
    "\n",
    "# Create a DataFrame for negative emotion\n",
    "negative_df = pd.DataFrame({'Token': feature_names, 'Value Impact': -coefficients})\n",
    "negative_df = negative_df.sort_values(by='Value Impact', ascending=False)\n",
    "\n",
    "# Print the positive DataFrame\n",
    "print('Positive Emotion DataFrame:')\n",
    "print(positive_df.head(50))\n",
    "print()\n",
    "\n",
    "# Print the negative DataFrame\n",
    "print('Negative Emotion DataFrame:')\n",
    "print(negative_df.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the positive dataframe to CSV\n",
    "positive_df.to_csv('positive_emotion_dataframe.csv', index=True)\n",
    "\n",
    "# Save the negative dataframe to CSV\n",
    "negative_df.to_csv('negative_emotion_dataframe.csv', index=True)\n",
    "\n",
    "print('Dataframes saved to CSV files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Clean the text data\n",
    "X_cleaned = clean_text(X, tokenizer, stopwords_list, remove_words)\n",
    "\n",
    "# Tokenize the cleaned text\n",
    "tokens = [token for tweet_tokens in X_cleaned for token in tokenizer.tokenize(tweet_tokens)]\n",
    "\n",
    "# Remove the words specified for removal\n",
    "tokens_filtered = [token for token in tokens if token not in remove_words]\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_counts = Counter(tokens_filtered)\n",
    "\n",
    "# Get the top 10 most common words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "\n",
    "# Extract the words\n",
    "words = [word for word, _ in top_words]\n",
    "\n",
    "# Print the top 10 words\n",
    "print(\"Top 30 Words:\")\n",
    "for word in words:\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 10 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "words, frequencies = zip(*top_words)\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(words, frequencies, color='#1DA1F2')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 30 Words')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clean the text data\n",
    "X_cleaned = clean_text(X, tokenizer, stopwords_list, remove_words)\n",
    "\n",
    "# Tokenize the cleaned text\n",
    "tokens = [token for tweet_tokens in X_cleaned for token in tokenizer.tokenize(tweet_tokens)]\n",
    "\n",
    "# Remove the words specified for removal\n",
    "tokens_filtered = [token for token in tokens if token not in remove_words]\n",
    "\n",
    "# Create a frequency dictionary of the filtered words\n",
    "word_freq = {}\n",
    "for word in tokens_filtered:\n",
    "    word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "# Generate the word cloud based on the word frequency\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients for the positive class\n",
    "coefficients = best_model_lr.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Get the top and bottom features\n",
    "sorted_indices = coefficients.argsort()\n",
    "top_features = [feature_names[idx] for idx in sorted_indices[:50]]\n",
    "bottom_features = [feature_names[idx] for idx in sorted_indices[-50:]]\n",
    "\n",
    "# Join the word lists for positive and negative emotions\n",
    "negative_text = ' '.join(top_features)\n",
    "positive_text = ' '.join(bottom_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate word cloud with custom color\n",
    "def generate_word_cloud_with_color(text_data, title):\n",
    "    # Define the color function\n",
    "    def blue_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        return \"hsl(200, 100%%, %d%%)\" % np.random.randint(30, 70)\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=blue_color_func).generate(text_data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Generate word cloud for positive emotion with shades of blue\n",
    "generate_word_cloud_with_color(positive_text, 'Word Cloud - Positive Emotion')\n",
    "generate_word_cloud_with_color(negative_text, 'Word Cloud - Negative Emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate word cloud with custom color\n",
    "def generate_word_cloud_with_color(text_data, title):\n",
    "    # Define the color function for blue\n",
    "    def blue_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        return \"hsl(200, 100%%, %d%%)\" % np.random.randint(30, 70)\n",
    "\n",
    "    # Define the color function for red\n",
    "    def red_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        return \"hsl(0, 100%%, %d%%)\" % np.random.randint(30, 70)\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white')\n",
    "\n",
    "    if \"Positive\" in title:\n",
    "        wordcloud.generate_from_text(text_data)\n",
    "        color_func = blue_color_func\n",
    "    elif \"Negative\" in title:\n",
    "        wordcloud.generate_from_text(text_data)\n",
    "        color_func = red_color_func\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud.recolor(color_func=color_func), interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Generate word cloud for positive emotion with shades of blue\n",
    "generate_word_cloud_with_color(positive_text, 'Word Cloud - Positive Emotion')\n",
    "# generate_word_cloud_with_color(negative_text, 'Word Cloud - Negative Emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud_with_color(negative_text, 'Word Cloud - Negative Emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the predicted labels for the test set\n",
    "y_pred = best_model_lr.predict(X_test)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = best_model_lr.named_steps['classifier'].classes_\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Get the predicted probabilities for each class\n",
    "y_probs = best_model_lr.predict_proba(X_test)\n",
    "\n",
    "# Compute the false positive rate (fpr), true positive rate (tpr), and thresholds for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i, class_label in enumerate(best_model_lr.named_steps['classifier'].classes_):\n",
    "    fpr[class_label], tpr[class_label], _ = roc_curve(y_test, y_probs[:, i], pos_label=class_label)\n",
    "    roc_auc[class_label] = auc(fpr[class_label], tpr[class_label])\n",
    "\n",
    "# Plot the AUC-ROC curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "for class_label in best_model_lr.named_steps['classifier'].classes_:\n",
    "    plt.plot(fpr[class_label], tpr[class_label], label=f'{class_label} (AUC = {roc_auc[class_label]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image Description](Image/Twitter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
